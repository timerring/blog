[{"id":0,"href":"/posts/go-common-test/","title":"Go Common Test","section":"Blog","content":"The test methods in Go mainly include three types: unit test, benchmark test, and example test.\nFirst of all:\nYou should import the testing package first. In the package directory, all source code files with the suffix *_test.go are part of the go test test, and will not be compiled into the final executable file by go build. Unit Test # The basic format/signature is:\nfunc TestXxx(t *testing.T) { // ... } Put the _test.go and .go in the same dir, and run go test -v to execute the test detailed, the go test -cover to check the coverage of the test.\nBenchmark test # The benchmark test will not be excuted by default, you need to use go test -bench=Xxx to execute the benchmark test.\nThe basic format/signature is:\nfunc BenchmarkXxx(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { // ... } } The b.N is the number of times the test is run, and the b.N is automatically adjusted by the go test tool.\nBenchmarkSplit-8 10000000 215 ns/op The -8 means the test is run on the 8 GOMAXPROCS The 10000000 means the test is run 10000000 times. The 215 ns/op means the test takes 215 nanoseconds average per operation. go test -bench=Xxx -benchmem can check the memory allocation and the number of allocations per operation.\nBenchmarkSplit-8 10000000 215 ns/op 112 B/op 3 allocs/op The 112 B/op means the test allocates 112 bytes per operation. The 3 allocs/op means the test allocates 3 times per operation. Performance comparison # // note: the n is the parameter of Fib not the b.N, the b.N is the number of times the test is run. it will be automatically adjusted by the go test tool. func benchmarkFib(b *testing.B, n int) { for i := 0; i \u0026lt; b.N; i++ { Fib(n) } } func BenchmarkFib1(b *testing.B) { benchmarkFib(b, 1) } func BenchmarkFib2(b *testing.B) { benchmarkFib(b, 2) } func BenchmarkFib3(b *testing.B) { benchmarkFib(b, 3) } go test -bench=. will execute the benchmark test for all functions with the prefix Benchmark.\nfunc BenchmarkSplit(b *testing.B) { time.Sleep(5 * time.Second) // some time-consuming operations b.ResetTimer() // reset the timer(ignore the time above) for i := 0; i \u0026lt; b.N; i++ { // some time-consuming operations } } // you can also use this method func BenchmarkSplit(b *testing.B) { b.StopTimer() // some time-consuming operations b.StartTimer() for i := 0; i \u0026lt; b.N; i++ { // some time-consuming operations } } Parallel test # Signature:\nfunc BenchmarkSplitParallel(b *testing.B) { // b.SetParallelism(1) // set the number of CPU to use b.RunParallel(func(pb *testing.PB) { for pb.Next() { // some time-consuming operations } }) } Example test # Signature:\nfunc ExampleName() { // No parameters and no return } "},{"id":1,"href":"/posts/go-concurrency-and-parallelism/","title":"Go Concurrency and Parallelism","section":"Blog","content":" Process and Thread # The process is the program execution process in the operating system, and it is an independent unit for resource allocation and scheduling.\nThe thread is the execution entity of the process, the basic unit for CPU scheduling and distribution, and it is a smaller unit that can run independently.\nA process can create and cancel multiple threads; multiple threads in the same process can execute concurrently.\nConcurrency and Parallelism # Concurrency is multiple threads running on the same CPU core.\nParallelism is multiple threads running on multiple CPU cores.\nGoroutine # A thread can run multiple goroutines, and a goroutine is a lightweight thread, which is managed by the Go runtime, independent stack space, shared heap space, scheduling controlled by the user, essentially similar to user-level threads. The cost of routine is KB level which is much lower than thread MB level.\ngoroutine is just a super \u0026ldquo;thread pool\u0026rdquo; implemented by the official. The 4~5KB stack memory occupied by each instance and the greatly reduced creation and destruction overhead due to the implementation mechanism are the fundamental reason for Go\u0026rsquo;s high concurrency.\nA goroutine must correspond to a function, you just need to add the go keyword before the function.\nfunc hello() { fmt.Println(\u0026#34;Hello Goroutine!\u0026#34;) } func main() { go hello() // use goroutine fmt.Println(\u0026#34;main goroutine done!\u0026#34;) } // output: // main goroutine done! // why? the main goroutine life cycle is over, the program will exit. // this only for the main goroutine, so for the other goroutine, if return, the sub-routine can still running. Use sync.WaitGroup to wait all goroutine done.\nvar wg sync.WaitGroup func hello(i int) { defer wg.Done() // goroutine done, add -1 fmt.Println(\u0026#34;Hello Goroutine!\u0026#34;, i) } func main() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) // add a goroutine go hello(i) } wg.Wait() // wait all goroutine done } "},{"id":2,"href":"/posts/go-cheatsheet/","title":"Go Cheatsheet","section":"Blog","content":" syntax # The uppercase of the first letter of const, var, func, type is exported. And the lowercase is private. The { cannot be as a separate line. Not need to use ; to end the statement.(Not recommend) // or /* */ can be used to comment. the string can be connected by + fmt.Printf is used to print the string format. dependency # go get # go env # GOROOT=\u0026#39;/usr/local/go\u0026#39; // the standard library # GOPATH=\u0026#39;/Users/username/go\u0026#39; // the project lib or three-party lib go get will download the three-party lib to the GOPATH/src directory. The go search GOROOT first, then search GOPATH. But the denpendency only can keep one version, which will cause some conflict.\ngo vendor # Save all the denpendency in the vendor directory of the project, which make the project more redundant. The go will search the vendor first. This still cannot solve the problem of version.\ngo module # It was introduced in go1.11, which can manage the denpendency more flexibly.\ngo mod init first initialize the project denpendency. go mod tidy write the using denpendency to the go.mod file and remove the unused denpendency in the file. go mod download or go build or go test, the three-party lib will be downloaded to the GOPATH/pkg/mod directory. indirect means the sub-denpendency. +incompatible means compatible with the old version without the go.mod file.\nIf the project different package needs the same denpendency\u0026rsquo;s different version, it will choose the minimum compatible version.\ndenpendency distribution # Normally use the GOPROXY='https://proxy.golang.org,direct' search the proxy first, if not found, then search the original source.\ndata type # Int float..: default is 0 String: default is \u0026quot;\u0026quot; Bool: default is false Below are all nil.\nvar a *int var a []int var a map[string] int var a chan int var a func(string) int var a error var # // case1 var identifier1, identifier2 type // usually used in global variable var ( vname1 v_type1 vname2 v_type2 ) // case2 only can be used in function intVal := 1 // you cannot declare the variable twice // which is equivalent to var intVal int = 1 var intVal int intVal =1 // case3 auto var v1name, v2name = value1, value2 The int, float, bool and string are basic value type, using these types of variables directly save the value in memory, if use such as i = j, then actually copy the value of j to i in memory. \u0026amp;i is used to get the address of i in memory. When the i is local variable, the address is in the stack, when the i is global variable, the address is in the heap.\nThe complex type is a pointer, slice, map, channel, function, interface, struct, they are usually used as reference type. The reference type usually save the address of the value in memory, if use such as i = j, then actually copy the address of j to i in memory. So if j changes reference value, i will also change.\nYou cannot declare a var but not use it in function. Except the global variable.\nYou can use a, b = b, a to swap the value of a and b.(Must be the same type)\nUse _ to drop value, such as _, b = a, b\nconst # // type only boolen, string, number const identifier [type] = value You can use the build-in function to operate the const.\nimport \u0026#34;unsafe\u0026#34; const ( a = \u0026#34;abc\u0026#34; b = len(a) c = unsafe.Sizeof(a) ) iota # special const, default is 0, every time add one const, the iota will add one.\nAnd in the const block, if you don\u0026rsquo;t assign the value obviously, it will inherit the last value.\nfunc main() { const ( a = iota //0 b //1 c //2 d = \u0026#34;ha\u0026#34; //\u0026#34;ha\u0026#34; iota += 1 e //\u0026#34;ha\u0026#34; iota += 1 f = 100 //100 iota +=1 g //100 iota +=1 h = iota //7 i //8 ) } operator # \u0026amp;: get the address of the variable.\npointer variable: get the value of the address. package main import \u0026#34;fmt\u0026#34; func main() { var a int = 4 var b int32 var c float32 var ptr *int ptr = \u0026amp;a fmt.Printf(\u0026#34;a is %d\\n\u0026#34;, a); // a is 4 fmt.Printf(\u0026#34;*ptr is %d\\n\u0026#34;, *ptr); // *ptr is 4 } if # if num := 9; num \u0026lt; 0 { fmt.Println(num, \u0026#34;is negative\u0026#34;) } else if num \u0026lt; 10 { fmt.Println(num, \u0026#34;has 1 digit\u0026#34;) } else { fmt.Println(num, \u0026#34;has multiple digits\u0026#34;) } switch # switch var1 { case val1: // do something case val2: // do something default: // do something } switch x.(type){ case type: statement(s); case type: statement(s); default: // optional statement(s); } // the fallthrough will execute the next case forcefully. func main() { switch { case false: fmt.Println(\u0026#34;1\u0026#34;) fallthrough case true: fmt.Println(\u0026#34;2\u0026#34;) fallthrough case false: fmt.Println(\u0026#34;3\u0026#34;) fallthrough case true: fmt.Println(\u0026#34;4\u0026#34;) case false: fmt.Println(\u0026#34;5\u0026#34;) fallthrough default: fmt.Println(\u0026#34;6\u0026#34;) } } // 2 3 4 select # select only can be used in channel, each case must be a channel operation, either send or receive.\nselect { case \u0026lt;-ch1: // do something case value := \u0026lt;- channel2: // do something case channel3 \u0026lt;- value: // do something default: // do something } select statement will listen to all the channel operations, once one channel is ready, then execute the corresponding code block. If multiple channels are ready, then the select statement will randomly select one channel to execute. If all channels are not ready, then execute the code in the default block. if there is no default, select will block until one channel is ready. Go will not re-evaluate the channel or value.\nfor # for n := 0; n \u0026lt; 5; n++ { if n%2 == 0 { continue } fmt.Println(n) } // infinite loop for { fmt.Println(\u0026#34;loop\u0026#34;) break } array # It is fixed length, which is not common used.\nvar twoD [2][3]int for i := 0; i \u0026lt; 2; i++ { for j := 0; j \u0026lt; 3; j++ { twoD[i][j] = i + j } } slice # func main() { s := make([]string, 3) s[0] = \u0026#34;a\u0026#34; s[1] = \u0026#34;b\u0026#34; s[2] = \u0026#34;c\u0026#34; fmt.Println(\u0026#34;get:\u0026#34;, s[2]) // c fmt.Println(\u0026#34;len:\u0026#34;, len(s)) // 3 s = append(s, \u0026#34;d\u0026#34;) // must be received back s = append(s, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;) fmt.Println(s) // [a b c d e f] c := make([]string, len(s)) copy(c, s) fmt.Println(c) // [a b c d e f] fmt.Println(s[2:5]) // [c d e] fmt.Println(s[:5]) // [a b c d e] fmt.Println(s[2:]) // [c d e f] good := []string{\u0026#34;g\u0026#34;, \u0026#34;o\u0026#34;, \u0026#34;o\u0026#34;, \u0026#34;d\u0026#34;} fmt.Println(good) // [g o o d] } map # func main() { m := make(map[string]int) m[\u0026#34;one\u0026#34;] = 1 m[\u0026#34;two\u0026#34;] = 2 fmt.Println(m) // map[one:1 two:2] fmt.Println(len(m)) // 2 fmt.Println(m[\u0026#34;one\u0026#34;]) // 1 fmt.Println(m[\u0026#34;unknow\u0026#34;]) // 0 r, ok := m[\u0026#34;unknow\u0026#34;] fmt.Println(r, ok) // 0 false delete(m, \u0026#34;one\u0026#34;) m2 := map[string]int{\u0026#34;one\u0026#34;: 1, \u0026#34;two\u0026#34;: 2} var m3 = map[string]int{\u0026#34;one\u0026#34;: 1, \u0026#34;two\u0026#34;: 2} fmt.Println(m2, m3) } range # func main() { nums := []int{2, 3, 4} sum := 0 for i, num := range nums { sum += num if num == 2 { fmt.Println(\u0026#34;index:\u0026#34;, i, \u0026#34;num:\u0026#34;, num) // index: 0 num: 2 } } fmt.Println(sum) // 9 m := map[string]string{\u0026#34;a\u0026#34;: \u0026#34;A\u0026#34;, \u0026#34;b\u0026#34;: \u0026#34;B\u0026#34;} for k, v := range m { fmt.Println(k, v) // b 8; a A } for k := range m { fmt.Println(\u0026#34;key\u0026#34;, k) // key a; key b } } func # // func name(parameter-list) (return-list) func add(a int, b int) int { return a + b } func add2(a, b int) int { return a + b } func exists(m map[string]string, k string) (v string, ok bool) { v, ok = m[k] return v, ok } func main() { res := add(1, 2) fmt.Println(res) // 3 v, ok := exists(map[string]string{\u0026#34;a\u0026#34;: \u0026#34;A\u0026#34;}, \u0026#34;a\u0026#34;) fmt.Println(v, ok) // A True } pointer # func add2(n int) { n += 2 } func add2ptr(n *int) { *n += 2 } func main() { n := 5 add2(n) fmt.Println(n) // 5 add2ptr(\u0026amp;n) fmt.Println(n) // 7 } struct # type user struct { name string password string } func main() { // 1 a := user{name: \u0026#34;wang\u0026#34;, password: \u0026#34;1024\u0026#34;} // 2 b := user{\u0026#34;wang\u0026#34;, \u0026#34;1024\u0026#34;} // 3 c := user{name: \u0026#34;wang\u0026#34;} c.password = \u0026#34;1024\u0026#34; // 4 var d user d.name = \u0026#34;wang\u0026#34; d.password = \u0026#34;1024\u0026#34; fmt.Println(a, b, c, d) // {wang 1024} {wang 1024} {wang 1024} {wang 1024} fmt.Println(checkPassword(a, \u0026#34;haha\u0026#34;)) // false fmt.Println(checkPassword2(\u0026amp;a, \u0026#34;haha\u0026#34;)) // false } func checkPassword(u user, password string) bool { return u.password == password } // if use pointer, you can make some changes and avoid some big structure cost func checkPassword2(u *user, password string) bool { return u.password == password } // the structure method func (u user) checkPassword(password string) bool { return u.password == password } // You can change the value via pointer func (u *user) resetPassword(password string) { u.password = password } func main() { a := user{name: \u0026#34;wang\u0026#34;, password: \u0026#34;1024\u0026#34;} a.resetPassword(\u0026#34;2048\u0026#34;) fmt.Println(a.checkPassword(\u0026#34;2048\u0026#34;)) // true } error # import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) type user struct { name string password string } func findUser(users []user, name string) (v *user, err error) { for _, u := range users { if u.name == name { return \u0026amp;u, nil } } return nil, errors.New(\u0026#34;not found\u0026#34;) } func main() { if u, err := findUser([]user{{\u0026#34;wang\u0026#34;, \u0026#34;1024\u0026#34;}}, \u0026#34;li\u0026#34;); err != nil { fmt.Println(err) // not found return } else { fmt.Println(u.name) } } string # import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { a := \u0026#34;hello\u0026#34; fmt.Println(strings.Contains(a, \u0026#34;ll\u0026#34;)) // true fmt.Println(strings.Count(a, \u0026#34;l\u0026#34;)) // 2 fmt.Println(strings.HasPrefix(a, \u0026#34;he\u0026#34;)) // true fmt.Println(strings.HasSuffix(a, \u0026#34;llo\u0026#34;)) // true fmt.Println(strings.Index(a, \u0026#34;ll\u0026#34;)) // 2 fmt.Println(strings.Join([]string{\u0026#34;he\u0026#34;, \u0026#34;llo\u0026#34;}, \u0026#34;-\u0026#34;)) // he-llo fmt.Println(strings.Repeat(a, 2)) // hellohello fmt.Println(strings.Replace(a, \u0026#34;e\u0026#34;, \u0026#34;E\u0026#34;, -1)) // hEllo fmt.Println(strings.Split(\u0026#34;a-b-c\u0026#34;, \u0026#34;-\u0026#34;)) // [a b c] fmt.Println(strings.ToLower(a)) // hello fmt.Println(strings.ToUpper(a)) // HELLO fmt.Println(len(a)) // 5 b := \u0026#34;你好\u0026#34; fmt.Println(len(b)) // 6 } fmt # type point struct { x, y int } func main() { s := \u0026#34;hello\u0026#34; n := 123 p := point{1, 2} // %v: value fmt.Printf(\u0026#34;s=%v\\n\u0026#34;, s) // s=hello fmt.Printf(\u0026#34;n=%v\\n\u0026#34;, n) // n=123 fmt.Printf(\u0026#34;p=%v\\n\u0026#34;, p) // p={1 2} // %+v: value with field name fmt.Printf(\u0026#34;p=%+v\\n\u0026#34;, p) // p={x:1 y:2} // more detail fmt.Printf(\u0026#34;p=%#v\\n\u0026#34;, p) // p=main.point{x:1, y:2} f := 3.141592653 fmt.Println(f) // 3.141592653 fmt.Printf(\u0026#34;%.2f\\n\u0026#34;, f) // 3.14 } json # import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type userInfo struct { // you should make sure the uppercase of field name Name string Age int `json:\u0026#34;age\u0026#34;` Hobby []string } func main() { a := userInfo{Name: \u0026#34;wang\u0026#34;, Age: 18, Hobby: []string{\u0026#34;Golang\u0026#34;, \u0026#34;TypeScript\u0026#34;}} // Marshal: convert struct to json buf, err := json.Marshal(a) if err != nil { panic(err) } // hex code fmt.Println(buf) // [123 34 78 97...] // convert to string fmt.Println(string(buf)) // {\u0026#34;Name\u0026#34;:\u0026#34;wang\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;Hobby\u0026#34;:[\u0026#34;Golang\u0026#34;,\u0026#34;TypeScript\u0026#34;]} buf, err = json.MarshalIndent(a, \u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) if err != nil { panic(err) } fmt.Println(string(buf)) var b userInfo err = json.Unmarshal(buf, \u0026amp;b) if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, b) // main.userInfo{Name:\u0026#34;wang\u0026#34;, Age:18, Hobby:[]string{\u0026#34;Golang\u0026#34;, \u0026#34;TypeScript\u0026#34;}} } time # import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { now := time.Now() fmt.Println(now) // 2022-03-27 18:04:59.433297 +0800 CST m=+0.000087933 t := time.Date(2022, 3, 27, 1, 25, 36, 0, time.UTC) t2 := time.Date(2022, 3, 27, 2, 30, 36, 0, time.UTC) fmt.Println(t) // 2022-03-27 01:25:36 +0000 UTC fmt.Println(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute()) // 2022 March 27 1 25 fmt.Println(t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) // 2022-03-27 01:25:36 diff := t2.Sub(t) fmt.Println(diff) // 1h5m0s fmt.Println(diff.Minutes(), diff.Seconds()) // 65 3900 t3, err := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2022-03-27 01:25:36\u0026#34;) if err != nil { panic(err) } fmt.Println(t3 == t) // true fmt.Println(now.Unix()) // 1648738080 } strconv # import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { f, _ := strconv.ParseFloat(\u0026#34;1.234\u0026#34;, 64) fmt.Println(f) // 1.234 // str base precision n, _ := strconv.ParseInt(\u0026#34;111\u0026#34;, 10, 64) fmt.Println(n) // 111 n, _ = strconv.ParseInt(\u0026#34;0x1000\u0026#34;, 0, 64) fmt.Println(n) // 4096 // convert quickly n2, _ := strconv.Atoi(\u0026#34;123\u0026#34;) fmt.Println(n2) // 123 n2, err := strconv.Atoi(\u0026#34;AAA\u0026#34;) // invalid fmt.Println(n2, err) // 0 strconv.Atoi: parsing \u0026#34;AAA\u0026#34;: invalid syntax } os # import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; ) func main() { // go run example/20-env/main.go a b c d fmt.Println(os.Args) // [/var/folders/8p/n34xxfnx38dg8bv_x8l62t_m0000gn/T/go-build3406981276/b001/exe/main a b c d] fmt.Println(os.Getenv(\u0026#34;PATH\u0026#34;)) // /usr/local/go/bin... fmt.Println(os.Setenv(\u0026#34;AA\u0026#34;, \u0026#34;BB\u0026#34;)) buf, err := exec.Command(\u0026#34;grep\u0026#34;, \u0026#34;127.0.0.1\u0026#34;, \u0026#34;/etc/hosts\u0026#34;).CombinedOutput() if err != nil { panic(err) } fmt.Println(string(buf)) // 127.0.0.1 localhost } "},{"id":3,"href":"/posts/video-technology-101/","title":"Video Technology 101","section":"Blog","content":"Do you really understand the video technology? What is the frame rate, resolution, bit rate and their relationships? Do you know the parameters p and K in the terminology 1080p and 4K? Do you know how to describe the video quality? What is the Blu-ray Disc on earth? What the difference between the codec such as H.264/AVC, H.265/HEVC, AV1? You may notice the Apple ProRes in apple, so do you really understand what it for? Do you know the HDR and Dolby Vision? So why there are so many tailers such as .mp4, .mkv, .flv, etc?\nNow this Video Technology 101 will introduce them to you.\nAt the beginning, you should know the Gib（Gibibyte, 1Gib = 2^30 Bytes）and GB（Gigabyte, 1GB = 10^9 Bytes）is not the same thing.\nGB is normal used for the storage device capacity such as hard disk, SSD, and the software package size. Gib is normal used for the RAM, file system capacity and other storage that need to be represented in binary. Bandwidth # Generally, the unit of bandwidth is bps (or b/s), which means bits per second, indicating how many bits of information are transmitted per second. It is the abbreviation of bit per second. Normally, the bandwidth provided by the ISP is Mbps, so the true bandwidth you need to divided 8 convert to MBps which is usually used. The bandwidth is mainly focus on the transmission field.\nFrame # We often call the number of frames in 1 second as frame rate, which is usually represented by fps (Frames Per Second). So in the video field, the frame rate is normally 24fps、25fps、29.97fps and 30fps. Nowdays, 99 percent of films are still using 24fps.\nThe refresh rate of the screen # The refresh rate of the screen is the number of times the screen is refreshed per second. It is usually represented by Hz (Hertz). So in the video field, the refresh rate of the screen is normally 60Hz、75Hz、120Hz and 144Hz. If the frame rate is higher than the refresh rate, the redundant frames will be discarded.\nSo the frame rate of the phone is 30fps, the frame rate of the TV is 25/30 (commonly used), 50/60fps (motion lens), and the frame rate of the high-speed camera is 120/240fps (slow lens).\nThey are different concepts, the frame rate is focus on the video, but the refresh rate is focus on the device. Even your device has 120 Hz, but the playing video is 24fps, the display is still 24fps.\nThis reminds me of my childhood experience, when I was a child, I always played the CF game, every time the display didn\u0026rsquo;t fit, I would try to close the vertical synchronization technology to improve the smoothness. The vertical synchronization technology is used to make the display follows the video same frame rate.\nResolution # The resolution of a video/screen is the number of pixels in the horizontal and vertical directions.\nP or i? # eg. If the resolution of a video is 1920x1080, it means that the video has 1920 pixels in the horizontal direction and 1080 pixels in the vertical direction(In the 16:9 aspect ratio, 1080/9*16=1920). So it total has 1920 * 1080 = 2073600 pixels, whose resolution is 2073600.\nAnd the traditional we call this resolution as 1080p, which means the vertical resolution is 1080 and the p means progressive scan.\nThe difference between progressive scan(1080p) and interlaced scan(1080i):\nInterlaced scan: Each frame contains half of the lines making up the entire image: the first containing only the odd lines, and the second frame containing only the even lines. The two frames will be displayed in alternating modes, allowing the human brain to reconstruct the entire image into one without realizing that it’s made up of two frames. That really save the bandwidth, which means if the fps is 60, actually the interlaced scan only creates a total of 30 full frames. The monitor only displays half of what it recorded by the camera itself. Progressive scan: The pixels are displayed in a single frame. While the human eye can’t usually detect the 1080i technology, 1080p has it clear advantages when it comes to scenes with lots of motion. In this case, an object in fast motion can have moved from the first field to the second, creating an almost blurry or glitchy image for the viewer.\nCompare the 1080i and 720p source: https://youtu.be/Avvh0iH2xSg Refer to the industry standard:\n480p SD（Standard Definition） 720p HD（High Definition） 1080p HD or FHD （Full High Definition） 2160p 4k UHD（Ultra High Definition） 4320p 8k UHD K # Now we can talk about the K, differ from the P and i in the vertical direction, the K is used to describe the number of horizontal pixel lines in the cinema level. In this case, you can just call the 1920x1080 as 1.9K or 2K. The 3840x2160 is the 4K of TV standard（Actually name is UHD: Ultra High Definition）, and the 4096×2160 is also the 4K in the cinema.\nNormally, there is not the fixed resolution of 4K or 2K, it just about the horizontal pixels lines.\nAspect Ratio # The aspect ratio of a video is the ratio of the width to the height. The normal is 16:9 or 4:3. For the resolution below 480p(SD), the aspect ratio normally is 4:3. The resolution is (480 / 3 * 4 = 640 ) 640x480.\nBit Rate / Data Rate # It is also called the data rate, which is more focus on the data compared to the bit rate on the binary data.\nThe size of data produced by the encoder per second, in kbps. For example, 100kbps means that the encoder generates 100kb of data per second. Most of the time, we don\u0026rsquo;t use the data size to describe it because every video duration is different. So we use the data rate which means the size of data produced by the encoder per second or the size of data in this video per second(1 Mbps = 1000 kbps). We can just estimate the data rate of a 2-hours film whose size is 35G and its bit rate is 35×1024×1024×8/2/3600=40777kbps=41Mbps. The bit rate is higher, the video image will be more detailed.\nThe data rate can be also categorized into Variable Bit-Rate (VBR) and Constant Bit-Rate (CBR).\nVBR: The data rate is not fixed, it will change according to the content of the video. Often used in the video website. CBR: The data rate is fixed, the common scenario is the streaming or TV broadcast. There is a question: A video file size is 10 M, the playback duration is 2 minutes 21 seconds, a 10 Mbps network can shared by how many people? Answer is in the end.\nRelationship between frame rate, resolution, and bit rate # How to describe the video quality # The image quality is usually described by PSNR (Peak signal-to-noise ratio), which means the ratio of the maximum signal to the noise. The image compressed the PSNR near 50dB means the image is very clear, and keep beyond 35 dB is acceptable.\nFor the video quality, we can use the VMAF (Video Multi-Method Assessment Fusion) from netflix to describe it.\nUnderstand the relationship # Different kinds of video requires different data rate. eg, the animation video has many blocks color, so it requires less than sport.\nSo when we center around the data rate:\nWhen the data rate is flexible, if the frame rate is higher, the frames in every second will be more, so the encoder will need more data to encode the frames. The video size will be larger.\nWhen the data rate is fixed, if the resolution is higher, the number of pixels will be more, but the encoder generates data is fixed, so the video will be more blurry. If the resolution is lower, the video will be more clear.\nYou can just refer to the netflix\u0026rsquo;s tech blog:\nAt each resolution, the quality of the encode monotonically increases with the bitrate, but the curve starts flattening out (eg A and B) when the bitrate goes above some threshold. This is because every resolution has an upper limit in the perceptual quality it can produce. When a video gets downsampled to a low resolution for encoding and later upsampled to full resolution for display, its high frequency components get lost in the process.\nOn the other hand, a high-resolution encode may produce a quality lower than the one produced by encoding at the same bitrate but at a lower resolution (see C and D). This is because encoding more pixels with lower precision can produce a worse picture than encoding less pixels at higher precision combined with upsampling and interpolation. Furthermore, at very low bitrates the encoding overhead associated with every fixed-size coding block starts to dominate in the bitrate consumption, leaving very few bits for encoding the actual signal. Encoding at high resolution at insufficient bitrate would produce encoding artifacts such as blocking, ringing and contouring. Encoding artifacts are typically more annoying and visible than blurring introduced by downscaling (before the encode) then upsampling at the member’s device.\nFrom netflix\u0026amp;rsquo;s tech blog If we collect all these regions from all the resolutions available, they collectively form a boundary called convex hull. Ideally, we want to operate exactly at the convex hull, but due to practical constraints, we would like to select bitrate-resolution pairs that are as close to the convex hull as possible.\nSo on the video website, if your device does not support higher resolution, but you have the higher bandwidth, the video website will offer you more higher bit rate video to improve your experience.\nBlu-ray Disc # As we can see in many video website, there is always a option named Blu-ray Disc. In fact, it means uses the blue laser to read and write, it is just a kind of storage, not a format of video resolution. Which is the successor of the DVD(720×480) and VCD(320×240).\nIn 2015, the Blu-ray Disc Association launched Ultra HD Blu-ray, with a capacity of up to 100GB and support for 4K UHD video at a resolution of 3840×2160 via H.265/HEVC.\nAnd in 2016, the Blu-ray Disc Association launched Ultra HD Blu-ray standard, which requires the HDR10, and can set the Dolby Vision as the optional.\nEncode is efficient # But if a video has a high resolution and frame rate and data rate, the video size will be very large. When you play it via internet, which is very waste of bandwidth. At this time, you will need to compress the video through some encode methods.\nThe x axis is data rate If you use different encode method, you will get a different data rate. But the cost is compression and poor compatibility.\nSo what is the codec? # Nowadays, we can shot the image with the camera, and then they are encoded via encoder and saved in your device, finally you can play it via the decoder, through the decoder, the compressed video data is output as non-compressed color data, such as YUV420P, RGB, etc.\nThe codec is the abbreviation of the encoder and decoder.\nAnd the common used tailers .mp4, .mkv, .flv have nothing to do with the encode. You can just treat them as the container. Every container has a lot of different encoded of video, audio, subtitle and other data.\nH.264/AVC # H.264 is the most common codec for video compression, it was released in 2003 by MPEG (Moving Picture Experts Group). It is the successor of the MPEG-2. It has a lot of different names, such as:\nH.264 AVC(Advanced Video Coding) MPEG-4 Part 10 H.265/HEVC # H.265 HEVC（High Efficiency Video Coding） MPEG-H Part 2 H.265 is the successor of the H.264. It is the most common codec for video compression. The main advantage is that it can compress the video more efficiently, which means the same quality video can be compressed to a smaller size as well as save the 50% of the bit rate at the same quality of video. Besides, the best part of H.265 is that it can support the resolution beyond 4K, eg 8K. eg, the Dolby Vision is almost codec in H.265.\nBut it needs the patent fee.\nH.266/VVC # It was released in 2020, the compression efficiency of H.266/VVC is 50% higher than H.265/HEVC.\nVP8/9 # They are created by Google and free of charge.\nAV1 # The AV1(AOMedia Video 1) is released in 2018 by Alliance for Open Media which is composed of Apple、Amazon、Cisco、Google、Intel、Microsoft、Mozilla and Netflix, and it can be more efficient about 20% than VP9.\nApple ProRes # Different from the codec before, Apple ProRes is the Intra-compression, not the Inter-compression.\nAs we can see, the intra-compression will save a lot of frame, which is larger than the inter-compression. But it has a lot of advantages:\nYou don\u0026rsquo;t need to compute other frames, so it has lower requirements for the device. You can do more editing on the video. For better understanding, you should know the IPB frames in inter-compression. In the video, every frame is a picture. But when saving them, we should consider compressing them.\nI: Intra-coded frame, which means the frame is independent, only use the current frame to encode. P: Predictive-coded frame, which means the frame is used the previous I or P frame to predict the current frame. B: Bi-directional predictive-coded frame, which means the frame is used the previous I or P frame and next P frame to predict the current frame. In the video encoding sequence, GOP (Group of picture) refers to the distance between two I frames, and Reference (Reference period) refers to the distance between two P frames. The number of bytes occupied by an I frame is greater than that of a P frame, and the number of bytes occupied by a P frame is greater than that of a B frame.\nSo in the same bit rate, the larger the GOP value, the more P and B frames, the more bytes occupied by each I, P, and B frames, and the better the image quality. The larger the Reference value, the more B frames, the same is true.\nIn a GOP, the largest frame is the I frame, so relatively speaking, the larger the gop_size is, the better the image quality will be, but in the decoding end, it must start from the first I frame received to correctly decode the original image, otherwise it will not be able to decode correctly. In the technique of improving video quality, there is also a technique of using more B frames. Generally, the compression rate of I is 7 (similar to JPG), P is 20, and B can reach 50. It can be seen that using B frames can save a lot of space, and the saved space can be used to save more I frames, so that better image quality can be provided at the same bit rate. So we should set the size of gop_size according to different business scenarios to get better video quality.\nNormally, there is 1 P frame after the I frame, and 2～3 B frames between the I and P frames, and 2～3 B frames between the two P frames. B frames transmit the difference information between it and the I or P frame, or the difference information between the P frame and the subsequent P frame or I frame, or the difference information between it and the front and rear I, P frames or P, P frames average value. When the main content changes more, the frame value between two I frames is smaller; when the main content changes less, the interval of I frames can be set larger.\nSo the order of encoding and display is not the same: The upper is encoding order, the lower is display order Color Depth # The color depth is the number of bits used to represent the color of a pixel. In the RGB, the common color depth is 8-bit, 10-bit, 12-bit.\nIn the 8-bit color depth, the color is represented by 256 levels, which means the color is represented by 256 different shades of gray. So the total number of colors is 256^3 = 16777216.\nBesides, the engineers find that the human eyes are sensitive to the brightness, it is not necessary to store all the color signals. We can allocate more bandwidth to the black-white signal (referred to as \u0026ldquo;brightness\u0026rdquo;) and allocate less bandwidth to the color signal (referred to as \u0026ldquo;chroma\u0026rdquo;). So, there is YUV. The Y means Brightness Luma, UV means Chroma.\nFor more info about images, I will introduce them in the article Image Technology 101.\nHDR # The HDR is an emerging concept in the video field. It is the abbreviation of High Dynamic Range. Compared with the SDR(Standard Dynamic Range), the HDR can display more color ranges and lightness.\nHDR also has a lot of different standards, such as:\nHDR10 HLG HDR10+ Dolby Vision HDR10 # HDR10 is an open standard announced by the American Consumer Technology Association in 2015. It does not require any copyright fees, and the \u0026ldquo;10\u0026rdquo; comes from the 10-bit color depth. In addition to the color depth, HDR10 recommends using a wide color gamut Rec.2020, PQ (SMTPE ST2084) absolute display, and static data processing. It can support the 1000 nit.\nThe HDR10 is mainly designed for the streaming media, which is not suitable for the film.\nHLG # But for a non HDR device such as TV, if it displays the HDR10 video, it will be very dark. The maximum brightness is 300 nit, so the HLG is designed for this. The NHK and BBC are the main supporters of the HLG, which can let the device display the 1000 nit differentiatedly.\nDolby Vision # The Dolby Vision is created by the Dolby lab, it uses the 12-bit color depth, and the color gamut is Rec.2020. It can support the 10000 nit.\nBesides, the dynamic metadata is also supported, which can adjust the color and brightness partially, emphasizing the contrast progressively.\nHDR10+ # HDR10+ is created by Samsung, which is also use the dynamic metadata.\nVideo Format # Note: the video format is different from the video codec.\nVideo format is the way to package the video data, audio data, subtitle data, etc. into a file. The file format is the video format, if a video file is packaged in a certain format, then its file suffix name will usually reflect it. The normal video format is:\nAVI (.avi) ASF (.asf) WMV (.wmv) QuickTime (.mov) MPEG (.mpg / .mpeg) MP4 (.mp4) m2ts (.m2ts / .mts ) Matroska (.mkv / .mks / .mka ) TS FLV AVI # Audio Video Interleaved, which is nearly a outdated technology, the file structure is divided into header, body and index 3 parts. The image data and sound data are stored in the body, and the index can be used to find the position of the image data and sound data. AVI itself only provides this framework, the internal image data and sound data format can be arbitrary encoding form. Because the index is placed at the end of the file, it is not possible to play the network media. For example, if you download the AVI file from the network, if it is not downloaded completely, it is difficult to play normally.\nFLV # FLV is an Adobe-released packaging format that can be used for both live streaming and on-demand scenarios. Its packaging format is extremely simple, with each FLVTAG being an independent entity.\nThe FLV packaging format consists of a file header (9 bytes) and many tags (FLV body). Each tag contains audio and video data, and each tag has a preTagSize field that indicates the size of the previous tag. The structure of FLV is shown below.\nAnd the tags can be divided into 3 types:\nVideo: Video Tag Audio: Audio Tag Script: Script Tag(Metadata Tag) A normal FLV file consists of a header, a script tag, and several video and audio tags.\nAnd the header is composed of 9 bytes, the first 3 bytes are the file type, always \u0026ldquo;FLV\u0026rdquo;, which is (0x46 F 0x4C L 0x56 V). The 4th byte is the version number. The 5th byte is the stream information, the last bit if is 0x01 means video exists, the last bit is 0x04 means audio exists, 0x01 | 0x04（0x05） means both video and audio exist, others are 0. The last 4 bytes represent the length of the FLV header 3+1+1+4=9.\nM3U8 # M3U8 is a common streaming media format, mainly in the form of a file list, supporting both live streaming and on-demand.\n#EXTM3U // m3u8 header #EXT-X-VERSION:3 #EXT-X-TARGETDURATION:4 #EXT-X-MEDIA-SEQUENCE:0 # if not EXT-X-ENDLIST the sequences will always be played from the last 3 sequences. #EXTINF:3.760000, out0.ts #EXTINF:1.880000, out1.ts #EXTINF:1.760000, out2.ts #EXTINF:1.040000, out3.ts #EXTINF:1.560000, out4.ts FFmpeg has built-in HLS packaging parameters, using the HLS format can perform HLS packaging.\nMP4 # MP4 actually represents MPEG-4 Part 14. It is only the 14th part of the MPEG standard. It is mainly based on the ISO/IEC standard. MP4 mainly aims to achieve fast forward and fast backward, and the effect of downloading while playing. It is the most common video format in the industry.\nMP4 file format is a very open container, almost able to describe all media structures. The media description and media data in the MP4 file are separated, and the organization of media data is also very free, not necessarily in chronological order, and media data can be directly referenced from other files. At the same time, MP4 also supports streaming media. MP4 is widely used for packaging h.264 video and AAC audio.\nMP4 data is all in the box（atom in QuickTime）, which means that the MP4 file is composed of several boxes, each box has a type and length, and can be understood as a data object block.\nA box can contain another box, this box is called container box.\nA MP4 file will have a ftyp type box as the flag of MP4 format and contain some information about the file; Then there will be a moov type box (Movie Box), which is a container box, the sub-box contains the media metadata information. moov in the MP4 file is also unique, moov will contain 1 mvhd and several trak. mvhd is the header box, which usually appears as the first sub-box of moov. mvhd defines the characteristics of the entire movie, usually containing media-independent information such as playback duration, creation time, etc. The media data of the MP4 file is contained in the mdat type box (Midia Data Box), this type of box is also a container box, can have multiple, can also be none (when the media data is all referenced from other files), the media data structure is described by metadata. The normal MP4 file playback requires that the ftyp and moov boxes are loaded completely, and some frames of the mdat box are downloaded, before it can start playing.\nOn top of that, the fMP4 can be fragmented, which means that the fMP4 does not need a moov Box to initialize, it can just contains some tracks, the metadata is in the moof box.\nTS # The Transport Stream file is a streaming media format, which is widely used in the live streaming field. It is a container format that can be used for both live streaming and on-demand. The suffix of the TS stream is .ts, .mpg or .mpeg. The HLS protocol is based on the TS format.\nThe difference between fMP4 and ts # The ts file does not provide information about the duration, so you cannot perform seek operations on the ts file. fMP4 provides information about the duration, so you can seek to a specific position. MPEG2-TS is a format that requires the video stream to be independently decodable from any segment.\nStreaming video format # We often call the flv, rmvb, mov, asf as the streaming video format. That is because the streaming file can be decoded while it is being transmitted, and it does not need the whole file to start. The characteristics are that there is file header information (this is not necessary) and the middle is packaged, which can be parsed directly by packet, and the file can be of any size, without the need to pass through the index packet. FLV, MPEG, RMVB, etc. can be parsed directly by packet, while MP4, AVI must rely on the index table, and the start must be fixed, if the index table is at the end, it is not possible to parse.\nBonus:\nThe streaming process is as follows:\nThe host uses rtmp to push the stream, and then pushes it to the cdn. The cdn supports the audience to use http-flv, hls, rtmp three ways to pull the stream. The common live streaming app uses http-flv. These protocols are like containers, they carry the packaging, rtmp and http-flv carry flv, hls carries m3u8 and ts. m3u8, ts inside are audio and video. The data size will be TS \u0026gt; MP4 \u0026gt; FLV.\nThe answer of the question # A video file size is 10 M, the playback duration is 2 minutes 21 seconds, a 10 Mbps network can shared by how many people?\nIt bit rate is 10 * 1024 * 1024 * 8 / (2 * 60 + 21) = 594936.73759 bps\n10* 1024 * 1024 / 594936.73759 = 17.215 people\nSo the answer is 17 people.\nRecommend the bit rate of the video:\nbitrate = w * h * fps * factor(the streaming on phone is 0.08)\neg. 720 X 480 25fps the recommend bit rate is 675Kb/s ( 720 * 480 * 25 * 0.08 )/1024 = 675Kb/s ，so the 100M bandwidth can shared by 100/0.675≈148 people.\nHow about the device? # For the more info about device, such as nit, ppi, refresh rate, etc. I will write a new article about it.\nReference # https://tagarno.com/blog/1080p-vs-1080-on-digital-microscopes/\nhttps://www-file.huawei.com/-/media/corporate/pdf/ilab/30-cn.pdf\nhttps://netflixtechblog.com/per-title-encode-optimization-7e99442b62a2\nhttps://netflixtechblog.com/optimized-shot-based-encodes-for-4k-now-streaming-47b516b10bbb\nhttps://netflixtechblog.com/optimized-shot-based-encodes-now-streaming-4b9464204830\nhttps://sspai.com/post/66001\nhttps://sspai.com/post/58012\nhttps://en.wikipedia.org/wiki/Video_Multimethod_Assessment_Fusion\nhttps://www.zhihu.com/question/265520537\nhttps://github.com/CharonChui/AndroidNote/tree/master/VideoDevelopment\nhttps://www.easemob.com/news/3614\nhttp://www.52im.net/thread-235-1-1.html\n"},{"id":4,"href":"/posts/the-main-kind-of-message-queue/","title":"The Main Kind of Message Queue","section":"Blog","content":"Message queues are a form of asynchronous service-to-service communication. They are important in enhancing a system\u0026rsquo;s scalability, reliability, and maintainability.\nNote: this article is reprint from the article : The System Design Cheat Sheet: Message Queues - ActiveMQ, RabbitMQ, Kafka, ZeroMQ, the author is Aleksandr Gavrilenko who I really appreciate.\nThe list of key features:\nAsynchronous Communication: Allows different parts of a system to communicate without needing to respond immediately, leading to more efficient use of resources. Decoupling of Services: Enables services to operate independently, reducing the system\u0026rsquo;s complexity and enhancing maintainability and scalability. Load Balancing: Distributes messages evenly across different services or workers, helping to manage workload and improve system performance. Order Preservation: Some message queues can ensure that messages are processed in the order they are sent, which is crucial for specific applications. Scalability: Facilitates easy scaling of applications by adding more consumers or resources to handle increased message flow. Rate Limiting and Throttling: Controls the rate at which messages are processed, which is important for managing resources and preventing system overloads. Fan-out Capability: Message queues often include a fan-out mechanism, which allows a single message to be delivered to multiple consumers or services simultaneously. Data Persistence: Offers the ability to store messages on disk or in memory until they are successfully processed, ensuring data is not lost in case of system failures. Message Filtering and Routing: Allows messages to be routed or filtered based on specific criteria or content, enabling more targeted and efficient processing. Components # In the context of message queues, the concepts of producers, consumers, and messages form the core of how these systems operate.\nProducer is an application or service responsible for creating and sending messages to the message queue. It does not need to be aware of who will process the message or when it will be processed. Consumer is an application or service that retrieves and processes messages from the queue. It acts on the data sent by producers. Messages are the data packets sent from producers to consumers. They can vary in size and format, ranging from simple text strings to complex data structures like JSON or XML. Message Broker is a middleware tool that facilitates communication between different applications or services by receiving messages from a sender and routing them to the appropriate receiver. It typically provides features like message queuing, routing, transformation, and delivery assurance. Messaging Models # Globally, there are two types of messaging: Point-to-Point and Publish-Subscribe.\nPoint-to-Point # Messages sent by a producer are placed in a queue and are consumed by a single consumer. It ensures that each message is processed only once by one receiver.\nPublish-Subscribe # Messages are published to a specific topic rather than a queue. Multiple consumers can subscribe to a topic and receive messages broadcast to that topic.\nHowever, some messaging protocols and the brokers that support them use an additional Exchange component for routing. In that case, messages are published to an exchange in the broker first. The Exchange, acting as the routing agent, forwards these messages to the appropriate queue using its routing rules.\nThe following exchange operating modes are distinguished:\nDirect Exchange # The message is routed to the queues whose binding key matches the message\u0026rsquo;s routing key.\nTopic Exchange # The topic exchange will perform a wildcard match between the routing key and the routing pattern specified in the binding to publish messages to the queue.\nFanout exchange # A message sent to a fan-out exchange is copied and forwarded to all the queues bound to the exchange.\nHeader exchange # Header exchanges will use the message header attributes for routing.\nDead letter # Dead letter queues collect messages that couldn’t be processed successfully for various reasons like processing errors, message expiration, or delivery issues.\nProtocols # Message brokers are responsible for delivering messages from producers to consumers. They use specific protocols that define the rules and formats for messaging.\nThe most popular protocols in this domain are:\nAMQP (Advanced Message Queuing Protocol) # A binary protocol designed for message-oriented middleware with robustness, security, and interoperability. Ideal for complex and reliable enterprise messaging systems.\nUse Cases: Enterprise applications, financial systems, and business processes Messaging Model: point-to-point, publish-subscribe Security: TLS/SSL, SASL, PLAIN Addressing: Uses exchange and queue-based addressing with routing capabilities Architecture: Broker-based MQTT (Message Queuing Telemetry Transport) # A lightweight, publish-subscribe network protocol optimized for high-latency or unreliable networks, ideal for IoT scenarios.\nUse Cases: IoT devices, home automation, mobile messaging applications Messaging Model: publish-subscribe Security: TLS/SSL, SASL, PLAIN Addressing: It uses topic-based addressing where messages are published to topics Architecture: Broker-based JMS (Java Message Service) # A Java-based messaging standard offers interfaces for point-to-point and publish-subscribe messaging patterns in Java applications.\nUse Cases: Enterprise Java applications, integration of multiple Java-based systems Messaging Model: point-to-point, publish-subscribe Security: Relies on the underlying Java EE security model Addressing: Uses JNDI for locating queues and topics Architecture: It is often implemented on top of enterprise service buses or application servers. STOMP (Simple Text Oriented Messaging Protocol) # A simple, text-based protocol that is easy to implement, suitable for scenarios where advanced messaging features are not a priority.\nUse Cases: Rapid development environments and simple messaging applications Messaging Model: point-to-point, publish-subscribe Security: PLAIN; relies on the underlying transport protocol for encryption Addressing: Frame-based with headers for destination, content type, etc. Architecture: Broker-based Kafka Protocol # Associated with Apache Kafka, a distributed streaming platform capable of handling high-throughput data streams.\nUse Cases: Real-time analytics, data pipelines, stream processing applications Messaging Model: publish-subscribe Security: SSL/TLS, SASL Addressing: Topic-based with partitioning for scalability. Architecture: Distributed system architecture with brokers and coordination. ZMTP (ZeroMQ Message Transport Protocol) # The underlying protocol for ZeroMQ is a high-performance asynchronous messaging library for building scalable, distributed applications.\nUse Cases: High-throughput, low-latency applications, microservices architecture. Messaging Model: request-reply, publish-subscribe, pipeline, exclusive pair, etc. Security: PLAIN, CurveZMQ, and ZAP Addressing: Flexible addressing using sockets Architecture: Library-based, enabling a brokerless design or various brokered configurations Brokers # ActiveMQ RabbitMQ Kafka ZeroMQ Written in Java Erlang Scala C++ Cross-platform yes yes yes yes Opensource yes yes yes yes Multiple languages yes yes yes yes Protocols AMQP, AUTO, MQTT, OpenWire, REST, RSS and Atom, Stomp, WSIF, WS Notification, XMPP, WebSocket AMQP, STOMP, MQTT, HTTP Binary over TCP TCP, UDP, inproc, PGM, IPC, TIPC, NORM, SOCKS5 QoS at-least-once at-most-once at-least-once at-most-once at-least-once at-most-once exactly-once at-least-once at-most-once Message patterns Queue, Pub-Sub Queue, Pub-Sub, RPC Pub-Sub Request-Reply, Pub-Sub, Push-Pull, Dealer and Router, Pair, Exclusive Pair, etc Persistence Disk, DB Mem, Disk Disk - ActiveMQ # Apache ActiveMQ is an open-source, multi-protocol, Java-based message broker designed by Apache. Architecture Features:\nMulti-Protocol Support: ActiveMQ supports a wide range of messaging protocols, including AMQP, MQTT, OpenWire, STOMP, and JMS (Java Message Service), making it highly adaptable to different client requirements. JMS Provider: As a JMS provider, ActiveMQ complies with the JMS API, which allows loose coupling, asynchronous communication, and reliability for Java applications. Broker-Based Architecture: ActiveMQ uses a broker architecture, where a central broker handles message routing, delivery, and queuing. Pluggable Persistence and Storage: Offers options for message persistence, including database storage (for durability) and file-system storage, supporting both high-performance and high-durability scenarios. Clustering and Load Balancing: Supports clustering and load balancing. Client-Side Acknowledgements: Provides different options for message acknowledgments, enhancing message reliability. Scenarios: # Enterprise Integration: Ideal for integrating different systems within an enterprise, mainly where Java-based or multiple protocols are used. Asynchronous Communication: Useful in scenarios where decoupling system components is essential, like in microservices architecture. Distributed Computing: Facilitates message communication in distributed systems, ensuring data consistency and reliability. IoT Communication: Can be used in IoT setups, especially where MQTT is preferred. Pros: # Versatility in Protocol Support: One of the key strengths of ActiveMQ is its support for multiple protocols, offering flexibility in various environments. Reliability and Durability: Provides reliable message delivery and durable storage. Clustering and High Availability: Supports clustering for load balancing and high availability. JMS Support: Comprehensive support for the JMS API makes it a strong candidate for Java-based systems. Cons: # Performance: While robust, ActiveMQ may not match the performance of some newer message brokers, especially in scenarios with extremely high throughput requirements. Complex Configuration: Can be difficult to configure and manage, especially in clustered setups. Resource Usage: Might require significant resources, particularly under heavy load, for optimal performance. Management and Monitoring: While it offers management tools, they might be less comprehensive and user-friendly than those of some newer brokers. RabbitMQ # RabbitMQ is an open-source message broker software known as a message-oriented middleware. It\u0026rsquo;s written in Erlang and is built on the Open Telecom Platform framework for clustering and failover. RabbitMQ is widely used for handling asynchronous processing, enabling communication between distributed systems through various messaging protocols, primarily AMQP (Advanced Message Queuing Protocol).\nSupport for Multiple Messaging Protocols: While RabbitMQ is primarily known for AMQP, it also supports MQTT, STOMP, and other protocols through plugins. Producer-Consumer Model: It follows the standard producer-consumer pattern, where producers send messages and consumers receive them, with RabbitMQ acting as the broker. Exchange-Queue Binding: Messages in RabbitMQ are published to exchanges, which are then routed to bound queues based on routing keys and patterns. Durable and Transient Messaging: Supports durable (persistent on disk) and transient (in-memory) messages. Clustering and High Availability: RabbitMQ can be clustered for high availability and scalability, distributing queues among multiple nodes. Flexible Routing: Offers several exchange types (like direct, topic, fanout, and headers) for diverse routing logic. Pluggable Authentication and Authorization: Supports pluggable authentication modules, including LDAP. Scenarios: # Asynchronous Processing: Ideal for decoupling heavy processing tasks in web applications, ensuring responsive user interfaces. Inter-Service Communication: Used in a microservices architecture for communicating between services. Task Queues: Well-suited for handling background tasks like sending emails or processing images. Distributed Systems: Facilitates message communication in distributed systems, maintaining consistency and reliability. Pros: # Reliability: RabbitMQ is known for its reliability and ability to ensure message delivery. Flexible Routing Capabilities: Its routing capabilities are more advanced than those of many message brokers. Scalability and High Availability: Supports scalable clustering, which is crucial for large-scale applications. Wide Protocol Support: The ability to support multiple messaging protocols increases adaptability. Management Interface: Comes with a user-friendly management interface, which simplifies monitoring and managing message flows. Cons: # Memory Usage: It can be memory-intensive, especially under heavy load, requiring proper monitoring and tuning. Erlang Dependency: Being built on Erlang, it introduces an additional technology stack that teams might need to familiarize themselves with. Performance Under High Load: While generally performant, performance tuning might be necessary under extremely high loads or in complex routing scenarios. Kafka # Apache Kafka is an open-source stream-processing software platform developed by LinkedIn and later donated to the Apache Software Foundation. It\u0026rsquo;s designed to handle high volumes of data and enable real-time data processing. Kafka is a distributed, partitioned, and replicated commit log service.\nArchitecture Features:\nProducer-Consumer Model: Kafka operates on a producer-consumer model. Producers publish messages to Kafka topics, and consumers subscribe to those topics to read the messages. Topics and Partitions: Data in Kafka is categorized into topics. Each topic can be split into partitions, allowing for parallel data processing. Partitions also enable Kafka to scale horizontally. Distributed System: Kafka runs as a cluster on one or more servers, and the Kafka cluster stores streams of records in categories called topics. Replication: Kafka replicates data across multiple nodes (brokers) to ensure fault tolerance. If a node fails, data can be retrieved from other nodes. Zookeeper Coordination: Kafka uses ZooKeeper for cluster management and coordination, ensuring consistency across the cluster. Commit Log Storage: Kafka stores all data as a sequence of records (or a commit log), providing durable message storage. Scenarios # Real-Time Data Processing: Ideal for real-time analytics and monitoring systems where quick data processing is crucial. Event Sourcing: Suitable for recording the sequence of events in applications. Log Aggregation: Effective for collecting and processing logs from multiple services. Stream Processing: Can be used for complex stream processing tasks like aggregating data streams or real-time filtering. Integration with Big Data Technologies: Often used with big data tools for data processing and analysis. Pros # High Throughput: Can handle high volumes of data and many simultaneous transactions. Scalability: Easily scalable both horizontally and vertically. Durability and Reliability: Provides durable storage of messages. Fault Tolerance: High fault tolerance due to data replication. Flexibility: Can be used for a wide range of use cases, from messaging systems to activity tracking and log aggregation. Cons # Complexity: Setup and management can be complex, especially for large clusters. Resource Intensive: Can be resource-intensive, requiring a good amount of memory and CPU. Dependency on ZooKeeper: Relies on ZooKeeper for coordination, adding an extra component to manage. Latency: While fast, it may not be suitable for use cases requiring extremely low latency. ZeroMQ # ZeroMQ (ØMQ, 0MQ, or ZMQ) is a high-performance asynchronous messaging library for distributed or concurrent applications. It\u0026rsquo;s not a message broker but a library that abstracts socket communication into a message-oriented middleware, making it easier to implement complex communication patterns in a scalable way. Developed in C++, ZeroMQ can be used in various programming languages through bindings.\nArchitecture Features:\nSocket-Based Communication: ZeroMQ uses sockets that abstract away the complexity of low-level network programming. These sockets can be used in patterns like publish-subscribe, request-reply, and fan-out. Brokerless Design: Unlike traditional message brokers, ZeroMQ is brokerless, allowing direct communication between endpoints without requiring a central message broker. Scalable Multithreading: Provides a way to manage multiple threads with socket-based communication, facilitating scalable I/O bound operations. Asynchronous I/O: Supports non-blocking, asynchronous I/O operations, which is critical for building responsive, high-performance applications. Language Agnostic: Offers bindings for multiple programming languages, making it accessible from different technology stacks. Scenarios # Microservices: Ideal for inter-service communication in a microservices architecture. High-Performance Computing: Used in parallel processing systems where performance is critical. Distributed Systems: Suitable for scenarios requiring complex, distributed messaging patterns without the overhead of a broker. Real-time Communication:** Effective in systems needing low-latency, real-time data exchange**. Pros # High Performance: ZeroMQ is designed for high throughput and low latency, making it suitable for performance-critical applications. Flexibility in Messaging Patterns: Supports various messaging patterns, providing flexibility for different communication scenarios. Reduced Complexity: The brokerless architecture simplifies deployment and reduces system complexity. Scalability: Facilitates easy scaling of applications with its efficient handling of multiple connections. Lightweight: Less resource-intensive compared to traditional messaging brokers. Cons # No Built-in Durability or Message Persistence: Lacks built-in message durability or persistence support, which must be handled externally. Requires Explicit Management of Connections: Developers need to manage connections, retries, and error handling, which can add complexity to application logic. Lack of a Central Broker: While this can be an advantage, it also means needing more centralized management, monitoring, and control over the messaging system. "},{"id":5,"href":"/posts/the-method-to-manage-traffic/","title":"The Method to Manage Traffic","section":"Blog","content":"Do you know the basic method to manage the traffic? There are four methods: Load Balancers, Reverse Proxies, Forward Proxies, and API Gateways. And they have different features and usage scenarios.\nNote: this article is reprint from the article : The System Design Cheat Sheet: Load Balancer, Reverse Proxy, Forward Proxy, API Gateway, the author is Aleksandr Gavrilenko who I really appreciate.\nLoad Balancers # A load balancer is a specialized network device or software application designed to optimize the distribution of incoming network traffic across multiple servers or resources, which prevents any single server from becoming a bottleneck. Load balancers achieve this by employing various algorithms to route incoming requests to the most appropriate server intelligently.\nLoad balancers can also be used within a data center to balance traffic between different components of an application, such as microservices.\nTypes # Based on specific needs, load balancing can be performed at the network/transport and application layer of the OSI layers:\nLayer 4\nOperate at the Transport layer of the OSI model, dealing primarily with TCP and UDP packets. This load balancers route traffic based on source and destination IP addresses and ports. They are relatively simple, fast, and effective for routing user requests to available servers without inspecting the content of the packets. Used when needed: High-speed data routing Simple load distribution based on IP and port Layer 7\nOperate at the Application layer and can inspect the data packets\u0026rsquo; content. This allows them to make more intelligent routing decisions based on HTTP headers, cookies, or application-specific data. Used when needed: SSL termination Content-based routing Application-level decisions like directing users to a specific version of a web page Layer 2/3\nThough less common, some load balancers operate at the Data Link (Layer 2) and Network (Layer 3) levels. These load balancers are generally used in specialized scenarios requiring packet-level routing. Used when needed:\nMAC address-based routing (Layer 2) IP-based routing without port considerations (Layer 3) GSLB(Global Server Load Balancer) # Global Server Load Balancing, is designed to distribute user traffic across multiple geographically dispersed data centers. GSLB is primarily based on the Domain Name System (DNS). Based on many factors, the DNS server returns the IP address of the most suitable data center.\nUse Cases # DNS round-robin: Distributes traffic between all data centers in multiple locations. Geolocation-based DNS: Detect users\u0026rsquo; locations and route traffic to the nearest data center to lower latency. Failover: Send all traffic to a primary data center, but redirect traffic to a secondary data center if the primary becomes inaccessible. Popular Solutions: F5 BIG-IP DNS, Citrix ADC, AWS Route 53, Cloudflare Load Balancer\nLocal Load Balancers # A Local Load Balancer operates within a single data center or cloud region, primarily focusing on distributing incoming traffic among local servers. Its main goal is to optimize resource utilization, maximize throughput, and minimize response time.\nPopular Solutions: HAProxy, NGINX Load Balancer, AWS Elastic Load Balancer (ELB), F5 BIG-IP Local Traffic Manager (LTM)\nLoad-balancing algorithms # Different algorithms offer various advantages and trade-offs, making them more or less suitable for particular scenarios.\nRound Robin # Distributes incoming requests sequentially and evenly across all available servers cyclically.\nSticky Round Robin # A hybrid approach that combines Round Robin distribution with session persistence, ensuring that once a user session is established, it remains on the assigned server.\nWeighted Round Robin # Similar to Round Robin, each server is assigned a weighted score, affecting the distribution of requests. Servers with higher weights receive a larger share of the incoming requests.\nIP/URL Hash # This algorithm hashes the client\u0026rsquo;s IP address to determine the server for routing the request, ensuring session persistence by always directing a specific client\u0026rsquo;s requests to the same server.\nDynamic Algorithms # Least Time # Requests are redirected to the server with the fastest average response time, balancing server load and user experience.\nLeast Connections # Requests are redirected to the server with the fewest active connections, requiring additional computation by the load balancer to identify less-busy servers.\nReverse Proxy # The reverse proxy is a server that sits between clients and a web server, directing incoming requests to appropriate backend servers. The key difference between a reverse proxy and a load balancer is their primary focus. While both can distribute traffic across multiple servers, a load balancer is designed explicitly for this purpose and usually offers more advanced distribution algorithms. A reverse proxy, on the other hand, provides a broader range of functionalities, such as:\nBackend Anonymity: Backend servers remain hidden from the external network, protecting against potential vulnerabilities. DDoS Mitigation: Many reverse proxies have built-in features to shield backend servers from distributed denial-of-service attacks, such as IP deny listing and client connection rate limiting. SSL Offloading: Handles the decryption of incoming requests and encryption of server responses, relieving backend servers from these computationally intensive tasks. Data Compression: Reduces the size of server responses for faster data transfer. Response Caching: Serves previously cached responses to identical requests, improving speed and reducing server load. Direct Serving of Static Content: Manages the delivery of static files like HTML, CSS, JavaScript, images, and videos directly to the client. URL/Content Rewriting: Modifies the URL or content before forwarding requests to the backend servers. Reverse proxies can be helpful even with just one web server or application server.\nPopular Solutions: Nginx, Apache HTTP Server (mod_proxy), HAProxy, Squid, Azure Application Gateway\nForward Proxy # A Forward Proxy is a server that sits between client devices and the Internet, acting as an intermediary for outgoing requests from the client. A forward proxy accepts connections from computers on a private network and forwards those requests to the public internet. It is the single exit point for subnet users accessing resources outside their private network.\nThe key difference between a forward proxy and a reverse proxy lies in their primary roles and whom they serve.\nA forward proxy primarily serves the client\u0026rsquo;s needs, helping it access blocked or restricted content and providing anonymity. A reverse proxy, on the other hand, is installed on the server side and manages incoming requests to the server. A forward proxy is client-focused and provides functions like：\nClients Anonymity: A forward proxy conceals the client\u0026rsquo;s original IP address, adding an extra layer of security during internet access. Access Management: Organizations can employ forward proxies to limit access to specific resources, safeguarding sensitive information. Caching: By caching commonly accessed resources, forward proxies can enhance client internet response times. Traffic Control: Forward proxies can manage and control network traffic flow, optimizing bandwidth usage. Logging: Forward proxies can record all outgoing requests and responses, aiding in monitoring and auditing. Popular Solutions: Squid, Tinyproxy, CCProxy, WinGate\nAPI Gateway # An API Gateway is a centralized entry point that manages and routes API requests from client applications to appropriate backend services. It acts as a layer of abstraction between the client and multiple backend services, streamlining their interaction. It is a crucial component in modern architecture, especially in microservices-based systems. API gateways offer various functionalities like:\nAn API Gateway is a centralized entry point that manages and routes API requests from client applications to appropriate backend services. It acts as a layer of abstraction between the client and multiple backend services, streamlining their interaction. It is a crucial component in modern architecture, especially in microservices-based systems. API gateways offer various functionalities like:\nRouting: Directs client-originating API requests to the suitable backend service or microservice, guided by established rules and settings. Authentication and Authorization: Manages user credentials to ensure only approved clients can access services. This includes verification of API keys, tokens, or other forms of identification. Rate Limiting and Throttling: Safeguards backend services by enforcing client request rate limits or throttling based on pre-configured policies. Load Balancing Caching Request and Response Transformation: Alters incoming and outgoing data, such as data format conversions or header modifications, to maintain compatibility between clients and backend services. Monitoring Request and Response Validation Circuit Breaking: Implements a circuit breaker pattern to prevent a single service failure from compromising the entire system. It monitors service health and can switch to a backup service if needed. Service Discovery: Identifies available microservices and their locations, allowing clients to interact with them without knowing their specific addresses. Enhanced Security: Enforces robust authentication and access control measures, bolstering the system\u0026rsquo;s overall security against unauthorized access. Popular Solutions: Kong, Amazon API Gateway, Apigee, Azure API Gateway, MuleSoft Anypoint Platform\nConclusion # Load Balancers primarily focus on distributing incoming traffic across multiple servers to ensure no single server is overwhelmed. They are essential for scalability and high availability but are generally agnostic to the type of content being served.\nReverse Proxies sit in front of web servers and direct client requests to the appropriate backend server. They are server-facing and are often used for caching, SSL termination, and load distribution within an internal network.\nForward Proxies act as intermediaries between clients and servers, often filtering requests, providing anonymity for users, or bypassing geo-restrictions. They are client-facing and are generally used to control outbound traffic.\nAPI Gateways, on the other hand, are specialized types of reverse proxies tailored for API traffic. They offer advanced functionalities like request routing, API composition, rate limiting, and security features such as authentication and authorization.\n"},{"id":6,"href":"/posts/the-different-kind-of-api-design/","title":"The Different Kind of API Design","section":"Blog","content":"In the daily life, we often hear about different kind of API, such as REST API, GraphQL API, WebSocket, Webhook, RPC and gRPC even the SOAP, so do you know the difference between them? How to choose the right API for your project?\nNote: this article is reprint from the article : The System Design Cheat Sheet: API Styles - REST, GraphQL, WebSocket, Webhook, RPC/gRPC, SOAP, the author is Aleksandr Gavrilenko who I really appreciate.\nREST(Representational State Transfer): the most used style that uses standard methods and HTTP protocols. It\u0026rsquo;s based on principles like statelessness, client-server architecture, and cacheability. It\u0026rsquo;s often used between front-end clients and back-end services. GraphQL: a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, reducing over-fetching. WebSocket: a protocol allowing two-way communication over TCP. Clients use web sockets to get real-time updates from back-end systems. Webhook: a way to send data from one application to another. It\u0026rsquo;s often used to send data about specific events from a back-end service to a front-end client. It is a user-defined HTTP callback. RPC (gRPC): a protocol that one service can use to request a procedure/method from a service located on another computer in a network. Usually, It\u0026rsquo;s designed for low-latency, high-speed communication. SOAP: a protocol for exchanging structured information to implement web services. It relies on XML and is known for its robustness and security features, currently considered a legacy protocol. REST API # REST API is the most used style that uses standard methods and HTTP protocols. Its stateless nature and use of standard HTTP methods make it a popular choice for building web-based APIs.\nFormat: XML, JSON, HTML, plain text\nTransport protocol: HTTP/HTTPS\nKey Concepts and Characteristics # Resource # In REST, everything is a resource. A resource is an object with a type, associated data, relationships to other resources, and a set of methods that operate on it. Resources are identified by their URIs (typically a URL).\nCRUD Operations # REST services often map directly to CRUD (Create, Read, Update, Delete) operations on resources.\nHTTP Methods # REST systems use standard HTTP methods:\nGET: Retrieve a resource. POST: Create a new resource. PUT/PATCH: Update an existing resource. DELETE: Remove a resource. Status Codes # REST APIs use standard HTTP status codes to indicate the success or failure of an API request:\nFor more status codes, you can refer to the RFC manual.\n2xx - Acknowledge and Success\n200 - OK 201 - Created 202 - Accepted 3xx - Redirection\n301 - Moved Permanently 302 - Found 303 - See Other 4xx - Client Error\n400 - Bad Request 401 - Unauthorized 403 - Forbidden 404 - Not Found 405 - Method Not Allowed 5xx - Server Error\n500 - Internal Server Error 501 - Not Implemented 502 - Bad Gateway 503 - Service Unavailable 504 - Gateway Timeout Stateless # Each request from a client to a server must contain all the information needed to understand and process the request. The server should not store anything about the client\u0026rsquo;s state between requests.\nClient-Server Architecture # REST is based on the client-server model. The client is responsible for the user interface and experience, while the server is responsible for processing requests, handling business logic, and storing data.\nCacheable # Responses from the server can be cached by the client. The server must indicate whether a response is cacheable or not.\nLayered System # A client cannot ordinarily tell whether it is connected directly to the end server or an intermediary. Intermediary servers can improve system scalability by enabling load balancing and providing shared caches.\nHATEOAS # Hypermedia As The Engine Of Application Stat is a REST web service principle that enables clients to interact with and navigate through a web application entirely based on the hypermedia provided dynamically by the server in its responses, promoting loose coupling and discoverability.\nUse Cases # Web Services: Many web services expose their functionality via REST APIs, allowing third-party developers to integrate and extend their services.\nMobile Applications: Mobile apps often communicate with backend servers using REST APIs to fetch and send data.\nSingle Page Applications (SPAs): SPAs use REST APIs to dynamically load content without requiring a full page refresh.\nIntegration Between Systems: Systems within an organization can communicate and share data using REST APIs.\nExamples # Request\nGET “/user/42” Response\n{ \u0026#34;id\u0026#34;: 42, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34; \u0026#34;links\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;/user/42/role\u0026#34; } } GraphQL API # It offers a more flexible, robust, and efficient approach to building APIs, especially in complex systems or when the frontend needs high flexibility. It shifts some of the responsibility from the server to the client, allowing the client to specify its data requirements.\nFormat: JSON\nTransport protocol: HTTP/HTTPS\nKey Concepts and Characteristics # Query Language for APIs # It allows clients to request the data they need, making it possible to get all required information in a single request.\nType System # GraphQL APIs are organized in terms of types and fields, not endpoints. It uses a strong type system to define the capabilities of an API. All the types exposed in an API are written down in a schema using the GraphQL Schema Definition Language (SDL).\nSingle Endpoint # Unlike REST, where you might have multiple endpoints for different resources, in GraphQL, you typically expose a single endpoint that expresses the complete set of capabilities of the service.\nResolvers # On the server side, resolvers gather the data described in a query.\nReal-time Updates with Subscriptions # GraphQL supports real-time updates through subscriptions, allowing clients to receive updates when data changes.\nIntrospective # A GraphQL server can be queried for the types it supports. This creates a strong contract between client and server, allowing for tooling and better validation.\nUse Cases # Flexible Frontends: For applications (especially mobile) with crucial bandwidth, you want to minimize the data fetched from the server.\nAggregating Microservices: A GraphQL layer can be introduced to aggregate the data from these services into a unified API if you have multiple microservices.\nReal-time Applications: With its subscription system, GraphQL can be an excellent fit for applications that need real-time data, like chat applications, live sports updates, etc.\nVersion-Free APIs: With REST, you often need to version your APIs once changes are introduced. With GraphQL, clients only request the data required, so adding new fields or types doesn\u0026rsquo;t create breaking changes.\nExamples # Request\nGET “/graphql?query=user(id:42){ name role { id name } }” Response\n{ \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: 42, \u0026#34;name\u0026#34;: \u0026#34;Alex\u0026#34;, \u0026#34;role\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;admin\u0026#34; } } } } WebSocket # WebSockets provide a full-duplex communication channel over a single, long-lived connection, allowing real-time data exchange between a client and a server. This makes it ideal for interactive and high-performance web applications.\nThe Websocket establish a connection by the Upgrade header in the HTTP request. The non-encrypted ws:// and encrypted wss://. Because it uses HTTP handshake, it uses the same port: ws is 80 (HTTP), wss is 443 (HTTPS).\nFormat: Binary\nTransport protocol: TCP\nKey Concepts and Characteristics # Persistent Connection # Unlike the traditional request-response model, WebSockets provide a full-duplex communication channel that remains open, allowing for real-time data exchange.\nUpgrade Handshake # WebSockets start as an HTTP request, which is then upgraded to a WebSocket connection if the server supports it. This is done via the Upgrade header.\nFrames # Once the connection is established, data is transmitted as frames. Both text and binary data can be sent through these frames.\nLow Latency # WebSockets allow for direct communication between the client and server without the overhead of opening a new connection for each exchange. This results in faster data exchange.\nBidirectional # Both the client and server can send messages to each other independently.\nLess Overhead # After the initial connection, data frames require fewer bytes to send, leading to less overhead and better performance than repeatedly establishing HTTP connections.\nProtocols and Extensions # WebSockets support subprotocols and extensions, allowing for standardized and custom protocols on top of the base WebSocket protocol.\nUse Cases # Online Gaming: Real-time multiplayer games where players\u0026rsquo; actions must be immediately reflected to other players.\nCollaborative Tools: Applications like Google Docs, where multiple users can edit a document simultaneously and see each other\u0026rsquo;s changes in real-time.\nFinancial Applications: Stock trading platforms where stock prices need to be updated in real-time.\nNotifications: Any application where users need to receive real-time notifications, such as social media platforms or messaging apps.\nLive Feeds: News websites or social media platforms where new posts or updates are streamed live to users.\nExamples # Request\nGET /chat HTTP/1.1 // 请求行 Host: server.example.com Upgrade: websocket // required Connection: Upgrade // required Origin: http://example.com Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 Response\nHTTP/1.1 101 Switching Protocols Upgrade: websocket // required Connection: Upgrade // required Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= // required，the encoded Sec-WebSocket-Key Sec-WebSocket-Protocol: chat The handshaking process is not the TCP handshaking, but the upgrade process from HTTP/1.1 to WebSocket. After the handshaking process, the next is the frames of the websocket.\nWebhook # Webhook is a user-defined HTTP callback triggered by specific web application events, allowing real-time data updates and integrations between different systems.\nFormat: XML, JSON, plain text\nTransport protocol: HTTP/HTTPS\nKey Concepts and Characteristics # Event-Driven # Webhooks are typically used to denote that an event has occurred. Instead of requesting data at regular intervals, webhooks provide data as it happens, turning the traditional request-response model on its head.\nCallback Mechanism # Webhooks are essentially a user-defined callback mechanism. When a specific event occurs, the source site makes an HTTP callback to the URI provided by the target site, which will then take a specific action.\nPayload # When the webhook is triggered, the source site will send data (payload) to the target site. This data is typically in the form of JSON or XML.\nReal-time # Webhooks allow applications to get real-time data, making them highly responsive.\nCustomizable # Users or developers can typically define what specific events they want to be notified about.\nSecurity # Since webhooks involve making callbacks to user-defined HTTP endpoints, they can pose security challenges. It\u0026rsquo;s crucial to ensure that the endpoint is secure, the data is validated, and possibly encrypted.\nUse Cases # Continuous Integration and Deployment (CI/CD): Triggering builds and deployments when code is pushed, or a pull request is merged.\nContent Management Systems (CMS): Notifying downstream systems when content is updated, published, or deleted.\nPayment Gateways: Informing e-commerce platforms about transaction outcomes, such as successful payments, failed transactions, or refunds.\nSocial Media Integrations: Receiving notifications about new posts, mentions, or other relevant events on social media platforms.\nIoT (Internet of Things): Devices or sensors can trigger webhooks to notify other systems or services about specific events or data readings.\nExamples # Request\nGET “https://external-site/webhooks?url=http://site/service-h/api\u0026amp;name=name” Response\n{ \u0026#34;webhook_id\u0026#34;: 12 } RPC/gRPC # RPC (Remote Procedure Call) is a protocol that allows a program to execute a procedure or subroutine in another address space, enabling seamless communication and data exchange between distributed systems.\ngRPC (Google RPC) is a modern, open-source framework built on top of RPC that uses HTTP/2 for transport and Protocol Buffers as the interface description language, providing features like authentication, load balancing, and more to facilitate efficient and robust communication between microservices.\nRPC # Format: JSON, XML, Protobuf, Thrift, FlatBuffers\nTransport protocol: Various\nKey Concepts and Characteristics # Definition # RPC allows a program to cause a procedure (subroutine) to execute in another address space (commonly on another computer on a shared network). It\u0026rsquo;s like calling a function performed on a different machine than the caller\u0026rsquo;s.\nStubs # In the context of RPC, stubs are pieces of code generated by tools that allow local and remote procedure calls to appear the same. The client has a stub that looks like the remote procedure, and the server has a stub that unpacks arguments, calls the actual procedure, and then packs the results to send back.\nSynchronous by default # Traditional RPC calls are blocking, meaning the client sends a request to the server and gets blocked waiting for a response from the server.\nLanguage Neutral # Many RPC systems allow different client and server implementations to communicate regardless of the language they\u0026rsquo;re written in.\nTight Coupling # RPC often requires the client and server to know the procedure being called, its parameters, and its return type.\nUse Cases # Distributed Systems: RPC is commonly used in distributed systems where parts of a system are spread across different machines or networks but need to communicate as if they\u0026rsquo;re local.\nNetwork File Systems: NFS (Network File System) is an example of RPCs performing file operations remotely.、\nExamples # Request\n{ \u0026#34;method\u0026#34;: \u0026#34;addUser\u0026#34;, \u0026#34;params\u0026#34;: [ \u0026#34;Alex\u0026#34; ] } Response\n{ \u0026#34;id\u0026#34;: 42, \u0026#34;name\u0026#34;: \u0026#34;Alex\u0026#34;, \u0026#34;error\u0026#34;: null } gRPC # Format: Protobuf\nTransport protocol: HTTP/2\nKey Concepts and Characteristics # Definition # gRPC is an open-source RPC framework developed by Google. It uses HTTP/2 for transport, Protocol Buffers (Protobuf) as the interface description language, and provides authentication, load balancing features, and more.\nProtocol Buffers # This is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. With gRPC, you define service methods and message types using Protobuf.\nPerformance # gRPC is designed for low latency and high throughput communication. HTTP/2 allows for multiplexing multiple calls over a single connection and reduces overhead.\nStreaming # gRPC supports streaming requests and responses, allowing for more complex use cases like long-lived connections, real-time updates, etc.\nDeadlines/Timeouts # gRPC allows clients to specify how long they will wait for an RPC to complete. The server can check this and decide whether to complete the operation or abort if it will likely take too long.\nPluggable # gRPC is designed to support pluggable authentication, load balancing, retries, etc.\nLanguage Neutral # Like RPC, gRPC is language agnostic. However, with Protobuf and the gRPC tooling, generating client and server code in multiple languages is easy.\nUse Cases # Microservices: gRPC is commonly used in microservices architectures due to its performance characteristics and ability to define service contracts easily.\nReal-time Applications: Given its support for streaming, gRPC is suitable for real-time applications where servers push data to clients in real-time.\nMobile Clients: gRPC\u0026rsquo;s performance benefits and streaming capabilities make it a good fit for mobile clients communicating with backend services.\nExamples # Request\nmessage User { int id = 1 string name = 2 } service UserService { rpc AddUser(User) returns (User); } SOAP # SOAP, which stands for Simple Object Access Protocol, is a protocol for exchanging structured information to implement web services in computer networks. It\u0026rsquo;s an XML-based protocol that allows programs running on disparate operating systems to communicate with each other.\nFormat: XML\nTransport protocol: HTTP/HTTPS, JMS, SMTP, and more\nKey Concepts and Characteristics # XML-Based # SOAP messages are formatted in XML and contain the following elements:\nEnvelope: The root element of a SOAP message that defines the XML document as a SOAP message. Header: Contains any optional attributes of the message used in processing the message, either at an intermediary point or the ultimate end-point. Body: Contains the XML data comprising the message being sent. Fault: An optional Fault element that provides information about errors while processing the message. Neutrality # SOAP can be used with any programming model and is not tied to a specific one.\nIndependence # It can run on any operating system and in any language.\nStateless # Each request from a client to a server must contain all the information needed to understand and process the request.\nBuilt-in Error Handling # The Fault element in a SOAP message is used for error reporting.\nStandardized # Operates based on well-defined standards, including the SOAP specification itself, as well as related standards like WS-ReliableMessaging for ensuring message delivery, WS-Security for message security, and more.\nUse Cases # Enterprise Applications: SOAP is often used in enterprise settings due to its robustness, extensibility, and ability to traverse firewalls and proxies.\nWeb Services: Many web services, especially older ones, use SOAP. This includes services offered by major companies like Microsoft and IBM.\nFinancial Transactions: SOAP\u0026rsquo;s built-in security and extensibility make it a good choice for financial transactions, where data integrity and security are paramount.\nTelecommunications: Telecom companies might use SOAP for processes like billing, where different systems must communicate reliably.\nExample # Request\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;soap:Envelope\u0026gt; \u0026lt;soap:Body\u0026gt; \u0026lt;m:AddUserRequest\u0026gt; \u0026lt;m:Name\u0026gt;Alex\u0026lt;/m:Name\u0026gt; \u0026lt;/m:AddUserRequest\u0026gt; \u0026lt;/soap:Body\u0026gt; \u0026lt;/soap:Envelope\u0026gt; Response\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;soap:Envelope\u0026gt; \u0026lt;soap:Body\u0026gt; \u0026lt;m:AddUserResponse\u0026gt; \u0026lt;m:Id\u0026gt;42\u0026lt;/m:Id\u0026gt; \u0026lt;m:Name\u0026gt;Alex\u0026lt;/m:Name\u0026gt; \u0026lt;/m:AddUserResponse\u0026gt; \u0026lt;/soap:Body\u0026gt; \u0026lt;/soap:Envelope\u0026gt; "},{"id":7,"href":"/posts/the-encode-and-decode-in-python/","title":"The Encode and Decode in Python","section":"Blog","content":"Do you really know the encode and decode in Python?\nThe encode and decode in Python are used to convert between strings and bytes. That we all know that the string in the computer storage and communication in the network is in the form of byte sequence, not the unicode.\nEncode # So the encode is used to transform the string to the byte sequence. And when you call the encode function, you need to specify the encoding type, such as utf-8, gbk, gb2312, etc. And python will use the encoding type to transform every character in the string to the corresponding byte sequence.\ns = \u0026#34;你好，世界\u0026#34; encoded_s = s.encode(\u0026#39;utf-8\u0026#39;) print(encoded_s) # b\u0026#39;\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xef\\xbc\\x8c\\xe4\\xb8\\x96\\xe7\\x95\\x8c\u0026#39; # the b is the prefix of the byte sequence. Decode # And the decode is the function of byte sequence. It transform the byte sequence to the string. And you should all use the same encoding type to transform the byte sequence to the string.\nb = b\u0026#39;\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xef\\xbc\\x8c\\xe4\\xb8\\x96\\xe7\\x95\\x8c\u0026#39; decoded_b = b.decode(\u0026#39;utf-8\u0026#39;) print(decoded_b) # 你好，世界 "},{"id":8,"href":"/posts/about-the-systemd/","title":"About the Systemd","section":"Blog","content":"It has been a long time that the linux use init to manage the startup process, such as sudo /etc/init.d/apache2 start or service apache2 start, but the init is serial. To address this issue, the systemd was born. The d is the abbreviation of daemon, which means the systemd is a daemon manager. The systemd substitutes the initd and becomes the default main process PID 1.\nYou can check the version systemctl --version.\nsystemctl # sudo systemctl reboot sudo systemctl poweroff sudo systemctl suspend hostnamectl # Look up the host info, Architecture, Hardware, Kernel, Operating System, etc.\nYou can also query via uname -a.\ntimedatectl # Query the timezone.\nloginctl # Manage the login session.\nloginctl list-sessions loginctl list-users loginctl show-user Unit # There are 12 types of units:\nService unit Target unit which is a group of units Device Unit Mount Unit Automount Unit Path Unit Scope Unit: not started by systemd Slice Unit: process group Snapshot Unit: Systemd snapshot, can switch back to a snapshot Socket Unit: process communication socket Swap Unit: swap file Timer Unit You can also query them:\nsystemctl list-units \u0026ndash;all systemctl list-units \u0026ndash;all \u0026ndash;state=inactive systemctl list-units \u0026ndash;type=service systemctl status # systemctl status bluetooth.service systemctl about service # systemctl start systemctl stop systemctl restart systemctl reload systemctl enable systemctl disable systemctl show service Unit config # The unit config file is located at /etc/systemd/system/. But most of them are the symbolic links to the real config file in /usr/lib/systemd/system/.\nThe systemctl enable command will create a symbolic link to the real config file in /etc/systemd/system/(if you config start on boot in the unit file, it will start on boot) And the systemctl disable command will remove the symbolic link. Such as\nsudo systemctl enable clamd@scan.service # which is equivalent to $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; You can list all the config files:\nsystemctl list-unit-files # the tail is the kind of unit, such as service(default), socket, etc. There are four status of the unit:\nenabled: the unit is enabled disabled: the unit is disabled static: the unit is static, which only served as other unit\u0026rsquo;s dependency masked: the unit is banned to be enabled Adjust file # systemctl cat atd.service can show the specific unit file.\nThe detail you can refer to the official document.\nOnce you adjust the unit file, you need to reload the systemd and restart the service:\nsudo systemctl daemon-reload sudo systemctl restart httpd.service Target # The target is a group of units, once the target is enabled, the units in the target will be enabled.\njournalctl # You can check the kernel log and the service log by only journalctl. The config file is /etc/systemd/journald.conf.\nsudo journalctl sudo journalctl -k # kernel log sudo journalctl \u0026ndash;since yesterday sudo journalctl -f # follow the log sudo journalctl _PID=1 # the log of the specific process sudo journalctl -u # the log of the specific service Refer to https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html\n"},{"id":9,"href":"/posts/docker-cheatsheet/","title":"Docker Cheatsheet","section":"Blog","content":"This is a cheatsheet of docker.\nNote: the docs will be updated from time to time.\nDeamon # docker info systemctl start | stop | restart | status | enable docker This command to operate the docker daemon. For more details, you can refer to the systemd. docker system df query the disk usage of the docker images # docker push \u0026lt;username\u0026gt;/\u0026lt;image_name\u0026gt; docker images docker pull | inspect | rmi ubuntu:20.04 normally, the image name is composed by registry/username/repository:tag, if there is no username, the default is library, which is the official repository. if there is no registry, the default is docker.io, which is the official registry. docker create -it ubuntu:20.04 create a container by the image docker tag image_name:tag new_image_name:new_tag docker export/import and docker save/load： export/import will discard history and metadata information, only saving the snapshot state of the container at the time docker export -o xxx.tar CONTAINER docker import xxx.tar image_name:tag save/load will save the complete record, with a larger volume docker save -o xxx.tar image_name:tag docker load -i xxx.tar docker hub # docker login -u \u0026lt;username\u0026gt; docker search \u0026lt;image_name\u0026gt; docker push \u0026lt;username\u0026gt;/\u0026lt;image_name\u0026gt; dangling image: if the image is updated by official, and the tag is allocated to the new image, the old image will be called dangling image. Only display \u0026lt;none\u0026gt; in the docker images command. containers # docker ps -a list all containers docker ps list running containers docker stats search all the containers resource usage (CPU, memory, storage, network) docker rename CONTAINER1 CONTAINER2 docker start | stop | restart | rm | top | inspect | kill ｜ port CONTAINER docker run -itd ubuntu:20.04 search and run a container (-d means detach) == pull + create + start eg. docker run -p 20000:22 --name my_docker_server -itd docker_images:1.0 docker attach CONTAINER ⌃ + p and ⌃ + q which can detach the container ⌃+d which can close and exit the container（exit; then the container will be stopped） docker logs -f CONTAINER -f means follow, you can see the logs in real time docker cp xxx CONTAINER:xxx docker exec CONTAINER COMMAND eg docker exec -it container_name bash docker exec -it container_name /bin/bash if your garrison program is sshd(which is not accept input) not the bash, then you should use this command to substitute it. (Recommend, exit; the container will not be stopped) You can also use docker run -it container_name /bin/bash specific the shell to enter the container. docker update CONTAINER --memory 500MB docker container prune remove all stopped containers docker commit container_name image_name:tag Package the container as an image For the detail of build docker image, you can refer to the tips about dockerfile.\n"},{"id":10,"href":"/posts/docker-101/","title":"Docker 101","section":"Blog","content":"Docker is a practical tool for everyday use, and like Git, you can learn it in just 30 minutes.\nDocker 101 # Why docker # Traditionally, it is believed that after the completion of software coding development/testing, the output is a program or executable binary bytecode, such as java. In order to enable these programs to execute smoothly, the development team also has to prepare complete deployment files and a running environment, so that the operation and maintenance team can deploy the application. The emergence of Docker enables the packaging, from bottom to top, of the system environment required to run the application, excluding the operating system kernel, through images.\nDocker Concepts # Docker itself is a container runtime carrier or a management engine. Docker is an open source project based on the Go. The main goal of Docker is \u0026ldquo;Build, Ship and Run Any App, Anywhere\u0026rdquo;, addressing the issues of software containers regarding the running environment and configuration.\nimage # A Docker Image is a read-only template. Many containers can be created from the image.\nYou can imagine the image as the class and the container as the instance.\ncontainer # Containers can be regarded as a simplified Linux environment, including root user privileges, process space, user space, network space, etc., as well as the applications running within them.\nrepository # A repository is a centralized place for storing image files. It is similar to a Maven repository, which is where various jar packages are stored, and a GitHub repository, where various Git projects are stored. The official registry provided by Docker, Inc. is called Docker Hub。\nDocker Workflow # Docker is a Client-Server structured system. The Docker daemon runs on the host machine and can be accessed from the client via a Socket connection. The daemon receives commands from the client and manages the containers running on the host, similar to MySQL.\nDocker is a C/S mode architecture. The backend is a loosely coupled architecture, with numerous modules separated and each performing its own functions.\nThe basic process of running Docker is as follows:\nUsers use the Docker Client to establish communication with the Docker Daemon and send requests to the latter. The Docker Daemon, as the main part of the Docker architecture, first provides the Docker Server function so that it can accept requests from the Docker Client. The Docker Engine executes a series of internal tasks in Docker, and each task exists in the form of a Job. During the running of a Job, when a container image is needed, the image is downloaded from the Docker Registry, and the downloaded image is stored in the form of a Graph through the image management driver, Graph driver. When creating a network environment for Docker, the Docker container network environment is created and configured through the network management driver, Network driver. When operations such as restricting the running resources of a Docker container or executing user instructions are required, it is completed through the Exec driver. Libcontainer is an independent container management package. Both the Network driver and the Exec driver use Libcontainer to implement specific operations on containers. Docker components # Before we talk about Docker, we need to understand some basic concepts about linux.\nbootfs(boot file system): contains the kernel and the bootloader. The bootloader is used to load the OS kernel into memory and start it. Then the bootfs will be unloaded and release some memory space. rootfs(root file system): contains the OS kernel and the root directory. The rootfs is used to store the OS kernel and the root directory, such as /dev, /proc, /bin, /etc, /lib, /usr, and /tmp etc. When starting the system, the rootfs will be mounted as read-only. After the system is started, the rootfs will be mounted as read-write. UnionFS: (below from wiki) It allows files and directories of separate file systems, known as branches, to be transparently overlaid, forming a single coherent file system. Contents of directories which have the same path within the merged branches will be seen together in a single merged directory, within the new, virtual filesystem. When mounting branches, the priority of one branch over the other is specified. So when both branches contain a file with the same name, one gets priority over the other. The different branches may be either read-only or read/write file systems, so that writes to the virtual, merged copy are directed to a specific real file system. This allows a file system to appear as writable, but without actually allowing writes to change the file system, also known as copy-on-write, which means that the modification of the read-only file system can be saved to the writable file system. The startup process of a computer:\nPOST (Power-On Self-Test), this process is mainly executed by the computer\u0026rsquo;s BIOS (Basic Input/Output System) or UEFI (Unified Extensible Firmware Interface). BIOS/UEFI checks whether the computer\u0026rsquo;s hardware, such as memory, hard disk, CPU, etc., is working properly. After completing POST, the next task of BIOS/UEFI is to find and load the boot loader. The boot loader（such as GRUB - Grand Unified Bootloader） is responsible for loading the kernel(vmlinuz in the /boot) and the rootfs. The kernel init: Device test and driver loading, the memory paging. And then init the first process PID 1, which is init or systemd. Then other services will be started, such as GNOME Display Manager, etc. For the PID 1 and the systemd, you can refer my blog the systemd. So the docker is based on layers. When docker run a container and do some changes, it will just add the writable layer on the other layers and this layer is so-called container.\nThe maximum number of UnionFS layers is 127.\nIn the dockerfile, every RUN command will create a new layer. So you should use\nRUN xxxx \u0026amp;\u0026amp; xxxx \\ \u0026amp;\u0026amp; xxxx to reduce the number of layers. And in the end, you should also clean the cache to make this layer as small as possible.\nCompare # Traditional Virtual Machine Technology:\nA virtual machine (VM) is a solution that includes an environment installation. It can run one operating system within another operating system. A hypervisor (such as VMware) virtualizes a set of OS. It virtualizes a set of hardware, on which a complete operating system runs, and within that system, the required application processes are executed. Docker:\nThe application processes inside a container run directly on the host\u0026rsquo;s kernel. The container does not have its own kernel and does not perform hardware virtualization. It directly uses the hardware resources of the physical machine, isolating the processes. Each container is isolated from one another, each having its own file system. Processes in different containers do not affect each other, allowing for the distinction of computing resources. Docker is kernel-level virtualization, which does not require reloading an operating system kernel like a virtual machine. This avoids the time-consuming and resource-intensive process of seeking and loading the operating system kernel. Docker Installation # Docker is not a universal container tool. It depends on an existing and running Linux kernel environment.\nDocker essentially creates an isolated file environment within a running Linux system. As a result, its execution efficiency is nearly equivalent to that of the deployed Linux host.\nTherefore, Docker must be deployed on a system with a Linux kernel. If other systems want to deploy Docker, they must install a virtual Linux environment. For example, in Windows, you should run Docker on your VMware Linux images.\nThe process you can refer to the official docs: https://docs.docker.com/engine/install/\nIn this process, you run docker run hello-world which will first search the image locally, if not found, it will search the image from the Docker Hub. And docker image pull it automatically, and then run it.\nPrequisite # Add current user to docker group # To avoid having to use the sudo command every time you use the docker command, you can add the current user to the docker group created during installation (refer to the official documentation).\nAliyun mirror acceleration # Only domestic developers refer:\nhttps://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images\nmkdir -p /etc/docker\nvim /etc/docker/daemon.json\ndon\u0026rsquo;t forget restart\nsystemctl daemon-reload systemctl restart docker Now you have known the basic of docker, for more commands, you can refer to the docker-cheatsheet.\n"},{"id":11,"href":"/posts/the-instance-class-static-magic-method-in-python/","title":"The Instance Class Static Magic Method in Python","section":"Blog","content":"So what is the difference between the Instance method, the Class method and the Static method?\nInstance method # The normal method is defined with self as the first parameter. And it can only be called by the instance.\nClass method # The class method is mainly about the class.\nYou have to use the @classmethod to sign your type. So you can easily use the variable inside the class via cls.variable you cannot call the init method because they are called only the instance is created. You can call the function through ClassName.method_name(others not recommend) Static method # The static method is as a normal function. Only has the name related to the class. So that it cannot access the class variable and instance variable.\nYou can call the function via ClassName.method_name\nMagic method # And there is a special method called the magic method. The magic method is the method that has double underscores at the beginning and end of the method name. Such as __str__, __init__, etc.\nThe normal methods need to be called, but the magic method is called automatically when some events happen. So if you want to customize your class, you can override the magic method.\nThe most common operators, for loops, and class operations are all run on the magic method.\nNow I will introduce some common magic methods:\ninit # The __init__ method is the constructor of the class. It is used to initialize the instance of the class. And it will be called automatically when the instance is created.\nnew # It will also be called automatically when the instance is created. But it is the first method to be called, which is prior to __init__.\ndel # The __del__ method is the destructor of the class. It is used to destroy the instance of the class. And it will be called automatically when the instance is destroyed. (But there still exists some problems, if the interpreter is terminated, but the instance is not destroyed, the destructor will not be called.)\nMost of the magic methods are not commonly used. So I will not introduce them in detail. For more information, you can refer to this article.\nPrivate method # Besides, there is another special method called the private method. The private method is the method that has two underscores at the beginning of the method name. Such as __method_name.\nThe private method is used to hide the method from the outside. So that the method cannot be called by the outside, if you try that, you will only get an AttributeError：\u0026lsquo;xxx\u0026rsquo; object has no attribute \u0026lsquo;__attribute_name\u0026rsquo;.\nThe private method and attribute can be accessed by the instance internally, so you can use the public method to access them indirectly.\nIn deed, there is no real private method in Python, it just converts the method name to _ClassName__method_name() or _ClassName__attribute_name. You can use the dir() function to see the method and attribute inside the instance.\n"},{"id":12,"href":"/posts/the-overview-of-security/","title":"The Overview of Security","section":"Blog","content":"In today\u0026rsquo;s digital age, security is paramount. As we increasingly rely on technology for communication, commerce, and data storage, understanding the fundamentals of security becomes essential. This article provides an overview of key security concepts, including encryption, digest algorithms, and digital signatures. By exploring these topics, we aim to equip you with the knowledge to protect your digital assets and ensure the integrity and confidentiality of your information. Whether you\u0026rsquo;re a tech enthusiast or a professional in the field, this guide will offer valuable insights into the mechanisms that safeguard our digital world.\nEncryption # Symmetric Encryption # The same key is used for both encryption and decryption. The key is normally short. And the efficiency is high, so it is widely used in https communication and network transmission.\nThe most common symmetric encryption algorithm is AES, DES, 3DES, DESX, Blowfish, RC6.\nAsymmetric Encryption # The public key and the private key are used for encryption and decryption. The public key is widely distributed, while the private key is kept secret. Only the holder of the private key can decrypt/encrypt the data encrypted/decrypted by the public key.\nCons: The efficiency is low, it will take a long time to encrypt/decrypt the data. So it is only suitable for small data encryption. e.g. https communication pre-shared key、CA certificate、login authentication.\nThe most common asymmetric encryption algorithm is RSA, ECC, DSA, ECDSA, Diffie-Hellman.\nThe symmetric encryption can not be used for signing, only the asymmetric encryption can be used for signing. Verify file consistency will use the Information Digest Algorithm. Digest Algorithm # The digest algorithm is usually called as the hash algorithm.\nIt is a one-way encryption algorithm, which means that the original data can not be restored from the encrypted data. It will generate a fixed length of data, which is called the digest. The digest is unique for the original data, and the same original data will generate the same digest(in the same hash algorithm). Avoid collision. Normally can be considered as the compression of the original data. Above all, so it can be used for file integrity verification.\nMD series # MD2、MD4、MD5, and the MD5 is the most common one as well as secure and fast.\nMD5（Message Digest Algorithm）: Generally generate a 128-bit hash value(16 bytes), and the output is a 32-character hexadecimal string. Normally generate the .md5 or .md5sum file to make sure the file is not modified.\nSHA series # SHA (Secure Hash Algorithm): The length of SHA is longer than MD, so it is more secure to avoid collision. But the speed is lower than MD.\nSHA1 generate a 20 bytes(160 bits) hash value, SHA224 generate a 28 bytes (224 bits) hash value, SHA256 generate a 32 bytes(256 bits) hash value, SHA384 generate a 48 bytes(384 bits) hash value, SHA512 generate a 64 bytes(512 bits) hash value.\nDigital Signature # Normally, the digital signature will use the hash algorithm to generate the digest, and then use the asymmetric encryption algorithm to sign the digest.\nThe process is as follows:\nSender:\nUse the hash algorithm to generate the digest of the original data. Use the sender\u0026rsquo;s private key to encrypt the digest. Send the original data and the encrypted digest to the receiver. Receiver:\nUse the hash algorithm to generate the digest of the received data. Use the sender\u0026rsquo;s public key to decrypt the digest. Compare the decrypted digest with the received digest. If they are the same, it means that the data is not modified. To make sure the public key is correct, the public key will be signed by the CA. And CA will sign the public key with its private key and send them both (Digital Certificate) to the receiver. Then the receiver can use the CA\u0026rsquo;s public key to decrypt Digital Certificate to get the sender\u0026rsquo;s public key.\nDigital signature algorithm # RSA signature algorithm is the most common one. Such as MD5withRSA means use the MD5 hash algorithm to generate the digest, and then use the RSA algorithm to sign the digest.\nDSA (Digital Signature Algorithm): It is a digital signature algorithm based on the discrete logarithm problem. Only can be used for signing, not for encryption.\nECDSA (Elliptic Curve Digital Signature Algorithm): It is a digital signature algorithm based on the elliptic curve. Secure and fast.\n"},{"id":13,"href":"/posts/how-to-publish-your-code-as-a-pip-module/","title":"How to Publish Your Code as a Pip Module","section":"Blog","content":"Last week, I have made a python cli tool. To make it more convenient to use, I want to publish it as a pip module, so I have made some research and mistakes, and finally succeeded.\nPrerequisites # Register a pypi account in the official website Apply a token in the pypi management page Make sure your module name will be unique, you can check it in the pypi search page Check your code # Make sure your code is in a \u0026ldquo;package\u0026rdquo; folder (Must have __init__.py file) Create a README.md Create a LICENSE Create the pyproject.toml file in the root folder of the package, you can use the following content as a template: [build-system] requires = [\u0026#34;hatchling\u0026#34;] build-backend = \u0026#34;hatchling.build\u0026#34; [project] name = \u0026#34;biliupload\u0026#34; # make sure your module name is unique version = \u0026#34;0.0.1\u0026#34; authors = [ { name=\u0026#34;timerring\u0026#34;}, ] description = \u0026#34;Login and upload videos to bilibili\u0026#34; readme = \u0026#34;README.md\u0026#34; license = { file=\u0026#34;LICENSE\u0026#34; } requires-python = \u0026#34;\u0026gt;=3.10\u0026#34; classifiers = [ \u0026#34;Programming Language :: Python :: 3\u0026#34;, \u0026#34;License :: OSI Approved :: MIT License\u0026#34;, \u0026#34;Operating System :: OS Independent\u0026#34;, ] dependencies = [ \u0026#34;PyYAML==6.0.2\u0026#34;, \u0026#34;qrcode==8.0\u0026#34;, \u0026#34;Requests==2.32.3\u0026#34;, \u0026#34;requests_html==0.10.0\u0026#34;, ] [project.urls] \u0026#34;Homepage\u0026#34; = \u0026#34;https://github.com/timerring/biliupload\u0026#34; The below is the basic template, if you are making a cli tool, you also need to add the project.scripts section.\nFor more details, you can refer to the official documentation\nBuild the package # Latest version of PyPA’s build is recommended python3 -m pip install --upgrade build Build the package(run this command from the same directory where pyproject.toml is located) python3 -m build You will see the following output in dist/ folder:\n.whl file: the built distribution .tar.gz file: the source distribution Upload distribution archive for TestPyPI # The TestPyPI is a isolated website of PyPI, you can upload your package to it first to check if it works.\nRegister on TestPyPI Apply a token in the TestPyPI management page install the twine package python3 -m pip install --upgrade twine upload the distribution packages via python3 -m twine upload --repository testpypi dist/* and you can check your package. Test your package in a new environment python3 -m pip install --index-url https://test.pypi.org/simple/ biliupload That maybe have some problems, you can refer to the Conflict problem section to fix it.\nUpload distribution archive formally # Make sure your production version for build is ready Upload the distribution archive via python3 -m twine upload dist/* Then you can pip it formally pip install biliupload Your can also refer to the official documentation if you want more details.\nAdditionally, you may also want to make it into a executable file, you can just use the pyinstaller package command pyinstaller -F biliupload/cli.py to do it.\nNote: pyinstaller is not a cross-platform compiler, you need to compile it on the platform you want to run it on via docker or some other tools. And if you want to Using Data Files from a Module, don\u0026rsquo;t forget to include it via pyinstaller --add-data \u0026quot;bilitool/authenticate/config.json:bilitool/authenticate\u0026quot; -F bilitool/cli.py.\nConflict problem # You may encounter the following error:\nThe conflict is caused by: biliupload 0.1.1 depends on pyyaml==6.0.2 biliupload 0.1.0 depends on pyyaml==6.0.2 To fix this you could try to: 1. loosen the range of package versions you\u0026#39;ve specified 2. remove package versions to allow pip to attempt to solve the dependency conflict That is because you are using the pyyaml package which is not exist in the testpypi, so you can refer to this stackoverflow to fix it via pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple biliupload==0.1.0, which the --extra-index-url pointer to the pypi.org.\n"},{"id":14,"href":"/posts/some-good-things-to-share-about-the-packages/","title":"Some Good Things to Share About the Packages","section":"Blog","content":"As a developer, I have been using many packages in my projects. Sometimes I may even forget the existence of the packages. When I changed my devices or some one else asked me, it\u0026rsquo;s hard for me to remember everything to recommend. Thus I will try to list the things which I think are very helpful and useful to share with you. Maybe we can even make an \u0026ldquo;Annual Oscar Awards ceremony\u0026rdquo; for the things.\nNote: This post will be updated regularly.\nPython # Env # pipdeptree # Most of the time, when we use the pip list or pip freeze command, we can only get all packages that we have installed. We don\u0026rsquo;t know the dependencies of the packages, and that\u0026rsquo;s where the advantage of pipdeptree to show.\n# usage pipdeptree pip-autoremove # Sometimes we want to remove the specific package, but usually it has some dependencies packages, on top of know the tree structure and remove them one by one, you can try to use the pip-autoremove to remove them all.\n# usage pip-autoremove \u0026lt;package_name\u0026gt; pipreqs # The pipreqs package can help us to generate the most simplified requirements.txt file for the project.\n# usage pipreqs "},{"id":15,"href":"/posts/introduction-to-the-http-and-https-protocol/","title":"Introduction to the HTTP and HTTPS Protocol","section":"Blog","content":"HTTP protocol is the foundation of the Internet, and HTTPS is the secure version of HTTP. HTTP is an application layer protocol based on TCP/IP protocol. It does not involve packet (packet) transmission, mainly specifying the communication format between the client and the server, and the default port is 80.\nHTTP/0.9 # In the 1991, HTTP 0.9 was released, there is only one method: GET. When the tcp connection is established, the client sends a GET request to the server, and the server only returns the HTML resource. Then closes the connection.\nHTTP/1.0 # In the 1996, HTTP 1.0 was released, besides the data parts, every request and response should have a HTTP header. It added the following features:\nMultiple methods: GET, POST, HEAD Status codes: 100, 200, 300, 400, 500 Headers: Content-Type(text/plain, text/html, image/jpeg, video/mp4, etc. You can also define your own), Content-Encoding(Accept-Encoding, you can specify you can accept the encoding format, such as gzip, deflate, etc.), Date, Server, Last-Modified, ETag, Expires, Cache-Control. But you can only request once in a TCP connection. It will be closed after the request is completed. If you want to request multiple resources, you need to open multiple TCP connections.\nHTTP/1.1 # persistent connection # In the 1997, HTTP 1.1 was released. It introduced the persistent connection, which means that the TCP connection will not be closed after the request is completed. You can request multiple resources in the same connection. You can establish 6 connections at most to the same domain. When the server and client are idle for a period of time, the connection can be closed actively (The client send Connection: close).\nBut you can just send one request in the TCP connection at the same time(which is serial).\npipelining # It added the pipelining mechanism, client can send multiple requests without waiting for the response of the previous request, the requests are clarified by Content-Length: the length of request body. But the server still needs to respond in the order of the request. But the server needs to wait for all the operations to be completed before sending the response. Hence introduces the chunked transfer encoding Transfer-Encoding: chunked, which means the server will send the response in chunks. Just as the streaming mode.\npipelining from https://shurutech.com/the-evolution-of-http/ Host header and methods # Besides, it added the Host: example.com header, which means the server can distinguish different domains, along with other methods, such as PUT、PATCH、HEAD、OPTIONS、DELETE.\nCons # The cons is that the response will cause the Head-of-line blocking problem.\nHTTP/2 # frame # In the 2015, HTTP 2 was released. It is a binary protocol, which means the data is transferred in binary format, which is so-called \u0026ldquo;frame\u0026rdquo;. It uses the SPDY protocol, which is a protocol for improving the performance of the web, it can implement the multiplexing mechanism, that means the client can send multiple requests in the same TCP connection at the same time. And because the packet is divided into frames, the server can send the response in any order.\nstream # A request or response is called as stream. And every frame has a stream identifier, which can be used to identify the stream. The id of client streams are odd, and the id of server streams are even. And the client or server can dismiss the stream by sending RST_STREAM frame. The client can specify the priority of the stream.\nheader compression # Besides, in order to improve the performance of the web, it added the HPACK compression algorithm, which can compress the HTTP header. And establishs a header table, which can be used to index the header between the client and the server. So they can only send the index in the following requests.\nserver push # Meanwhile, the server can implement the server push mechanism, which means the server can push the resources to the client before the client requests.\nPush mechanism eg. You can see the Network tab in the browser, some headers of requests are provisional headers are shown, which means the server is pushing the resources to the client. Normally, the Size column is from disk cache or from memory cache, which means the resources are from the browser cache. You can also check the Protocol column, it is h2, which means the protocol is HTTP/2.\nSSE # Server-Sent Events (SSE) is a technology where a browser receives automatic updates from a server via HTTP connection(which is normally requests by the browser). It is a server push mechanism, which means the server can push the resources to the client without the client requests.\nCons: The SSE is the one-way serial communication, which means the server can only push the resources to the client Web APP.\nCons # H2 Server push cons: The server push of h2 can only push the resources that are in the cache, which means you cannot push the message directly to the client Web APP. The Web does not have the api to query the push events. So if you want to implement the message push to the client, you can combine the h2 and SSE. TCP Head-of-Line (HOL) Blocking: HTTP/2.0 experiences delays known as TCP head-of-line blocking, which occurs within the TCP layer. If a single packet in the TCP stream gets lost, all streams using that connection have to wait for it to be retransmitted. TCP HOL Blocking from https://simrankhanna.substack.com/p/unclogging-the-pipeline-how-http Packet Sequence Requirement: Each TCP packet must be received in a specific sequence due to assigned sequence numbers. If any packet is lost, subsequent packets are stalled. TCP Buffer Holding: Lost packets cause subsequent packets to wait in the TCP buffer until the missing packet is retransmitted and received. Impact on HTTP Layer: The HTTP layer, built on top of TCP, does not handle these TCP retransmissions. It only notices a delay when attempting to retrieve data from the socket. Inability to Process Received Data: Even if received packets contain a complete HTTP request or response, they cannot be processed until the lost packet is retrieved. HTTP/3 # UDP # In the 2021, HTTP 3 was released. It is a protocol based on UDP, which means the data is transferred in UDP packets(when specific stream lost packet, other streams are not affected, which will not cause the head-of-line blocking problem).\nQUIC # Because the UDP is the unreliable transmission. So it uses the QUIC（Quick UDP Internet Connections） protocol to ensure the reliability. The QUIC is also a protocol that needs three handshakes to establish a connection, the main purpose is to determine the connection ID. And it can implement the multiplexing mechanism. And because the packet is divided into frames, the server can send the response in any order.\nHandshake process from https://www.catchpoint.com/http3-vs-http2 Pros # The HTTP based on TCP, it use the source IP, source port, destination IP, destination port to determine a TCP connection. So if the IP or port is changed, the connection will be closed. And needs to establish a new connection through the TCP three-way handshakes and the TLS handshake. But the QUIC protocol uses the connection ID to determine the connection. So it can implement the multiplexing mechanism. So even the IP or port is changed, the message has the same connection ID, it can be identified as the same connection. HTTPS # Now the most browers recommend HTTPS instead of HTTP.\nHttps is not a new protocol, it is the secure version of HTTP. It is based on the HTTP protocol, and adds a layer of security. The http protocol will cause eavesdropping, tampering, and pretending issues. The SSL/TLS protocol is used to solve these problems: encrypted, verification, and certificates.\nThe process of https is as follows:\nthe client requests the public key from the server, and uses the public key to encrypt the data. the server uses the private key to decrypt the data after receiving the request. how to ensure the public key is not tampered?\nUse the CA to sign the public key. If the CA is reliable, then the public key is reliable.\nhow to optimize the performance?\nUse the symmetric encryption key(session key) to encrypt the data. And the public key used to encrypt the symmetric encryption key.\nThe TLS handshake process is as follows (the handshake process is plaintext).\nClientHello # the protocol version, eg TLS 1.0 a random number(Client random) generated by the client, which will be used to generate the \u0026ldquo;session key\u0026rdquo; the supported encryption methods, such as RSA public key encryption the supported compression methods ServerHello # Confirm the encrypted communication protocol version used, eg TLS 1.0 a random number(Server random) generated by the server, which will be used to generate the \u0026ldquo;session key\u0026rdquo; confirm the encryption method, such as RSA public key encryption send the server certificate, and the server\u0026rsquo;s public key in the certificate If the server needs to confirm the client\u0026rsquo;s identity, it will include an additional request to require the client to provide a \u0026ldquo;client certificate\u0026rdquo;. For example, financial institutions often only allow authenticated customers to connect to their network, and will provide a USB key to formal customers, which contains a client certificate.\nClient Response # verify the server certificate. If the certificate is signed by a trusted CA, or the domain in the certificate is the same as the domain in the request or the certificate is expired, the client will warn the user. If the certificate is signed by a trusted CA, the client will use the public key in the certificate to encrypt the data.\na random number(which is so-called \u0026ldquo;pre-master secret\u0026rdquo;). The random number is encrypted by the server\u0026rsquo;s public key, which is used to prevent eavesdropping. (The three random numbers are used to generate the \u0026ldquo;session key\u0026rdquo;, which maximally guarantees randomness to prevent the key from being eavesdropping). encoding change notification, which means the subsequent information will be sent using the encryption method and key agreed by both parties. client handshake end notification, which means the client\u0026rsquo;s handshake phase has ended. This item is also the hash value of all the previous sent content, which is used to verify the server. Server Response # Decrypt the \u0026ldquo;pre-master secret\u0026rdquo; using the server\u0026rsquo;s private key. Use the three random numbers to generate the \u0026ldquo;session key\u0026rdquo;.\nencoding change notification. server handshake end notification, which means the server\u0026rsquo;s handshake phase has ended. This item is also the hash value of all the previous sent content, which is used to verify the client. Now the following communication uses the symmetric encryption key(session key) to encrypt the HTTP data.\nThe asymmetric encryption is only used in the handshake process.\nThe whole process is as follows:\nTLS handshake process from cloudflare And due to the asymmetric encryption keys are only used once, so if someone(eg. bank) wants to use the cdn service, but he doesn\u0026rsquo;t want to submit the private key to the cdn provider, then he can keep it in his server, and use it to encrypt and decrypt, and other process will be done by the cdn provider. As you can see, the bank\u0026rsquo;s server only needs to process the step 4.\nKeyless process from Cloudflare Eavesdropping # The TLS handshake process is plaintext, so it is easy to be eavesdropped. The eavesdropper can get the encryption method and the two random numbers. So whether the communication is really secure depends on the \u0026ldquo;pre-master secret\u0026rdquo; is not cracked.\nIn theory, as long as the server\u0026rsquo;s public key is long enough, such as 2048 bits, it is impossible to crack the \u0026ldquo;pre-master secret\u0026rdquo;. But if you pursue the ultra security, you can use the Diffie-Hellman algorithm, which will only need to exchange the DH parameters. And they can calculate the \u0026ldquo;pre-master secret\u0026rdquo; together.\nResume the session # If the session is disconnected, then needs to re-handshake. There are two ways to resume the session:\nSession ID: When the client reconnects, it will send the session ID to the server, and the server will use the session ID to find the \u0026ldquo;session key\u0026rdquo; in the memory. But it still has problem, the session ID is only stored in one server, if the client sends it to other server, the session won\u0026rsquo;t be resumed. Session resume from Cloudflare Session Ticket: When the client reconnects, it will send the session ticket(which is sent by the server at the end of the TLS handshake) to the server, and the server will use the ticket key to decrypt the session ticket and get the \u0026ldquo;session key\u0026rdquo;. Session resume from Cloudflare SSL and TLS # In brief, TLS is the successor of SSL. The SSL(Secure Sockets Layer) protocol is deprecated, and nearly does not be used. And the TLS(Transport Layer Security) protocol is the standard. Due to the historical reasons, the TLS certifcate sometimes is called as SSL certificate, but it is not the same.\nReferences # https://www.catchpoint.com/http3-vs-http2 https://shurutech.com/the-evolution-of-http/ https://simrankhanna.substack.com/p/unclogging-the-pipeline-how-http https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html https://blog.cloudflare.com/tls-session-resumption-full-speed-and-secure/ "},{"id":16,"href":"/posts/mail-service-and-protocol/","title":"Mail Service and Protocol","section":"Blog","content":"Recently, I have been working on DNS of my domain name. And then I need to set up the mail service of my domain name. When I tried many times, I always failed to receive the mail on my phone. Suddenly, I remembered that I didn\u0026rsquo;t set up IMAP service. So let\u0026rsquo;s review the mail service and protocol.\nThe most common mail service is SMTP, POP3, and IMAP.\nSMTP # SMTP（Simple Mail Transfer Protocol）is used to transfer mail between mail servers. It is a protocol based on TCP/IP, and its main task is to define how mail is sent from the sender\u0026rsquo;s mail server to the receiver\u0026rsquo;s mail server. SMTP uses a client/server model, with the sender\u0026rsquo;s mail server acting as the client connecting to the receiver\u0026rsquo;s mail server.\nEmail is submitted by a mail client (mail user agent, MUA) to a mail server (mail submission agent, MSA) using SMTP on TCP port 465. The MSA delivers the mail to its mail transfer agent (MTA). And this process can be done by multiple machines. The boundary MTA uses DNS to look up the MX (mail exchanger) record for the recipient\u0026rsquo;s domain (the part of the email address on the right of @). The MX record contains the name of the target MTA. Based on the target host and other factors, the sending MTA selects a recipient server and connects to it to complete the mail exchange. Once the final hop accepts the incoming message, it hands it to a mail delivery agent (MDA) for local delivery. Once delivered to the local mail server, the mail is stored for batch retrieval by authenticated mail clients (MUAs), using Internet Message Access Protocol (IMAP), a protocol that both facilitates access to mail and manages stored mail, or the Post Office Protocol (POP) which typically uses the traditional mbox mail file format MIME（Multipurpose Internet Mail Extensions）is a standard that extends the format of email messages to support text in character sets other than ASCII, and to allow audio, video, images, and application data to be included in email.\nThe default port is 25, but it is not secure, so it is recommended to use port with SSL/TLS encryption, such as 587(TLS) or 465(SSL). Details depend on the ISP.\nPOP3 # POP3（Post Office Protocol version 3）is a protocol used to download mail from the mail server to the local device. After downloading, the mail on the server is usually deleted or marked as read. It is suitable for users who check mail occasionally through a single device. The operation of POP3 is one-way, which means that the client\u0026rsquo;s operations are not reflected on the server.\nThe default port is 110, but it is not secure, so it is recommended to use port with SSL/TLS encryption, such as 995(SSL).\nIMAP # IMAP（Internet Message Access Protocol）is a protocol used to receive mail. It is similar to POP3, which is a mail retrieval protocol. Its main function is to allow mail clients (such as iPhone, Foxmail) to retrieve mail information and download mail from the mail server. IMAP is designed to provide a two-way communication between the webmail and the mail client, so that the client\u0026rsquo;s operations can be reflected on the server.\nThe default port is 143, but it is not secure, so it is recommended to use port with SSL/TLS encryption, such as 993(SSL).\n"},{"id":17,"href":"/posts/thinking-about-advertisement-from-an-open-source-perspective/","title":"Thinking About Advertisement from an Open Source Perspective","section":"Blog","content":"我在本科期间听到过很多关于广告论调，仍记得某位教授对于短视频所代表的互联网深恶痛绝，在课堂上批判广告的价值，抨击广告行业的浮躁。我身边的同学也大抵持相同的观点，认为互联网广告就是智商税，广告的目的是为了卖课，卖课的目的是为了收割。可事实真的如此吗？\n广告真的重要吗？ # 我们无法否认广告所呈现出来的种种弊端，但是广告仍发挥着至关重要的作用。作为网民日常生活的一部分，一天可能十分之一到五分之一的时间都在短视频或者各种流媒体之中，作为一个占比如此多的时间，其覆盖受众已经远远超过了大部分行业。\n上周在腾讯云线下听了章鱼老师的分享，印象深刻的一句话是“工科是一种视角”。\n这让我想到生活中总能听到一种论调“短视频也叫工作？”，持这种观点的人，可能总是以消费者的视角来看待短视频，但是在一个良好的生态中，消费者只是其次，生产者才是关键。有优质的生产者提供内容，才会有优质的消费者。\n生活中你没有意识到的广告有哪些？ # 我们作为广告的受众，可能平时看广告也是同一种视角：\n在公众的日常生活里，能接触到的广告无非是线上和线下两种。\n线下的广告通常是静态的、平面的。如果没有特定的场景，在大家都习惯性忘记的今天，路人扫一眼甚至有可能完全不会发现到广告，能留下印象都是无从说起。于是很多商家通过各种方式增加公众在广告上的停留，最出名的莫过于华与华设计的蜜雪冰城的广告歌曲，将品牌的概念通过听觉印入每一个消费者甚至是路人的脑中。还有商家会选择在目光不得不长时间停留的地方植入广告，例如电梯的屏幕，厕所的墙，工作人员的衣服，甚至每一个从写字楼里走出来的员工带着的工牌本质都是广告的一部分。\n线上广告更是五花八门，它甚至在你没有解锁手机，进入网络世界之前就已经产生了。各类应用会用推送广告证明它的存在。开屏同样会碰到各类防不胜防的广告。而内容同样是广告，目前广告行业最活跃的莫过于各类汽车广告，一些汽车行业的创始人争相拍短视频广告，为什么要这么做？后面的章节我会分析。由互联网广告还延伸出来了公域和私域的概念，公域是分发，多账号多平台多时间段的内容目的就是增大宣传广度，因为非常关键的点在于，没有用户量就没有优质用户。如果想获得垂直的优质用户，首先需要做的就是增大宣传广度。所谓的私域则是一种“提纯”的手段，通过拉人进群的方式，在每次广告时 @ 出每一个人，亦或是通过朋友圈的每天曝光，强制增加目标用户在广告上的停留时间，这就是增加宣传深度。\n我身边很多人都以互联网行业工作者，科技工作者自居，认为广告就是消费行业的专属，殊不知，其所看的“三大顶会”，AI 科技组织和公司早已将广告植入在各种类型的宣传中盈利了。\n广告真的有价值吗？ # 国内市场的用户没有付费订阅的习惯，因此一个互联网项目如果没有广告，那么不是在消失就是在消失的路上了。如果一个项目没有广告仍然能够维持，那它就一定不是真正的互联网项目，没有广度的用户，充其量只能算借助互联网宣传的项目。\n毫无疑问，广告就代表互联网的商业价值。信息的分发广度决定了信息主体的广告价值。胖东来短时间内以极低的成本推送到了 10 亿网民的面前，其广告的价值远大于企业自身盈利能力的价值。\n之前我关于网络的博客中参考的一篇公众号文章，作者是 IPIP 的创始人高春辉，根据报道，他早期做手机之家时，让他真正下定决心 all in 网站就是因为接到了广告业务。字节跳动早期也是通过广告业务探索来支撑，类似的例子还有很多。大多数时候人们关注的是技术本身，是产品本身，但是却忽略了广告本身，或者没有意识到广告的存在。\n我自己的广告实践 # 我最近做了一个开源项目 bilive 项目地址 https://github.com/timerring/bilive 文档地址 https://bilive.timerring.com 自动监听并录制B站直播和弹幕、通过 whisper 推理语音识别字幕并渲染弹幕和字幕，自动切片并通过智谱 GLM-4V-PLUS 大模型生成吸引眼球的标题，自动投稿视频和切片到平台，兼容无GPU版本，兼容超低配置服务器与主机。\n如何让项目通过广告推广，我做了一个小型的尝试，在某开发者交流论坛中，帖子显示的顺序是按照最后一位回复的时间先后排列，用户会在帖子中提出问题或者感谢，我每个小时回复一次用户，以确保帖子始终能在平台用户的视线之内。很快一周之内项目收获了数百 stars。\n因此，我对于开发者类型的论坛定位就是一个早期的微博，同早期的微博一样，最开始微博的发展处于一个混沌的时期，平台在移动互联网时期飞速扩张，但是相应的规则并不完善，因此博主在拓展粉丝的同时，还可以通过自己的受众和知名度对广告商进行议价，微博也很难有精力针对平台内部博主限制，因为创作者同样也是稀缺资源，人人网，饭否，网易等平台都在扩张，给与创作者最优质的收入，获得最好的广告效果是博主、平台和广告商三赢的过程。但是等到蓝海扩展结束，进入一个红海存量或者还在被新兴事物挤压缩小的阶段，平台就不得不考虑规范化以及维持生存的问题了。\n很多时候我们都只会因为局限站在一种角度思考问题，例如平台的粉丝都会认为博主应该专注创作“好活”，不应该接商单。但是由于国内没有付费订阅制的习惯，加上 toC 的版权很难得到有效的保障，因此注定了媒体传播的行业就是要为广告服务。因此创作者思考的绝对不是接或者不接广告的问题，而是如何优化广告的问题。\n广告并不是详细叙述，而是植入“感觉”，创造期待 # 慢慢运行 bilive 的账号也拥有了一定的粉丝，也有小型商家让我推送广告，从我接广告和商家的交流经验来说，商家在乎的是你本身的规模以及宣传效果。因此很多时候我认为广告并不是要详细介绍产品本身，而在与植入“感觉”。\n一个好的广告并不是要把每一个优点，每一项指标都贴在海报上，让用户驻足细看，用户很少有时间和耐心在广告上，而是要把一种“感觉”植入用户的内心。让用户看到这个商品就能想到这种“感觉”，从而创造期待，然后在逐渐的了解中，做到超出预期（当然要想做到超出预期，广告就一定要真实，如果广告内容是虚假的，结果一定适得其反）。\n特别认同一句话，你眼中的你不是你，别人眼中的你不是你，而你眼中的别人才是你。\n这也同时解释了我对于一个现象的疑问，有时在网上总会看到两个人为了比“谁支持的博主更有钱”争得不可开交，相互发评论几十条，起初我还不能理解，浪费这时间做点别的不好吗。后来思考后我才明白，他们表面上争论的是这个问题，本质上还是争论的自我认同的问题，为了证明“我的眼光更高”以及“我认同这种感觉”。\n因此一个好的广告应该植入用户内心，让其认同他眼中的别人都是这种“感觉”，从而间接认为别人眼中的他也是这种“感觉”。\n广告就是先熟悉再“重复” # 通常人对于陌生的新鲜事物会本能抗拒，因此广告的第一个作用就是打破陌生，让用户熟悉。同样两种商品，如果用户对其中一种熟悉，那么就会自然地选择熟悉的那一种。很少有人会为了一个完全陌生的事物在短时间内直接抉择。熟悉之后广告的重点就是重复，因为只有在重复中才能留下印象。如果用户无法接受三字经类型的重复，就换一种重复的方式，做到内容新鲜，内核重复。汽车创始人争相拍短视频，就是熟悉和重复的过程。因为“品牌“并非通过某个爆款形成，而是以一定的节奏在你信息流里持续曝光。\n复盘我所做的内容 # 回到我的项目bilive 我的宣传语就只有一条：\n7 x 24 小时无人监守录制、渲染弹幕、识别字幕、自动切片、自动上传、兼容超低配机器，启动项目，人人都是录播员。\n这个项目的宣传省略了所有的细节描述，直接描述流程，让用户熟悉项目的整个运作过程，植入全自动化的省事感觉，“兼容超低配机器”植入要求门槛低的感觉，最后“启动项目，人人都是录播员”，让用户产生期待，从而点击项目主页再进行详细查看并尝试使用，我相信项目开发的功能以及使用文档会远超用户的期待，从而产生更多的有效使用及建议反馈。此外，正如我最开始在开发者论坛中做的一样，持续地重复曝光才是宣传的关键。\n偶然间发现，如今在前端框架中炙手可热的 Vue 也曾经历过开源项目推广的广告过程，看完尤雨溪的博客 First Week of Launching Vue.js 不禁会心一笑。\n再回到一开始，互联网的底层逻辑就是广告。一个不懂广告的人，一个抗拒营销的企业，恐怕还不理解商业社会的基本规则，等不到被 AGI 取代的那一天，就早已被淘汰了。\n"},{"id":18,"href":"/posts/understanding-clash-through-configuration/","title":"Understanding Clash Through Configuration","section":"Blog","content":"We can learn the proxy process of clash through the configuration file.\nClash # Clash is a popular tool which can use different protocols to access the resources.\nTo use the proxy, you may have received the subscription link. So what\u0026rsquo;s inside? We can dig it out.\nAbout configuration # When you fill the subscription link into the Clash, you will get a configuration file.\nI select some example items from the configuration file. And we\u0026rsquo;re able to conduct a detailed analysis.\nA sample configuration file mixed-port: 7890 allow-lan: true bind-address: \u0026#39;*\u0026#39; mode: rule log-level: info external-controller: \u0026#39;127.0.0.1:9090\u0026#39; dns: enable: true ipv6: false default-nameserver: [223.5.5.5, 119.29.29.29] enhanced-mode: fake-ip fake-ip-range: 198.18.0.1/16 use-hosts: true nameserver: [\u0026#39;https://doh.pub/dns-query\u0026#39;, \u0026#39;https://dns.alidns.com/dns-query\u0026#39;] fallback: [\u0026#39;https://doh.dns.sb/dns-query\u0026#39;, \u0026#39;https://dns.cloudflare.com/dns-query\u0026#39;, \u0026#39;https://dns.twnic.tw/dns-query\u0026#39;, \u0026#39;tls://8.8.4.4:853\u0026#39;] fallback-filter: { geoip: true, ipcidr: [240.0.0.0/4, 0.0.0.0/32] } proxies: - { name: HK02, type: ss, server: domain-or-ip, port: port-num, cipher: chacha20-ietf-poly1305, password: a-example-password, udp: true } - { name: \u0026#39;HK03 x2\u0026#39;, type: ss, server: domain-or-ip, port: port-num, cipher: chacha20-ietf-poly1305, password: a-example-password, udp: true } proxy-groups: - { name: custom-policy-group, type: select, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;] } - { name: Netflix, type: select, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;] } - { name: auto, type: url-test, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;], url: \u0026#39;http://www.gstatic.com/generate_204\u0026#39;, interval: 86400 } - { name: fallback, type: fallback, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;, \u0026#39;Antarctic\u0026#39;], url: \u0026#39;http://www.gstatic.com/generate_204\u0026#39;, interval: 7200 } rules: - \u0026#39;DOMAIN-SUFFIX,services.googleapis.cn,custom-policy-group\u0026#39; - \u0026#39;DOMAIN-KEYWORD,netflixdnstest,Netflix\u0026#39; - \u0026#39;DOMAIN,netflix.com.edgesuite.net,Netflix\u0026#39; - \u0026#39;DOMAIN-SUFFIX,fast.com,Netflix\u0026#39; - \u0026#39;IP-CIDR,8.41.4.0/24,Netflix,no-resolve\u0026#39; - \u0026#39;IP-CIDR,23.246.0.0/18,Netflix,no-resolve\u0026#39; - \u0026#39;DOMAIN-KEYWORD,guanggao,REJECT\u0026#39; - \u0026#39;DOMAIN-SUFFIX,icloud.com,DIRECT\u0026#39; - \u0026#39;DOMAIN-SUFFIX,zhihu.com,DIRECT\u0026#39; - \u0026#39;DOMAIN-KEYWORD,gmail,custom-policy-group\u0026#39; - \u0026#39;IP-CIDR,91.108.4.0/22,custom-policy-group,no-resolve\u0026#39; - \u0026#39;IP-CIDR6,2001:67c:4e8::/48,custom-policy-group,no-resolve\u0026#39; - \u0026#39;DOMAIN-SUFFIX,cn,DIRECT\u0026#39; - \u0026#39;DOMAIN-KEYWORD,-cn,DIRECT\u0026#39; - \u0026#39;GEOIP,CN,DIRECT\u0026#39; - \u0026#39;MATCH,custom-policy-group\u0026#39; Basic # In the path, we can divide the locations where the traffic passes into three layers:\nFrom your traffic source to the proxy software, such as your browser to the Clash you use. From the proxy software to the remote server, such as from the Clash you use to a server in Hong Kong. From the remote server to the target server, such as from a server in Hong Kong to the Google server. But no matter what software you use, these software will listen on the specific port, which will take over the traffic to the port. Generally, the port will use socks5 or http proxy. Http only can proxy the http request. But socks5 can proxy the tcp or udp request.\nmixed-port: 7890 allow-lan: true bind-address: \u0026#39;*\u0026#39; mode: rule log-level: info external-controller: \u0026#39;127.0.0.1:9090\u0026#39; The mixed-port is the port that HTTP(S) and SOCKS4(A)/SOCKS5 proxy services share to listen on. The allow-lan is whether to allow connections from other LAN IP addresses. The bind-address is the address that the proxy software listens on(Only valid when allow-lan is true). The mode is the mode of the proxy software(rule, global, direct). The log-level is the log level of the proxy software(info / warning / error / debug / silent). The external-controller is the address that the RESTful Web API listens on.\nDNS # dns: enable: true # Whether to enable DNS. ipv6: false # Whether to enable IPv6. default-nameserver: [223.5.5.5, 119.29.29.29] # The default DNS server. enhanced-mode: fake-ip # Use fake IP to resolve the DNS request. https://www.rfc-editor.org/rfc/rfc3089 fake-ip-range: 198.18.0.1/16 # The CIDR of fake IP. use-hosts: true # Whether to use the hosts file to resolve. nameserver: [\u0026#39;https://doh.pub/dns-query\u0026#39;, \u0026#39;https://dns.alidns.com/dns-query\u0026#39;] # The DoH server. fallback: [\u0026#39;https://doh.dns.sb/dns-query\u0026#39;, \u0026#39;https://dns.cloudflare.com/dns-query\u0026#39;, \u0026#39;https://dns.twnic.tw/dns-query\u0026#39;, \u0026#39;tls://8.8.4.4:853\u0026#39;] # The fallback DNS server. fallback-filter: { geoip: true, ipcidr: [240.0.0.0/4, 0.0.0.0/32] } # The fallback filter. Redir-Host # The redir-host mode and fake-ip mode are the two modes of TAP/TUN. And most softwares will not use the system proxy, so the proxy system virtualize a network interface which takes over all the traffic(that\u0026rsquo;s what our phones do). So the TAP/TUN mode is working on the network layer, so it can not get the domain name, it can only get the IP address. So it will use other methods to get the domain name, the mothod is intercepting the DNS request at the 53 port and maintain a mapping table. When the terminal sends a DNS request, it will first check the mapping table, if the domain name is in the mapping table, then it will directly return the IP address. If the domain name is not in the mapping table, then it will send the DNS request to the DNS server, and then update the mapping table.\nYou can refer to my Real Computer Network to understand the OSI model.\nBesides, the TAP/TUN mode will not be able to encapsulate network layer data packets, so it isn\u0026rsquo;t the VPN(only can encapsulate the network layer data packets can implement the remote networking and can be called as VPN, the feature of VPN is obvious, that means it can be detected easily). Some commands in the network layer(eg. ICMP protocol) like ping will not work. The ttl is the latency between the terminal and the virtual network interface.(If it uses the fake-ip mode, then the ip of target domain such as google.com is also a fake ip).\nBut if multiple domains are deployed on the same IP, or are polluted to the same IP, then the redir-host will not work(except for Sniff). In this case, the clash will use the fallback DNS(nomorally use the overseas encrypted DNS server to avoid pollution) to resolve the DNS request. But the IP returned is just used as a key in the mapping table, does it really matter? That\u0026rsquo;s why the fake-ip mode appears.\nThe default nameserver means the DNS server that the local clash will use to resolve the DNS request, usually used in local resolution(direct mode). If the domain needs proxy, then use the fallback DNS to resolve the DNS request. Fallback means if the default DNS server returns a foreign IP(Always redirect to the unknown foreign IP), then use the fallback DNS servers return to make sure the foreign IP is not polluted.\nThe Classless Inter-Domain Routing (CIDR) is a method of allocating IP addresses. And the default CIDR of fake IP is 198.18.0.1/16, which is a reserved IP address. When the DNS request is sent to Clash DNS, the Clash kernel will allocate an idle fake-ip address from the pool through the management of the internal domain name and its fake-ip address mapping.\neg. You can find that the 198.18.1.79 is a fake IP, which is allocated by the Clash kernel.\nbase ❯ curl -v http://google.com \u0026lt;---- cURL asks your system DNS (Clash) about the IP address of google.com * Host google.com:80 was resolved. * IPv6: (none) * IPv4: 198.18.1.79 ----\u0026gt; Clash allocates 198.18.1.79 as google.com * Trying 198.18.1.79:80... \u0026lt;---- cURL connects to 198.18.1.79 tcp/80 ----\u0026gt; Clash will accept the connection immediately * Connected to google.com (198.18.1.79) port 80 ----\u0026gt; Clash looks up in its memory and found 198.18.1.79 being google.com ----\u0026gt; Clash looks up in the rules and sends the packet via the matching outbound \u0026gt; GET / HTTP/1.1 \u0026gt; Host: google.com \u0026gt; User-Agent: curl/8.7.1 \u0026gt; Accept: */* \u0026gt; * Request completely sent off \u0026lt; HTTP/1.1 301 Moved Permanently ...... Fake IP # Why fake IP?\nSome regions not only block the specific IP, but also pollute the DNS. In other words, the domain name is resolved to an incorrect IP. Due to the feature of TCP/IP, when the application initiates a TCP connection, it first sends a DNS question (sends an IP Packet), obtains the IP address of the server to be connected, and then directly connects to this IP address.\nSo we need to proxy the DNS request. The process is that the request needs to be examined locally first, (if needs proxy) then request the remote server DNS, then return the resolution result. Then the clash core maps the IP address to the domain, and then match the rules. In this process, you can find that the DNS request is not necessary. Because the IP returned is just used as a key with the value(domain), but if the fake ip occasionally match specific rules, and was redirected wrongly, which will cause the failure of visiting. Considering these issues, the official has stopped the redir-host mode directly. So, the Fake-IP technology appears.\nBut in fake IP, the clash core will directly return a fake IP to the client. And the client will use the fake IP to request the resource. Then in the clash core will map the fake IP to the domain name. And then use the domain name to match the rules. This will omit the DNS request. Which not only saves time, but also avoids the DNS leakage.\nBut it still has some problems, because any system has a DNS cache mechanism. If one day, due to some reason, you need to turn off the proxy software, then the client will not get any response when requesting this fake IP. You need to manually refresh the system DNS cache to solve it.\nproxies # Then let\u0026rsquo;s talk about the proxies. About the ratio of the proxy, I have written a lot in the Real Computer Network. You can review it.\nproxies: - { name: HK02, type: ss, server: domain-or-ip, port: port-num, cipher: chacha20-ietf-poly1305, password: a-example-password, udp: true } - { name: \u0026#39;HK03 x2\u0026#39;, type: ss, server: domain-or-ip, port: port-num, cipher: chacha20-ietf-poly1305, password: a-example-password, udp: true } The type is ss, which means the proxy is using the Shadowsocks protocol.\nThe udp is to enable the UDP proxy. Or you will not be able to proxy the UDP even in the tun mode.\nThe cipher is the encryption method of the proxy server. The chacha20-ietf-poly1305 is the encryption method of password. And the encryption methods which are supported by the Shadowsocks protocol are:\naes-128-gcm aes-192-gcm aes-256-gcm aes-128-cfb aes-192-cfb aes-256-cfb aes-128-ctr aes-192-ctr aes-256-ctr rc4-md5 chacha20-ietf xchacha20 chacha20-ietf-poly1305 xchacha20-ietf-poly1305 proxy-groups # proxy-groups: - { name: custom-policy-group, type: select, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;] } - { name: Netflix, type: select, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;] } - { name: auto, type: url-test, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;], url: \u0026#39;http://www.gstatic.com/generate_204\u0026#39;, interval: 86400 } - { name: fallback, type: fallback, proxies: [HK02, \u0026#39;HK03 x2\u0026#39;, \u0026#39;Antarctic\u0026#39;], url: \u0026#39;http://www.gstatic.com/generate_204\u0026#39;, interval: 7200 } The proxy-groups can be understood as filters one after another. So when you send a request, at which filter it will be intercepted depends on the match between the request and the rules. You should choose a meaningful name for the proxy-group. The type mainly includes four types:\nselect: Select the proxy manually in the proxy-group. url-test: Test the response time of the proxy-group. And use the proxy with the shortest response time. The url is used to ensure the connection to network to test the response time. 204 is the response code of the no content page. For more information, you can refer to the rfc7231. fallback: Use the first proxy of the proxy-group, if breakdown, use the second proxy of the proxy-group\u0026hellip; load-balance: Use the proxy with the least number of connections. relay: The traffic will be relayed through the proxies in order in the proxy-group. (Not support UDP). rules # The basic format of the rules is:\nTYPE,ARGUMENT,POLICY(,no-resolve) rules: - \u0026#39;DOMAIN-SUFFIX,services.googleapis.cn,custom-policy-group\u0026#39; - \u0026#39;DOMAIN-KEYWORD,netflixdnstest,Netflix\u0026#39; - \u0026#39;DOMAIN,netflix.com.edgesuite.net,Netflix\u0026#39; - \u0026#39;DOMAIN-SUFFIX,fast.com,Netflix\u0026#39; - \u0026#39;IP-CIDR,8.41.4.0/24,Netflix,no-resolve\u0026#39; - \u0026#39;IP-CIDR,23.246.0.0/18,Netflix,no-resolve\u0026#39; - \u0026#39;DOMAIN-KEYWORD,guanggao,REJECT\u0026#39; - \u0026#39;DOMAIN-SUFFIX,icloud.com,DIRECT\u0026#39; - \u0026#39;DOMAIN-SUFFIX,zhihu.com,DIRECT\u0026#39; - \u0026#39;DOMAIN-KEYWORD,gmail,custom-policy-group\u0026#39; - \u0026#39;IP-CIDR,91.108.4.0/22,custom-policy-group,no-resolve\u0026#39; - \u0026#39;IP-CIDR6,2001:67c:4e8::/48,custom-policy-group,no-resolve\u0026#39; - \u0026#39;DOMAIN-SUFFIX,cn,DIRECT\u0026#39; - \u0026#39;DOMAIN-KEYWORD,-cn,DIRECT\u0026#39; - \u0026#39;GEOIP,CN,DIRECT\u0026#39; - \u0026#39;MATCH,custom-policy-group\u0026#39; DOMAIN: route the request match the DOMAIN to the POLICY. DOMAIN-SUFFIX: route the request match the domain suffix to the POLICY. DOMAIN-KEYWORD: route the request match the domain keyword to the POLICY. IP-CIDR: route the request match the IPv4 address to the POLICY. (if you want to skip DNS resolution, add the no-resolve option, then the domain will not be resolved, so it cannot match the rules, and directly skip this rule) IP-CIDR6: route the request match the IPv6 address to the POLICY. (if you want to skip DNS resolution, add the no-resolve option) GEOIP: route the request match the country to the POLICY. Use the geolite2 database. Clash will resolve the domain name to the IP address, then find the country code of the IP address. If you want to skip DNS resolution, add the no-resolve option. eg. 'GEOIP,CN,DIRECT' redirect the request targeting CN ip to the DIRECT policy. MATCH: route the remaining request to the POLICY. For more info, you canrefer to the Clash Rules.\nReference # https://www.pupboss.com/post/2024/clash-tun-fake-ip-best-practice/ https://blog.skk.moe/post/what-happend-to-dns-in-proxy/ https://www.youtube.com/watch?v=qItL005LUik "},{"id":19,"href":"/posts/a-brief-introduction-to-dns/","title":"A Brief Introduction to DNS","section":"Blog","content":"In my mind, DNS is the key of the internet. I always believe if you control the DNS, you control the Internet world. So let us get started to know the DNS.\nHosts # Long long ago, if we want to access a computer, we need to know its IP address. But it\u0026rsquo;s hard to remember, and if the computer\u0026rsquo;s IP is changed, we need to notify the others.\nSo we need to make a list to map the computer\u0026rsquo;s name to its IP address and save it in every computer as well as updating from a specific computer which to maintain the list. And the list is called hosts.(eg. timerring: 88.88.88.88) And this is the origin of ARPANET.\nBut with the development of Internet, the number of IP is increasing, the hosts file is too large, and the names will be conflicts. Then comes the DNS.\nDNS # Paul Mockapetris proposed the Domain Name System in 1983, which is a distributed database that maps domain names to IP addresses.\nSo every time we want to access a website, we just need to query the website domain name to the DNS server and get the corresponding IP address.\nWe don\u0026rsquo;t need the local hosts records anymore.(The hosts file of the computers are empty.)\nDHCP # The ip of DNS server may be dynamic(for residential broadband). Every time you go online, it will be allocated by the gateway, which is so-called DHCP mechanism. (Dynamic Host Configuration Protocol)\nAnd it may be assigned the fixed address. You can check the DNS server ip of your Linux in /etc/resolv.conf.\nDNS protocol # First we need a specific rule to ensure the domain name is unique. So just like th e address in real world, from the street to city, the domain also obey the rule home.google.com.\nThe level of domain # So how can the DNS server know the ip of every domain? The answer is hierarchical query. Look back to the info of query math.stackexchange.com.. There is a pot . in the end, which means the root domain. It is usually omitted. So the level is as follows:\nroot domain: . top-level domain(TLD): such as .com. second-level domain(SLD): This level domain can be registered by user normally. host: user can assign the name of host, such as www Domain Name Resource Record # Every domain has a corresponding record in the DNS, and its format is:\nDomain_name Time_to_live Class Type Value Domain_name: The domain name. Time_to_live: The time to live of the record. Class: Most of the time is IN(Internet). Type: The type of the record. Value: The value of the record. The type of the record # The type of the record is as follows:\nA: address record, return the IPv4 of domain AAAA: address record, return the IPv6 of domain NS: Name server record. Every level of domain has its own NS record. This record point out the server of this level domain. These server know the every record of sublevel of domain.(Authoritative Name Server) MX: Mail eXchange record: return the server address of receiving email. CNAME: Canonical Name record: return another domain, which means the domain is a springboard for another domain. PTR: Pointer Record: PTR is used to check if the ip actually possesses the domain which it claims to. DNS server # Second, we have the unique domain name, but we query the same DNS server is not realistic. Now we need to split the server according to the top level domain(TLD) to form the DNS zone.\neg. Now every zone has a master server and many slave servers to backup and expedite the query. These servers are called Authoritative Name Servers.\nAnd it save the two types of records: This zone\u0026rsquo;s domain name resource records. This zone\u0026rsquo;s parent DNS and sub-DNS server records(mainly NS records). Now you can find that the A and B zone don\u0026rsquo;t have the parent DNS server, so how to ensure they know each other? The answer is the root DNS server ..\nYou can find the root DNS server here: root DNS server.\nDomain Name Resolution # Every time you connect to the network, you will get default DNS server(operator provide) or you can use the public DNS, and you query the domain name to the DNS server(so-called local DNS server).\nIf the domain name is actually in the same zone, then the local DNS server will return the record directly. Else the local DNS server will query the root DNS server(The root domain server is fixed, which is built in the DNS server.) to get the parent DNS server of the domain. And then query the DNS server recursively(eg. www.google.com: .-\u0026gt; com -\u0026gt; google.com -\u0026gt; www.google.com -\u0026gt; xx.xx.xx.xx). Caching Mechanism # Most of us usually visit the just 20% websites or we may visit the different pages of the same website, so our browser and OS can cache the records of these websites to improve the query efficiency.\nSo the Time_to_live segment is used to determine the cache time of the record. For those stable domain eg. google.com, the Time_to_live is set to a large value. And for those who often changes the domain resolution results, the Time_to_live is set to a small value.\nMeanwhile, the DNS server will also cache the records of the domain just as our computer do.\nDNS leaking # Check your DNS is leaking or not. https://ipleak.net/ It uses the random sub domain to record the last DNS servers to the authorative DNS.\nBesides, check this https://browserleaks.com/webrtc Avoid the WebRTC, it will leak your public ip because it will send the stun packet via UDP, and the UDP somehow cannot be proxied by the http proxy. But even you use the socks5 proxy, it will still leak ip because the browser like chrome will not give the UDP packet to the proxy. (If you use the tun mode or router proxy, you still need to check the node has the UDP proxy in the configuration.)\nThe main reason of DNS leaking is that the DNS request is plaintext, so every server in the request process will know what you are requesting. If the website you visit does not need to DNS request, then it can directly connect or proxy. But if the website does not hit the rules, it will send the DNS request locally. And the local request will only used to match the rules(redir-host), so the mode is abandoned by the official.\nMethods to avoid DNS leaking:\nDoH: DNS over HTTPS mainly HTTP/2 443 (RFC 8484) DoT: DNS over TLS mainly UDP 853 Make all requests encrypted and send to remote node, and let the remote node process all the requests. (Fake IP mode: have the TCP connection and domain name, the proxy client can easily package it using SOSCKS5 or some other protocol and send to the remote node.) For more details, you can refer to my blog Understanding Clash Through Configuration.\nExample process # To begin with, you should know the OSI model. I have drawn a good image to explain it. You can also read my previous blog Real Computer Network. OSI model So just imagine the process of go surfing the internet. eg. you query google.com on your browser, and then you get the page, what happened?\nIn the common case, when you purchase the broadband, the operator will provide you a Fiber - optic Modem, and you will buy a router. The router connects to the internet via PPPoE and get the public WAN ip (in fact still a intranet ip) and the DNS servers ip (common two DNS servers). Your router is as the gateway of your local network, so it will has own local network ip, and it will allocate the ip and DNS server ip to your devices through DHCP(commonly the DNS ip and the gateway ip are all the router\u0026rsquo;s local ip).\nYour browser first checks the browser\u0026rsquo;s cache to see if it has the ip of google.com, and then checks the OS\u0026rsquo;s cache(include the host file if there is the mapping relationship). If there isn\u0026rsquo;t, it will send a DNS request.(eg. tell me the ip of google.com) In the transport layer, the source port is eg.222 and the default destination DNS port is 53. In the network layer, the source ip is your computer\u0026rsquo;s ip 192.168.1.10 and the destination ip is the DNS server\u0026rsquo;s ip 8.8.8.8. But the DNS ip you cannot find locally, so you need to send the DNS request to the gateway you connect. And because the communication via MAC address in the same network, so it will be processed in data link layer. In data link layer, the source MAC address AA-AA-AA-AA is your computer\u0026rsquo;s MAC address and the destination MAC address CC-CC-CC-CC (get through ARP protocol) is the gateway\u0026rsquo;s MAC address. Then it will be sent through NIC and in the cable. The switch will receive the packet and forward it to the gateway(eg.router). In the data link layer of router, router finds the MAC is itself and resolve it pass to the network layer. But it cannot find the DNS 8.8.8.8 in its routing table, so it will send the packet to the default router(in the public network). Before sends to the public network, the router will use NAT to change the source private ip to the public ip(the WAN ip of router). In the public network, the routers will find and change the MAC addressed to forward the packet to the next router. Then the DNS server will receive the packet, and resolve the packet, in the transport layer, it find the destination port is 53, so it knows it is a DNS request. And it resolve the ip of google.com and return the ip. And the return process is similar to the request process. Finally, after those, your computer will receive the ip of google.com and request the ip of google.com to obtain the page, and the process is similar as above. But sometimes, the process won\u0026rsquo;t be so smooth, due to the DNS server is overseas, so the traffic needs to go through the public exit port(except for using the IPLC intranet of ISP). Every packet will be checked, thus causing the DNS pollution（tampers a not exist ip）, TCP reset(sends the RST packet in advance toreject the connection request), block ip or active detection.\ndig # The dig command is a powerful tool used for querying Domain Name System (DNS) servers.\neg. dig baidu.com which is equivalent to dig a baidu.com (record type is A).\n# You will see the query parameters and statistics. ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; baidu.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 17961 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 # This is the query content `A` record is the abbreviation for address. ;; QUESTION SECTION: ;baidu.com.\tIN\tA # This is the answer from server. `6` means that TTL which is the abbreviation of `Time to live`. ;; ANSWER SECTION: baidu.com.\t6\tIN\tA\t198.18.28.63 # This is the conclusion of the query. # You can find the DNS of your machine. The #53 means the port, which is the default port of DNS. ;; Query time: 1 msec ;; SERVER: 198.19.0.3#53(198.19.0.3) ;; WHEN: Thu Dec 26 22:50:14 CST 2024 ;; MSG SIZE rcvd: 43 dig +short baidu.com: Show in brief only get the IP dig @4.2.2.2 baidu.com: Query through the public DNS server via @DNSserver, such as 8.8.8.8 of google and 4.2.2.2 of Level3. dig ns com: You can query the each level of domain separately. dig mx github.com: Query the mail server of the domain. dig -x ip: Query the PTR record of the ip. dig +trace baidu.com: Show the trace of the query. First list all the root servers, then query these ip for the toplevel and sublevel server. But in fact, most of time the server first reply will be cached, and you will just see the cached result (except you are the first user to query a very niche domain, at that time you can actually see the whole process from the root server to the TLD to the SLD to the host). Normally the cache results just like the following: ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; +trace baidu.com ;; global options: +cmd .\t221\tIN\tNS\tm.root-servers.net. .\t221\tIN\tNS\td.root-servers.net. .\t221\tIN\tNS\th.root-servers.net. .\t221\tIN\tNS\tl.root-servers.net. .\t221\tIN\tNS\tf.root-servers.net. .\t221\tIN\tNS\tg.root-servers.net. .\t221\tIN\tNS\ta.root-servers.net. .\t221\tIN\tNS\tj.root-servers.net. .\t221\tIN\tNS\tb.root-servers.net. .\t221\tIN\tNS\tk.root-servers.net. .\t221\tIN\tNS\ti.root-servers.net. .\t221\tIN\tNS\tc.root-servers.net. .\t221\tIN\tNS\te.root-servers.net. ;; Received 239 bytes from 198.19.0.3#53(198.19.0.3) in 9 ms baidu.com.\t6\tIN\tA\t198.18.28.63 ;; Received 43 bytes from 198.18.29.158#53(c.root-servers.net) in 0 ms Above are thirteen root domain server all over the world. From A.ROOT-SERVERS.NET to M.ROOT-SERVERS.NET.\ndig cname facebook.github.io: The cname is mainly for the internal jump of domain, which provide the server configuration with more convenience. This is transparent to users. ... ;; ANSWER SECTION: facebook.github.io. 3370 IN CNAME github.map.fastly.net. github.map.fastly.net. 600 IN A 103.245.222.133 We can see that the CNAME of facebook.github.io points to the github.map.fastly.net, and return the ip of github.map.fastly.net. So when we tend to change the ip, we can directly change the configuration of github.map.fastly.net, there is no need to change the facebook.github.io anymore.\nYou cannot set other records anymore after you set CNAME. This will avoid the conflicts with other records because CNAME means a substitute.(eg. test.com and try.com have their own MX records, if the rules are not the same, then there will be some conflicts)\nwhois # Find the register info of domain\nwhois github.com Pay attention to the similar command whoami which is used to check the user name of system.\nReference:\nhttps://www.rfc-editor.org/rfc/rfc883.html https://viewdns.info/ https://www.ruanyifeng.com/blog/2016/06/dns.html https://www.petekeen.net/dns-the-good-parts/ https://selfboot.cn/2015/11/05/dns_theory/ https://www.youtube.com/watch?v=GQg5JIQIjgk https://blog.skk.moe/post/what-happend-to-dns-in-proxy/ "},{"id":20,"href":"/posts/real-computer-network/","title":"Real Computer Network","section":"Blog","content":"For the computer network, I believe that most people have learned it in the course of university or college. No matter whether you are familiar with it or not, this article will give you a different perspective of the network. It can really help you a lot.\nBasic concepts # Providers # IDC: Internet Data Center, which is the data center of the internet. It is the place where the servers are located.\nISP: Internet Service Provider, which is the internet service provider. It is the company that provides the internet service.\nMain Public Cloud Service Providers:\nAWS: Amazon Web Services, which is the cloud service of Amazon. Azure: Microsoft Cloud Service, which is the cloud service of Microsoft. Alibaba Cloud: Alibaba Cloud, which is the cloud service of Alibaba. GCP: Google Cloud Platform, which is the cloud service of Google. PCCW(Recommended): Pacific Century CyberWorks, which is the internet service provider of Hong Kong, China.(make sure it is Two-way instead of one-way) Besides, if your neighbors(the shared users of the server) are all \u0026ldquo;one-click script\u0026rdquo; masters, using serverspeeder, violent modification BBR, KCPTun multiple times more packet sending, etc. But you don\u0026rsquo;t do any optimization, then even you have a whole submarine cable, you will still be slower than them.\nWhen you buy a VPS, the bandwidth is provided by the operators which the VPS supplier purchase from the operators.\nNetwork Circuits # Public Network # You can check your network AS info here: https://ipinfo.io/\nInternational export: The international export is the last port of the internet in China when the traffic is going to the overseas. Mainly located in Beijing, Shanghai and Guangzhou. 163: AS4134. The 163 network is the backbone of the internet in China. And mainly used by China Telecom. The backbone node is started with 202.97. There is basically no performance bottleneck when accessing each other within the 163 network in China. Congestion only occurs at the international export..\n169: AS4837. The 169 network is the backbone of the internet in China. And mainly used by China Unicom. AS 9929: Also known as the former China Netcom Internet (CNCNET). The AS number of China Unicom\u0026rsquo;s A network backbone is 9929. It was built by the China Netcom, and after the merger of China Netcom and China Unicom, so the A network was available. Now the users are less and mainly aims for the government. AS9808: The AS9808 is the backbone of the internet in China. And mainly used by China Mobile. The PCCW line is currently among the lines between China and Hong Kong, China or those from China to other regions in Southeast Asia where transshipment in Hong Kong, China is required. It is the line with the best quality in China except for the pure CN2 GIA line. Educational Network / China Science and Technology Network / Private Broadband. CN2(CNCN): China telecom next carrier network, which is the backbone of the internet in China(Public network), which is more advanced than the old 163 network. The backbone node is started with 59.43. CN2GT: CN2 Global Transit, cheaper but congested, in CN2 GT product in the city → province → international export section is 163 network, the international export → overseas access point section is CN2 network, the return is the same. CN2GIA: CN2 Global Internet Access, expensive but less congested.(eg. Bandwagonhost has the most stable and cheapest CN2GIA line, but it is the key examined object of domestic.) GIA the whole network is CN2 network. Dedicated Network # IPLC: International Private Leased Circuit, which is the international dedicated line.\nBut for many service suppliers, it is just the intranet of Alibaba(深港means Alicloud shenzhen \u0026ndash; Alicloud HK), which usually purchase multiple end to end IPLC lines to connect the every data center. Then it has two pros:\nThe bandwidth in IPLC is dedicated, which is more stable than public network.(The decicated line is normally described the physical line, the most traffic in Submarine optical cable is the public network traffic and small part is the IPLC traffic.) The traffic when transiting, it will not go through the specific examination. IEPL: International Ethernet Private Line, which is the enhanced version of IPLC. It is a dedicated management bandwidth service from end to end.\nAnycast: it is a network technology that allows a single IP address to be broadcast to multiple locations. That means the IP will be the same, but the location is different.\nThis IP address is in the physical link between domestic and abroad. When users access this IP address, they will be connected to the nearest server. Just like the CDN. The cons:\nThe bandwidth is bind to the single IP address, so if it was DDOS, it is hard to deal with it. Expensive. Service Concepts # The three major operators are paid inter-network settlement, which means the traffic you consume is across the operators, they will pay the cost internally.\nQoS: Quality of Service, which is the service quality of the network. It can dynamically adjust the priority of the traffic, such as video calls(bandwidth first), online games(latency priority), etc.\nSLA: Service Level Agreement, which is the agreement between the supplier and the user. It is the service level of the supplier.\nBGP: Border Gateway Protocol, which can dynamically select the best route.(when you buy vps, you can easily find it on the supplier website) Which means the same IP in multiple operator\u0026rsquo;s network is directly connected.\nRedirect: Redirect data from one server to another. Alibaba Cloud public network transit is more common in small-scale suppliers redirect.\nPort: The port is the communication endpoint of the network. It is the port of the server.\nIP # IP database # IP Database stores IP address and physical address mapping.\nThe most used domestic IP database is IPIP. The overseas is MaxMind. Cellular Base Station # When using the cellular network, the IP address is the private IP address, and then it will be converted to the public IP address through the NAT. This situation leads to everyone using the same IP segment to access websites or apps. Generally, we refer to these relatively fixed IP segments as base station IP addresses.\nSo it is hard to locate the IP address to the specific city, which means the same IP address can be in different cities. And sometimes a series of IP is assigned to the 2~3 cities. Due to the NAT，every IP address corresponds to many users, so suspending the IP address will affect many users. Roaming: When you are roaming, the IP address will be changed. It\u0026rsquo;s mainly has three operators: mobile: roaming to the local network. If your card is in Beijing, and you go to Shanghai, then you will see the IP of Shanghai. Unicom and Telecom: roaming back to the local network. If your card is in Beijing, and you go to Shanghai, you will still see the IP of Beijing. So that accounts for the reason why you are using your card abroad, you are still blocked to visit websites. Cause you are roaming back to china and then try to access the websites. Check IP # https://ip.skk.moe/\nIP question # Why the ip is not correct?\nYou are using the phone to test? (It is the base station\u0026rsquo;s fault) What is your current operator? (If it is the secondary operator, it is the fault of the third-party export) What browser are you using? (It is the cloud acceleration\u0026rsquo;s fault) What is the third-party export?\nEvery operator will not only have their customers, but also have to obtain the network export, but the backbone networks are built by primary operators. So if the secondary operator wants to access the internet, it will have to pay the access fee to the primary operator. The primary operator avoids the competition, so it will bring up an expensive fee. But some people in the primary operator will sell them in a lower price, which is usually used by the secondary operator informally.\nIP attribution # The IP attribution identified based on your access purpose: Residential broadband, Business broadband, IDC, etc.\nNative IP # Native IP: The operator\u0026rsquo;s IP address. Broadcasting country is generally the same as registration country. Normally, it can used to unlock the hulu, netflix, etc. Because the Native IP is generally not used to the cloud computing service or have a good reputation.\nBroadcast IP: The IP address of the VPS is not the same as the location of the VPS. That means this IP is from another country / region.\nStreaming media unlock: Many streaming media platforms will restrict the specific IP access due to the copyright issues. Generally, the network operators(eg.HKT) have their own IP, which is used in commercial or Residential broadband. And the IP won\u0026rsquo;t be blocked because they are all the objective customers. Besides, the Residential broadband is hard to blocked because it is dynamic.\nProtocols # Shadowsocks: the fastest rtt.\nShadowsocksR.\nV2Ray(Vmess is the self protocol, V2Ray is the collection of protocols): more handshakes, which means slower rtt. Vmess + TLS encryption + websocket, which is more stable.\nTrojan: fix some cons of V2Ray. The core is only websocket + TLS. (TLS is the most secure which banks are using). It imitates the normal http request and works on the 443 port. If it receives the illegal request, it will provide service, or it will transit the traffic to nginx, and the nginx deal with the request. Its behavior is similar to nginx, so it is hard to detect. Meanwhile, in order to avoid the malicious detection, it will redirect the 80 port traffic to the 443, and only open the 80 and 443 port, which is similar to the normal web server.\nobfs (simple-obfs): it is a tool that can encrypt the traffic. It can be used to avoid the detection. obfs has two modes, one is HTTP, the other is TLS.\nDNS # DNS is the domain name system, which is the system that can translate the domain name to the IP address.\nNo matter how we use PPPoE to dial up or connect the optical cat through DHCP, the Internet service provider (ISP) will send you two DNS. For convenience, I call these two DNS as ISP DNS.\nIn the DNS resolution process, the user initiates a request to the recursive DNS, and the recursive DNS requests the resolution result from the authoritative DNS. In other words, the recursive DNS plays a forwarding role. The ISP\u0026rsquo;s DNS is a recursive DNS; at the same time, some individuals or Internet service providers also set up their own recursive DNS for everyone to use, which is called public DNS.\nSome famous public DNS:\nCloudflare DNS: 1.1.1.1, 1.0.0.1 Google Public DNS: 8.8.8.8, 8.8.4.4 Alidns: 223.5.5.5, 223.6.6.6 Tencent DNSPod: 119.29.29.29, 119.28.28.28 For most people, the ISP DNS provided by the operator should be the most accurate and suitable, with a short response time and the most accurate CDN resolution result.\nBut the operator often does DNS pollution, it will lead the user to their cache server or some advertising mirror website or tamper the TTL, which will lead to the DNS load less.\nBut the public DNS does not accelerate the resolution speed. Public DNS is a local DNS service provided by some enterprises, which usually provides one or more Anycast IP addresses, but actually has multiple cluster services.\nWhen users go online, the client will request the resolution from the A address in the cluster, this A address is called DNS entry; the public DNS will use the B address in the DNS cluster to compare with the IP library when judging the user\u0026rsquo;s source, this B address is called DNS exit.\nSo in the process of going online, users will get the resolution from the DNS entry, and the NS server will allocate the intelligent resolution to the DNS exit. If the DNS entry does not have the requested resolution cache, it will request the upper DNS to query, and finally request to the NS server, till then the user get the resolution result.\nHence, when the DNS entry and the DNS exit are inconsistent with the user\u0026rsquo;s actual network, it may lead to the DNS resolution result not being the optimal.\nCDN # CDN is the content delivery network, which can provide the content to the user faster and more reliable via the nearest server.\nBesides, the DNS exit is very important for CDN. The public DNS is essentially forwarding your query request to the upstream DNS; without EDNS, the authoritative DNS of the CDN will determine your operator and your location based on the request IP used by the public DNS (that is, the DNS exit), and then return the nearest node IP. In brief, CDN will return the nearest IP to the DNS exit.\nFor more information, you can refer my article A brief introduction to DNS\nProxy # Every traffic transit in public network across the countries will be examined.\nThe proxy means that the traffic is go through the proxy server.\nProxy Types # The basic proxy methods are mainly three types:\nSoftware Proxy: VPN: virtual private network which can ensure the end-to-end communication security. But nowadays, it might remains some risks. Encrypted traffic: mainly exists in the Shadowsocks, SSR, V2Ray and Trojan protocols, which usually encrypt the traffic locally and send to the transit server to forward and to the remote server to decrypt it. And the protocols should be implemented in the application layer, which means you have to used some applications to use it, such as Shadowsocks, V2Ray, Clash, Surge, etc. There still exists some issues, the application can only address the traffic which it can takes over. It(Without TUN mode) can not deal with the traffic which is on the OS layer, such as the UWP, some banks software, etc. The tun mode which can virtualize the network interface, and forced take over all the traffic. Hardware Proxy: can also called as router proxy, which is the end of whole internet. But the issue is that some router are not designed for this purpose, so the computing ability cannot meet the requirements of encryption and decryption. Gateway Proxy: it is usually implemented by the software installed on the PC, and via the CPU, it can easily complete the tasks. And you can change the nodes in the software. Ratio # The most suppliers will take all the traffic (upstream and downstream) into account.\nThe ratio between the traffic you consume and the traffic the supplier statistics.\neg. You use the 0.5x ratio node, and you consume 100G, then the supplier statistics is 50G.\nWhy there are different ratio nodes?\nThe ratio is related to the line quality and user experience. Now the supplier have two types of lines: Direct line: The line is directly connected to the overseas proxy server via public network. But the transmission effect is poor because the interconnection bandwidth between the overseas operator and the domestic operator is limited, and the domestic operator usually limits the speed of the data flow from the mainland. Besides, if you are the customer of unicom and the overseas server optimize the telecom, then you will get poorer performance than the telecom customer. Transit line: Add the transit server, which means the traffic will be transit through the server, hence the traffic is cost in every transit server, so the ratio is high. But it can provide more stable and faster service. BGP transit: The domestic transit server will provide the BGP, so you will have a better experience. Normally, it will use some tunnel protocols to balance the traffic and improve the stability. IPLC transit: Transit through the IPLC eg. SZ-HK, and then from HK to overseas proxy server. Latency # Note: The RTT is not the speed. The RTT is just the building time of the connection. The speed will depend on the shortcomings of the whole network.\nPING # ping aims to send a ICMP request to the target host and wait for the response.\nThe program will estimate the loss rate of data packets and the round-trip delay time based on the time and the number of successful responses.\nicmp ping: the classic ping. It test the latency between the machine and the transit server. tcp ping / ​http ping: It test the latency of the data packages of corresponding protocol. Normally, it will be slower than the icmp ping. Node selection mechanism # Load balancing url-test: It normally send the request to specific url, and select the best node. fall­back SSID Strategy # Traffic diversion # The traffic diversion is the strategy that can distribute the traffic to the different server, which can speed up the access speed.\nPAC1 # Proxy auto con­fig which is a method of web proxy. It can automatically select the suitable proxy server and only affect the browser.\nIt mainly depends on the specific rules which maintained by community, such as gfwlist.\nRouter traffic diversion # For traffic diversion in the routing table, you can refer to SSR-win. There are PAC diversion rules and routing diversion. For routing diversion, you need to add a SOCKS5 proxy in the browser by yourself or use Proxifier to set up a system proxy. Similarly, the settings of V2RayN on Windows also involve routing diversion. As for SS/SSR on Android, it is based on ACL (Access Control List) diversion, and there are ACLs made by third parties. On iOS, there is rule-based diversion. Since common protocols themselves don\u0026rsquo;t stipulate how to conduct diversion, it is all achieved by the software itself.\nStrategy diversion # proxy, direct, reject\nSocks5 # Socks5 is the protocol of the Session Layer, which is lower than the HTTP protocol. Socks5 mainly focus on the data package transmission, and it is not concerned with the specific protocol and usage.\nSocket is more like a \u0026ldquo;どこでもドア\u0026rdquo; in Doraemon, it needs the source IP and port and destination IP and port. The developer only needs to send the data to the Socket and get data from the Socket. The details of transport are transparent to the developer.\nVPN vs Socks5 # The OSI model is shown as above.\nThe Application Layer you search a query on the browser, and the browser sends it to the Presentation Layer via http.\nThe Presentation Layer translate the query to the machine language and sends it to the Session Layer.\nThe Session Layer maintains the session between the client and the server.\nThe Transport Layer defines the protocol and the port.\nThe Network Layer adds the IP address.\nThe Data Link Layer adds the MAC address.\nThe Physical Layer sends the data in bits.\nVPN is the same as virtual network interface, it will take over all the traffic. You can refer to the image below.\nSo we can find that the Socks5(without TUN mode) cannot proxy the traffic of online games, and the network commands.\nThe most VPN is used the TCP protocol, it needs to establish a connection, so it can be interupted by the reset packet. Besides, the feature of the VPN is very clear, so it is easy to be detected.\nNowadays, A new VPN called wireguard used the UDP protocol, so it cannot be interupted by normal methods. But it will be limited the speed in QoS.\nReference:\nhttps://www.rfc-editor.org/ https://www.youtube.com/watch?v=wAxOjL_gDzk https://www.duyaoss.com/archives/1086/ https://mp.weixin.qq.com/s/2teDwwIhyZ6BYIEQ_HL1vQ https://zhuanlan.zhihu.com/p/64467370 https://doubibackup.com/6r9z6_wi-2.html https://www.duyaoss.com/archives/2741/ https://blog.revincx.icu/posts/proxy-summary/index.html https://ephen.me/2017/PublicDns_1/ https://www.youtube.com/watch?v=Ty0n7AgcX0w "},{"id":21,"href":"/posts/python-generator-iterator-and-decorator/","title":"Python Generator Iterator and Decorator","section":"Blog","content":"This article will review the basic knowledge of Python, including generator, iterator, and decorator.\nCH9 Generator, Iterator, and Decorator # Generator # ls = [ i**2 for i in range(1, 1000001)] for i in ls: pass Disadvantage: Occupying a lot of memory\nUse lazy calculation Do not need to store a large amount of data at once Calculate on the fly, only calculate the value needed each time Actually always executing the next() operation until there is no value left Generator Expression # Do not need to store all data\nsum((i for i in range(101))) # Sum, inside a generator # 5050 Generator Function yield # Generate Fibonacci sequence def fib(max): n, a, b = 0, 1, 1 while n \u0026lt; max: print(a) a, b = b, a + b n = n + 1 Construct generator function, execute each time when next() is called, return when encountering yield statement, continue execution from the yield statement last returned.\nDifference:\nA normal function executes all code in the function body at once when called, returning a result (if there is a return value) and then ends. The function containing yield (i.e., the generator function) executes until yield, returns a value, and then continues execution multiple times based on needs, possibly returning new values each time, until the function is executed to completion (e.g., when reaching the end of the function or encountering a return statement). It seems like the function has memory effect. def fib(max): n, a, b = 0, 1, 1 while n \u0026lt; max: yield a a, b = b, a + b n = n + 1 fib(10) # \u0026lt;generator object fib at 0x000001BE11B19048\u0026gt; for i in fib(10): print(i) # 1 # 1 # 2 # 3 # 5 # 8 # 13 # ... Iterator # Iterable # Objects that can be directly used in for loops are collectively referred to as Iterable:\nList, tuple, string, dictionary, set, file\nUse isinstance() to determine if an object is an Iterable object\nfrom collections import Iterable isinstance([1, 2, 3], Iterable) # True Generator\nGenerators can not only be used in for loops but also be called by the next() function\nsquares = (i**2 for i in range(5)) isinstance(squares, Iterable) # True print(next(squares)) # Until there is no data to take, throw StopIteration print(next(squares)) # StopIteration: Objects that can be called by the next() function and return the next value until there is no data to take are called Iterators: Iterator\nIterator # Use isinstance() to determine if an object is an Iterator object\nGenerators are Iterators from collections import Iterator squares = (i**2 for i in range(5)) isinstance(squares, Iterator) # True List, tuple, string, dictionary, set are not Iterators isinstance([1, 2, 3], Iterator) # False Can create an Iterator by iter(Iterable) isinstance(iter([1, 2, 3]), Iterator) # True for item in Iterable is equivalent to: First get the Iterator of the Iterable by iter() function, then call next() method on the obtained Iterator to get the next value and assign it to item, and the loop ends when encountering the StopIteration exception.\nzip enumerate and other functions in itertools are Iterators x = [1, 2] y = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;] zip(x, y) # \u0026lt;zip at 0x1be11b13c48\u0026gt; for i in zip(x, y): print(i) isinstance(zip(x, y), Iterator) # True numbers = [1, 2, 3, 4, 5] enumerate(numbers) # \u0026lt;enumerate at 0x1be11b39990\u0026gt; for i in enumerate(numbers): print(i) isinstance(enumerate(numbers), Iterator) # True File is an Iterator with open(\u0026#34;测试文件.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding = \u0026#34;utf-8\u0026#34;) as f: print(isinstance(f, Iterator)) # True Iterator is consumable squares = (i**2 for i in range(3)) for square in squares: print(square) # 0 # 1 # 4 for square in squares: print(square) # Cannot iterate anymore, because it has been exhausted range() is not an Iterator Can be called range() as a lazy sequence, it is a sequence, but does not contain any content in memory, but answers questions through calculation.\nnumbers = range(10) isinstance(numbers, Iterator) # False print(len(numbers)) # Has length 10 print(numbers[0]) # Can be indexed 0 print(9 in numbers) # Can exist calculation True next(numbers) # Cannot be called by next() TypeError: \u0026#39;range\u0026#39; object is not an iterator # Will not be exhausted Decorator # Template # Talk is cheap, just show the code\ndef decorator(func): # The wrapper is the function to be decorated(must keep the same parameters with the original function) def wrapper(*args, **kwargs): # Do something before the function is called res = func(*args, **kwargs) # Call the original function # Do something after the function is called return res return wrapper # Return the wrapper(if the original function returns value, the wrapper must return the value) Demand # (1) Need to add some features to the already developed program (2) Cannot modify the source code of the function in the program (3) Cannot change the calling method of the function in the program\nFunction Object # You can assign a function to a variable and call the variable to realize the function of the original function. Functions can be passed as parameters def square(x): return x**2 print(type(square)) # square is an instance of the function class # \u0026lt;class \u0026#39;function\u0026#39;\u0026gt; pow_2 = square # It can be understood that this function is given an alias pow 2 print(pow_2(5)) # 25 print(square(5)) # 25 High-order Function # One of the following is sufficient:\nReceives a function as a parameter Or returns a function def square(x): return x**2 def pow_2(fun): return fun f = pow_2(square) f(8) # 64 print(f == square) # True Nested Function # Define a function inside a function\ndef outer(): print(\u0026#34;outer is running\u0026#34;) def inner(): print(\u0026#34;inner is running\u0026#34;) inner() outer() Closure # def outer(): x = 1 z = 10 def inner(): y = x + 100 return y, z return inner f = outer() # In fact, f contains the inner function itself + the environment of the outer function print(f) # \u0026lt;function outer.\u0026lt;locals\u0026gt;.inner at 0x000001BE11B1D730\u0026gt; print(f.__closure__) # __closure__ property contains information from the outer function for i in f.__closure__: print(i.cell_contents) # (\u0026lt;cell at 0x000001BE0FDE06D8: int object at 0x00007FF910D59340\u0026gt;, \u0026lt;cell at 0x000001BE0FDE0A98: int object at 0x00007FF910D59460\u0026gt;) # 1 # 10 res = f() print(res) # (101, 10) Closure: Function that extends the scope\nIf a function is defined in the scope of another function and references a variable in the outer function, then this function is called a closure\nA closure is an entity composed of a function and its related reference environment (i.e., closure = function + reference environment)\nOnce a variable with the same name is redefined inside the inner function, it becomes a local variable\ndef outer_function(x): outer_variable = x def inner_function(y): return outer_variable + y return inner_function closure = outer_function(10) # x is 10 closure = inner_function result = closure(5) # y is 5 print(result) # 15 def outer(): x = 1 def inner(): x = x+100 return x return inner f = outer() f() # \u0026lt;ipython-input-87-d2da1048af8b\u0026gt; in inner() # 3 # 4 def inner(): # ----\u0026gt; 5 x = x+100 # 6 return x # UnboundLocalError: local variable \u0026#39;x\u0026#39; referenced before assignment nonlocal allows the inner function to modify the closure variable, indicating that it is not an internal variable, and uses the variable of the outer function.\ndef outer(): x = 1 def inner(): nonlocal x x = x+100 return x return inner f = outer() f() # 1 # 101 LEGB rules # In order to understand actually how the scope resolution happening in Python, we should analyze the LEGB rule because, it is the sequence of names(variables, functions, objects and so on) that Python resolves in a program.\nLEGB stanas for： （L） Local scope （E） Enclosed scope （G） Global scope （B） Built-in scope\nSo the sequence of the scope resolution is: Local scope -\u0026gt; Enclosed scope -\u0026gt; Global scope -\u0026gt; Built-in scope. In a closure environment, if firstly search the local scope, if not, it will search the enclosed scope, you can refer to this example:\n#foo.py filename = \u0026#34;foo.py\u0026#34; print(filename) def call_func(f): filename = \u0026#34;foo_call.py\u0026#34; print(filename) return f() #func.py import foo filename = \u0026#34;func_global.py\u0026#34; print(filename) def wrapper(): filename = \u0026#34;func_enclosed.py\u0026#34; print(filename) def show_filename(): filename = \u0026#34;func_inner.py\u0026#34; print(filename) return f\u0026#34;filename: {filename}\u0026#34; print(foo.call_func(show_filename)) if __name__ == \u0026#34;__main__\u0026#34;: wrapper() Guess what the output will be? Can you explain the print sequence?\nthe main call the foo.call_func first, so the foo will be loaded first, the foo.py will be printed when import foo. then the func.py will be loaded, the func_global.py will be printed. Now the wrapper is called, the func_enclosed.py will be printed. And the call_func is a closure, it contains the f() and its environment. Now execute the closure, so the foo_call.py will be printed. Now execute the return, actually the return is the show_filename function, so the func_inner.py will be printed. And the filename return is the func_inner.py. (Local scope) So the output is:\nfoo.py func_global.py func_enclosed.py foo_call.py func_inner.py filename: func_inner.py Now we delete the func_inner.py, can you guess the filename?\nfilename: func_enclosed.py As we can see, the closure contains the show_filename function and its environment, there is no filename inside the function, so it search the env filename is func_enclosed.py. (Enclosed scope)\nIf we delete the func_enclosed.py, the filename will be func_global.py. (Global scope)\nNow if we delete the func_global.py, can you guess the output? Should the filename be foo_call.py?\nAbsolutely not, because the return is the show_filename function, and there is no filename inside both function and its environment, so the function cannot be executed originally, let alone called any other way. It will just appear the NameError: name 'filename' is not defined.\nHope this example can help you better understand the concepts.\nA Simple Decorator # Implemented with nested functions\nimport time def timer(func): def inner(): print(\u0026#34;inner run\u0026#34;) start = time.time() func() end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return inner def f1(): print(\u0026#34;f1 run\u0026#34;) time.sleep(1) f1 = timer(f1) # Contains inner() and the environment of timer, such as the passed parameter func f1() # inner run # f1 run # f1 function running time: 1.00 seconds Syntax Sugar # import time def timer(func): def inner(): print(\u0026#34;inner run\u0026#34;) start = time.time() func() end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return inner @timer # Equivalent to implementing f1 = timer(f1) def f1(): print(\u0026#34;f1 run\u0026#34;) time.sleep(1) Decorate Function with Parameters # import time def timer(func): def inner(*args, **kwargs): print(\u0026#34;inner run\u0026#34;) start = time.time() func(*args, **kwargs) end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return inner @timer # Equivalent to implementing f1 = timer(f1) def f1(n): print(\u0026#34;f1 run\u0026#34;) time.sleep(n) f1(2) Function decorated with return value\nimport time def timer(func): def inner(*args, **kwargs): print(\u0026#34;inner run\u0026#34;) start = time.time() res = func(*args, **kwargs) end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return res return inner @timer # Equivalent to implementing f1 = timer(f1) def f1(n): print(\u0026#34;f1 run\u0026#34;) time.sleep(n) return \u0026#34;wake up\u0026#34; res = f1(2) print(res) # inner run # f1 run # f1 function running time: 2.00 seconds # wake up Decorator with Parameters # Decorators themselves need to pass some additional parameters\nRequirement: Sometimes you need to count the absolute time, sometimes you need to count the absolute time twice def timer(method): def outer(func): def inner(*args, **kwargs): print(\u0026#34;inner run\u0026#34;) if method == \u0026#34;origin\u0026#34;: print(\u0026#34;origin_inner run\u0026#34;) start = time.time() res = func(*args, **kwargs) end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) elif method == \u0026#34;double\u0026#34;: print(\u0026#34;double_inner run\u0026#34;) start = time.time() res = func(*args, **kwargs) end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, 2*(end-start))) return res return inner return outer @timer(method=\u0026#34;origin\u0026#34;) # Equivalent to timer = timer(method = \u0026#34;origin\u0026#34;) f1 = timer(f1) def f1(): print(\u0026#34;f1 run\u0026#34;) time.sleep(1) @timer(method=\u0026#34;double\u0026#34;) def f2(): print(\u0026#34;f2 run\u0026#34;) time.sleep(1) f1() print() f2() # inner run # origin_inner run # f1 run # f1 function running time: 1.00 seconds # inner run # double_inner run # f2 run # f2 function running time: 2.00 seconds Understanding closures is key!\n9、When does the decorator execute\nExecute immediately when decorated, no need to wait for the call func_names=[] def find_function(func): print(\u0026#34;run\u0026#34;) func_names.append(func) return func @find_function def f1(): print(\u0026#34;f1 run\u0026#34;) @find_function def f2(): print(\u0026#34;f2 run\u0026#34;) # run # run for func in func_names: print(func.__name__) func() print() # f1 # f1 run # f2 # f2 run Return to the Source # The properties of the original function are hidden import time def timer(func): def inner(): print(\u0026#34;inner run\u0026#34;) start = time.time() func() end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return inner @timer # Equivalent to implementing f1 = timer(f1) def f1(): time.sleep(1) print(\u0026#34;f1 run\u0026#34;) print(f1.__name__) # inner Return to the source import time from functools import wraps def timer(func): @wraps(func) def inner(): print(\u0026#34;inner run\u0026#34;) start = time.time() func() end = time.time() print(\u0026#34;{} function running time: {:.2f} seconds\u0026#34;.format(func.__name__, (end-start))) return inner @timer # Equivalent to implementing f1 = timer(f1) def f1(): time.sleep(1) print(\u0026#34;f1 run\u0026#34;) print(f1.__name__) f1() # f1 # inner run # f1 run # f1 function running time: 1.00 seconds "},{"id":22,"href":"/posts/python-underlying-mechanism/","title":"Python Underlying Mechanism","section":"Blog","content":"This article will review the underlying mechanism of Python, including data types and derivation operations.\nCH8 Underlying Mechanism # Data Type Implementation # Strange List # list_1 = [1, [22, 33, 44], (5, 6, 7), {\u0026#34;name\u0026#34;: \u0026#34;Sarah\u0026#34;}] Shallow copy # list_3 = list_1 # Error! list_2 = list_1.copy() # Or list_1[:] \\ list(list_1) can also implement shallow copy Operations on the shallow copy of the two lists list_2[1].append(55) print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [1, [22, 33, 44, 55], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [1, [22, 33, 44, 55], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}] List Implementation # Concept of reference array\nThe elements inside the list can be scattered in memory\nThe list actually stores the addresses of these elements, and the addresses are stored in a continuous manner.\nShallow copy copies the addresses of the elements.\nlist_1 = [1, [22, 33, 44], (5, 6, 7), {\u0026#34;name\u0026#34;: \u0026#34;Sarah\u0026#34;}] list_2 = list(list_1) # Shallow copy The same functionality as list_1.copy() （1）New elements\nlist_1.append(100) list_2.append(\u0026#34;n\u0026#34;) print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [1, [22, 33, 44], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, 100] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [1, [22, 33, 44], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, \u0026#39;n\u0026#39;] （2）Modify elements, pay attention to the difference between modifying mutable or immutable types.\nLists and dictionaries, which are mutable types, content changes, but the address does not change. While tuples, numbers, and strings, which are immutable types, content changes, and the address changes. list_1[0] = 10 list_2[0] = 20 print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [10, [22, 33, 44], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, 100] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [20, [22, 33, 44], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, \u0026#39;n\u0026#39;] （3）Operations on list elements\nlist_1[1].remove(44) list_2[1] += [55, 66] print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [10, [22, 33, 55, 66], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, 100] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [20, [22, 33, 55, 66], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, \u0026#39;n\u0026#39;] Because the operation is on the list, and the original list maps the address, after modifying the element, the address is mapped, so the modification of list1 and 2 is the same\n（4）Operations on tuple elements\nlist_2[2] += (8,9) print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [10, [22, 33, 55, 66], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, 100] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [20, [22, 33, 55, 66], (5, 6, 7, 8, 9), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}, \u0026#39;n\u0026#39;] Tuples are immutable! They are equivalent to adding a tuple (5, 6, 7, 8, 9), and list2 points to this tuple.\n（5）Operations on dictionary elements\nlist_1[-2][\u0026#34;age\u0026#34;] = 18 print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [10, [22, 33, 55, 66], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;, \u0026#39;age\u0026#39;: 18}, 100] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [20, [22, 33, 55, 66], (5, 6, 7, 8, 9), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;, \u0026#39;age\u0026#39;: 18}, \u0026#39;n\u0026#39;] Deep Copy # After shallow copy\nOperations on immutable elements (numbers, strings, tuples) are effective Operations on mutable elements (lists, sets) cause some confusion Introducing deep copy\nDeep copy copies all related elements at all levels, completely separating them, clearly distinguishing between them, avoiding the above issues import copy list_1 = [1, [22, 33, 44], (5, 6, 7), {\u0026#34;name\u0026#34;: \u0026#34;Sarah\u0026#34;}] list_2 = copy.deepcopy(list_1) list_1[-1][\u0026#34;age\u0026#34;] = 18 list_2[1].append(55) print(\u0026#34;list_1: \u0026#34;, list_1) # list_1: [1, [22, 33, 44], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;, \u0026#39;age\u0026#39;: 18}] print(\u0026#34;list_2: \u0026#34;, list_2) # list_2: [1, [22, 33, 44, 55], (5, 6, 7), {\u0026#39;name\u0026#39;: \u0026#39;Sarah\u0026#39;}] Dictionary Implementation # Implement value storage and access through sparse arrays\nDictionary Creation Process\nCreate a sparse array (N \u0026raquo; n) d = {} Step 1: Calculate the hash value of the key through hash() print(hash(\u0026#34;python\u0026#34;)) # -4771046564460599764 print(hash((1,2))) # 3713081631934410656 # Adding a key-value pair, first calculate the hash value of the key hash(\u0026#34;age\u0026#34;) d[\u0026#34;age\u0026#34;] = 18 print(hash(\u0026#34;age\u0026#34;)) Step 2: Determine its position in the sparse array based on the calculated hash value, and if there is a hash value collision, there is a corresponding method to resolve the conflict. Step 3: Store the value at that position Summary\n（1）Dictionary data type, through space for time, implements fast data lookup, which also means that the space utilization efficiency of the dictionary is low.\n（2）Because the order of the hash value corresponding position may be different from the order of the key in the dictionary, the dictionary appears to be unordered.\nCompact String # Implement string storage through compact arrays, data is stored in memory in a continuous manner, more efficient, and saves space.\nAs a sequence type, why is the list implemented using reference arrays, while the string is implemented using compact arrays? The list can change, so it is not convenient to reserve space.\nMutable and Immutable Types # Immutable types: numbers, strings, tuples The content remains unchanged throughout its lifecycle, in other words, if it is changed, it is no longer itself (the id changes). The += operation on immutable objects actually creates a new object Tuples are not always immutable，if a tuple contains a mutable type, then the tuple can still change.\nt = (1,[2]) t[1].append(3) # (1, [2, 3]) Mutable types: lists, dictionaries, sets id remains unchanged, but the content can change The += operation on mutable objects actually modifies the original object in place A Few Examples of List Operations # Deleting a Specific Element in a List # Method 1 Existence Operation Deletion Disadvantage: Each existence operation requires traversing the list from the beginning, searching, and being inefficient\nalist = [\u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;d\u0026#34; ,\u0026#34;d\u0026#34;, \u0026#34;4\u0026#34;] s = \u0026#34;d\u0026#34; while True: if s in alist: alist.remove(s) else: break print(alist) # [\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;] Method 2 Delete all elements at once First, alist is being deleted, but the index s is in order, so there may be a phenomenon where some elements are skipped, but the deletion is still performed in the order of scanning from the list head.\nalist = [\u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;d\u0026#34; ,\u0026#34;d\u0026#34;, \u0026#34;4\u0026#34;] for s in alist: if s == \u0026#34;d\u0026#34;: alist.remove(s) # remove（s） Remove the first occurrence of the element in the list print(alist) # [\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;4\u0026#39;] Solution: Use negative indexing Negative indexing scans in reverse order, ensuring that each traversal is the list head, and the deletion is also the list head.\nalist = [\u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;d\u0026#34; ,\u0026#34;d\u0026#34;, \u0026#34;4\u0026#34;] for i in range(-len(alist), 0): if alist[i] == \u0026#34;d\u0026#34;: alist.remove(alist[i]) # remove（s） Remove the first occurrence of the element in the list print(alist) # [\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;] Creating a Multi-Dimensional List # ls = [[0]*10]*5 ls[0][0] = 1 # [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]] Because the four lists below are copies of the first list, so if the first list changes, the following ones will also change.\nMore Concise Syntax # Parsing Syntax # ls = [[0]*10 for i in range(5)] ls[0][0] = 1 # [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] List Comprehension # [expression **for value in iterable** if condition]\n# Equivalent to the following code result = [] for value in iterale: if condition: result.append(expression) squares = [i**2 for i in range(1,21) if i%2 == 1] print(squares) Support multiple variables\nx = [1, 2, 3] y = [1, 2, 3] results = [ i*j for i,j in zip(x, y)] results # [1, 4, 9] Support nested loops\ncolors = [\u0026#34;black\u0026#34;, \u0026#34;white\u0026#34;] sizes = [\u0026#34;S\u0026#34;, \u0026#34;M\u0026#34;, \u0026#34;L\u0026#34;] tshirts = [\u0026#34;{} {}\u0026#34;.format(color, size) for color in colors for size in sizes] tshirts # [\u0026#39;black S\u0026#39;, \u0026#39;black M\u0026#39;, \u0026#39;black L\u0026#39;, \u0026#39;white S\u0026#39;, \u0026#39;white M\u0026#39;, \u0026#39;white L\u0026#39;] Dictionary Comprehension # squares = {i: i**2 for i in range(3)} for k, v in squares.items(): print(k, \u0026#34;: \u0026#34;, v) # 0 : 0 # 1 : 1 # 2 : 4 Set Comprehension # squares = {i**2 for i in range(10)} squares # {0, 1, 4, 9, 16, 25, 36, 49, 64, 81} Generator Expression # squares = (i**2 for i in range(10)) squares # \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x000001DB37A58390\u0026gt; Conditional Expression # expr1 if condition else expr2\nn = -10 if n \u0026gt;= 0: x = n else: x = -n # which is equivalent to x = n if n\u0026gt;= 0 else -n # 10 "},{"id":23,"href":"/posts/python-files-exceptions-and-modules/","title":"Python Files Exceptions and Modules","section":"Blog","content":"This article will review the basic knowledge of Python, including files, exceptions, and modules.\nCH7 Files, Exceptions, and Modules # File Read and Write # File Open # The general format for opening a file, recommended to use with, because if not using with, then you need to consider the close operation # The advantage of using with block: automatically close the file after execution with open(\u0026#34;file path\u0026#34;, \u0026#34;open mode\u0026#34;, encoding = \u0026#34;character encoding of the file\u0026#34;) as f: \u0026#34;file read and write operation\u0026#34; with open(\u0026#34;E:\\ipython\\test.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding = \u0026#34;gbk\u0026#34;) as f: text = f.read() print(text) Open Mode # r Read mode，if the file does not exist, an error will be reported\nw Overwrite write mode，if the file does not exist, it will be created; if the file exists, it will completely overwrite the original file\nx Create write mode，if the file does not exist, it will be created; if the file exists, an error will be reported\na Append write mode，if the file does not exist, it will be created; if the file exists, it will be added to the original file\nb Binary file mode，cannot be used alone, it needs to be used together with rb, wb, ab, this mode does not need to specify encoding\nt Text file mode，default value, it needs to be used together with rt, wt, at, generally omitted, abbreviated as r, w, a\n+，with r, w, x, a, it adds read and write functions to the original functions\nThe default open mode is read mode\nCharacter Encoding # Universal code utf-8:includes all characters needed by all countries Chinese encoding gbk:used to solve the problem of Chinese encoding, in windows, if omitted, it defaults to gbk (the encoding of the region)。 For clarity, except for processing binary files, it is recommended not to omit encoding File Read # Read the entire content——f.read() with open(\u0026#34;never_gonna_give_you_up_utf.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: text = f.read() print(text) # with open(\u0026#34;never_gonna_give_you_up_utf.txt\u0026#34;, \u0026#34;r\u0026#34;) as f: # UnicodeDecodeError: \u0026#39;gbk\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 50: illegal multibyte sequence Read line by line——f.readline() with open(\u0026#34;never_gonna_give_you_up_utf.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: while True: text = f.readline() # Read each line if not text: # print(text is \u0026#34;\u0026#34;) break else: # print(text == \u0026#34;\\n\u0026#34;) # The newline character is not considered empty print(text, end=\u0026#34;\u0026#34;) # Keep the original newline, so that the print() newline does not take effect, because print itself also has a newline effect Read all lines, forming a list with each line as an element f.readlines() with open(\u0026#34;never_gonna_give_you_up_utf.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: text = f.readlines() # Note that each line has a newline character at the end print(text) # [\u0026#39;never gonna give you up\\n\u0026#39;, \u0026#39;never gonna let you down\\n\u0026#39;, \u0026#39;never gonna run around and desert you\\n\u0026#39;, \u0026#39;never gonna make you cry\\n\u0026#39;, \u0026#39;never gonna say goodbye\\n\u0026#39;, \u0026#39;never gonna tell a lie and hurt you\\n\u0026#39;] for text in f.readlines(): print(text) # If you don\u0026#39;t want to change lines, use print(text, end=\u0026#34;\u0026#34;) Text file read summary When the file is large, read() and readlines() occupy too much memory, not recommended. readline is not convenient to use\nwith open(\u0026#34;never_gonna_give_you_up_gbk.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;gbk\u0026#34;) as f: for text in f: # f itself is an iterable object, and each iteration reads one line of content print(text) Binary file Image: binary file\nwith open(\u0026#34;test.jpg\u0026#34;, \u0026#34;rb\u0026#34;) as f: print(len(f.readlines())) # 69 File Write # Write a string or byte stream (binary) to a file——f.write() with open(\u0026#34;恋曲1980.txt\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(\u0026#34;你曾经对我说\\n\u0026#34;) # If the file does not exist, it will immediately create one f.write(\u0026#34;你永远爱着我\\n\u0026#34;) # If you need to change lines, add a newline character \\n at the end, and the file will be written on the second line Write a list of strings to a file——f.writelines() ls = [\u0026#34;春天刮着风\\n\u0026#34;, \u0026#34;秋天下着雨\\n\u0026#34;, \u0026#34;春风秋雨多少海誓山盟随风远去\\n\u0026#34;] with open(\u0026#34;恋曲1980.txt\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.writelines(ls) Read and Write # r+ If the file name does not exist, an error will be reported The pointer is at the beginning, and the pointer must be moved to the end to start writing, otherwise it will overwrite the previous content with open(\u0026#34;浪淘沙_北戴河.txt\u0026#34;, \u0026#34;r+\u0026#34;, encoding=\u0026#34;gbk\u0026#34;) as f: # for line in f: # print(line) # After reading all, the pointer reaches the end f.seek(0,2) # Or you can move the pointer to the end f.seek(offset in bytes, position (0: start; 1: current position; 2: end)) text = [\u0026#34;萧瑟秋风今又是，\\n\u0026#34;, \u0026#34;换了人间。\\n\u0026#34;] f.writelines(text) w+ If the file does not exist, it will be created, and if the file exists, it will be immediately cleared. with open(\u0026#34;浪淘沙_北戴河.txt\u0026#34;, \u0026#34;w+\u0026#34;, encoding=\u0026#34;gbk\u0026#34;) as f: text = [\u0026#34;萧瑟秋风今又是，\\n\u0026#34;, \u0026#34;换了人间。\\n\u0026#34;] # Clear the original content f.writelines(text) # Write new content, pointer at the end f.seek(0,0) # Move the pointer to the start print(f.read()) # Read content ​\na+: If the file does not exist, it will be created, and if the file exists, the pointer is at the end, and new content will be added, without clearing the original content. Data Storage and Reading # Common data formats can be loaded and stored in different languages\ncsv format A character sequence separated by commas that can be opened by excel\nRead with open(\u0026#34;score.csv\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;gbk\u0026#34;) as f: ls = [] for line in f: # Read line by line ls.append(line.strip(\u0026#34;\\n\u0026#34;).split(\u0026#34;,\u0026#34;)) # Remove the newline character and split by \u0026#34;,\u0026#34; for res in ls: print(res) Write ls = [[\u0026#39;id\u0026#39;, \u0026#39;math\u0026#39;, \u0026#39;chinese\u0026#39;], [\u0026#39;1\u0026#39;, \u0026#39;100\u0026#39;, \u0026#39;98\u0026#39;], [\u0026#39;2\u0026#39;, \u0026#39;96\u0026#39;, \u0026#39;99\u0026#39;], [\u0026#39;3\u0026#39;, \u0026#39;97\u0026#39;, \u0026#39;95\u0026#39;]] with open(\u0026#34;score.csv\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;gbk\u0026#34;) as f: # encoding=\u0026#34;utf-8\u0026#34; for row in ls: # Write line by line f.write(\u0026#34;,\u0026#34;.join(row)+\u0026#34;\\n\u0026#34;) # Combine with commas, add a newline character at the end The above operations can also be completed using the csv module\n2、json format\nOften used to store dictionaries\nWrite - dump() import json scores = {\u0026#34;Petter\u0026#34;:{\u0026#34;math\u0026#34;:96 , \u0026#34;physics\u0026#34;: 98}, \u0026#34;Paul\u0026#34;:{\u0026#34;math\u0026#34;:92 , \u0026#34;physics\u0026#34;: 99}, \u0026#34;Mary\u0026#34;:{\u0026#34;math\u0026#34;:98 , \u0026#34;physics\u0026#34;: 97}} with open(\u0026#34;score.json\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: # Write the entire object # indent pretty print, ensure_ascii=False display Chinese json.dump(scores, f, indent=4, ensure_ascii=False) Read - load() with open(\u0026#34;score.json\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: scores = json.load(f) # Load the entire object for k,v in scores.items(): print(k,v) # Petter {\u0026#39;math\u0026#39;: 96, \u0026#39;physics\u0026#39;: 98} # Paul {\u0026#39;math\u0026#39;: 92, \u0026#39;physics\u0026#39;: 99} # Mary {\u0026#39;math\u0026#39;: 98, \u0026#39;physics\u0026#39;: 97} Exception Handling # When an exception occurs, if no pre-set processing method is provided, the program will interrupt\nCommon Exception Generation # Division by zero - ZeroDivisionError 1/0 # ZeroDivisionError: division by zero File not found - FileNotFoundError with open(\u0026#34;nobody.csv\u0026#34;) as f: pass # FileNotFoundError: [Errno 2] No such file or directory: \u0026#39;nobody.csv\u0026#39; Value error - ValueError Passing a value that is not expected by the caller, even though the value is of the correct type\ns = \u0026#34;1.3\u0026#34; n = int(s) # ValueError: invalid literal for int() with base 10: \u0026#39;1.3\u0026#39; Index error - IndexError Index out of sequence boundary\nls = [1, 2, 3] ls[5] # IndexError: list index out of range Type error - TypeError Passing an object type that does not match the requirement\n1 + \u0026#34;3\u0026#34; # TypeError: unsupported operand type(s) for +: \u0026#39;int\u0026#39; and \u0026#39;str\u0026#39; Other common exception types NameError - Using an undefined variable\nKeyError - Attempting to access a key that does not exist in a dictionary\nprint(a) # NameError: name \u0026#39;a\u0026#39; is not defined d = {} d[\u0026#34;1\u0026#34;] # KeyError: \u0026#39;1\u0026#39; Exception Handling # Improve the stability and reliability of the program\ntry except If the try block code runs smoothly, the except block is not triggered\nIf an error occurs in the try block, the except block is triggered, and the code in the except block is executed\nSingle branch\nx = 10 y = 0 try: z = x/y except ZeroDivisionError: # Generally, it is predicted what error will occur print(\u0026#34;0 cannot be divided!\u0026#34;) # 0 cannot be divided! Multiple branches ls = [] d = {\u0026#34;name\u0026#34;: \u0026#34;timerring\u0026#34;} try: y = m # ls[3] # d[\u0026#34;age\u0026#34;] except NameError: print(\u0026#34;Variable name does not exist\u0026#34;) except IndexError: print(\u0026#34;Index out of bounds\u0026#34;) except KeyError: print(\u0026#34;Key does not exist\u0026#34;) # Variable name does not exist Universal exception Exception (the ancestor of all errors) ls = [] d = {\u0026#34;name\u0026#34;: \u0026#34;timerring\u0026#34;} try: # y = m ls[3] # d[\u0026#34;age\u0026#34;] except Exception: print(\u0026#34;Error\u0026#34;) # Error Capture the value of the exception as ls = [] d = {\u0026#34;name\u0026#34;: \u0026#34;timerring\u0026#34;} # y = x try: y = m # ls[3] # d[\u0026#34;age\u0026#34;] except Exception as e: # Although it cannot obtain the specific type of error, it can obtain the reason for the error print(e) # name \u0026#39;m\u0026#39; is not defined try except else If the try module is executed, the else module is also executed, and the else module can be seen as an additional reward for the successful try. try: with open(\u0026#34;files.txt\u0026#34;) as f: text = f.read() except FileNotFoundError: print(\u0026#34;File not found\u0026#34;) else: for s in [\u0026#34;\\n\u0026#34;, \u0026#34;，\u0026#34;, \u0026#34;。\u0026#34;, \u0026#34;？\u0026#34;]: # Remove newline and punctuation characters text = text.replace(s, \u0026#34;\u0026#34;) print(\u0026#34;files consists of {} characters.\u0026#34;.format(len(text))) # files consists of 65 characters. try except finally Whether the try module is executed, finally is executed ls = [] d = {\u0026#34;name\u0026#34;: \u0026#34;timerring\u0026#34;} # y = x try: y = m # ls[3] # d[\u0026#34;age\u0026#34;] except Exception as e: # Although it cannot obtain the specific type of error, it can obtain the value of the error print(e) finally: print(\u0026#34;Whether an exception is triggered, it will be executed\u0026#34;) # name \u0026#39;m\u0026#39; is not defined # Whether an exception is triggered, it will be executed Module Introduction # Already encapsulated, no need to \u0026ldquo;invent the wheel\u0026rdquo; yourself, declare import, and use it directly.\nBroad module classification # Python built-in # Time library time Random library random Container data type collection Iterator function itertools\nThird-party library # Data analysis numpy, pandas Data visualization matplotlib Machine learning scikit-learn Deep learning Tensorflow\nCustom file # Separate py file Package contains multiple py files, needs to add an __init__.py file. Module import # Import the entire module——import module name Call method: module name.function name or class name import time start = time.time() # Call time module\u0026#39;s time() time.sleep(3) # Call time module\u0026#39;s sleep() end = time.time() print(\u0026#34;{:.2f}s\u0026#34;.format(end-start)) Import classes or functions from a module——from module import class name or function name Call method: function name or class name from itertools import product # This case can directly use the function name for use, without adding the previous module name ls = list(product(\u0026#34;AB\u0026#34;, \u0026#34;123\u0026#34;)) # Import multiple from function import fun1, fun2 fun1.f1() fun2.f2() Import all classes and functions from a module——from module import * (not recommended) Call method: function name or class name from random import * # Wildcard import all files, so you can use without adding the module name prefix print(randint(1,100)) print(random()) Module search path # Module search order:\nPriority memory loaded module Built-in module When Python starts, the interpreter will load some modules into sys.modules sys.modules variable contains a dictionary of modules loaded into the interpreter (fully and successfully imported), with the module name as the key and its location as the value import sys print(len(sys.modules)) # 738 print(\u0026#34;math\u0026#34; in sys.modules) # True print(\u0026#34;numpy\u0026#34; in sys.modules) # False for k,v in list(sys.modules.items())[:20]: print(k, \u0026#34;:\u0026#34;, v) # sys : \u0026lt;module \u0026#39;sys\u0026#39; (built-in)\u0026gt; # builtins : \u0026lt;module \u0026#39;builtins\u0026#39; (built-in)\u0026gt; # _frozen_importlib : \u0026lt;module \u0026#39;importlib._bootstrap\u0026#39; (frozen)\u0026gt; # _imp : \u0026lt;module \u0026#39;_imp\u0026#39; (built-in)\u0026gt; # _thread : \u0026lt;module \u0026#39;_thread\u0026#39; (built-in)\u0026gt; # _warnings : \u0026lt;module \u0026#39;_warnings\u0026#39; (built-in)\u0026gt; # _weakref : \u0026lt;module \u0026#39;_weakref\u0026#39; (built-in)\u0026gt; # zipimport : \u0026lt;module \u0026#39;zipimport\u0026#39; (built-in)\u0026gt; # _frozen_importlib_external : \u0026lt;module \u0026#39;importlib._bootstrap_external\u0026#39; (frozen)\u0026gt; # _io : \u0026lt;module \u0026#39;io\u0026#39; (built-in)\u0026gt; # marshal : \u0026lt;module \u0026#39;marshal\u0026#39; (built-in)\u0026gt; # nt : \u0026lt;module \u0026#39;nt\u0026#39; (built-in)\u0026gt; # winreg : \u0026lt;module \u0026#39;winreg\u0026#39; (built-in)\u0026gt; # encodings : \u0026lt;module \u0026#39;encodings\u0026#39; from \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\encodings\\\\__init__.py\u0026#39;\u0026gt; # codecs : \u0026lt;module \u0026#39;codecs\u0026#39; from \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\codecs.py\u0026#39;\u0026gt; # _codecs : \u0026lt;module \u0026#39;_codecs\u0026#39; (built-in)\u0026gt; # encodings.aliases : \u0026lt;module \u0026#39;encodings.aliases\u0026#39; from \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\encodings\\\\aliases.py\u0026#39;\u0026gt; # encodings.utf_8 : \u0026lt;module \u0026#39;encodings.utf_8\u0026#39; from \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\encodings\\\\utf_8.py\u0026#39;\u0026gt; # _signal : \u0026lt;module \u0026#39;_signal\u0026#39; (built-in)\u0026gt; # __main__ : \u0026lt;module \u0026#39;__main__\u0026#39;\u0026gt; modules in sys.path import sys sys.path # [\u0026#39;E:\\\\ipython\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\python37.zip\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\DLLs\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\u0026#39;, # \u0026#39;\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\site-packages\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions\u0026#39;, # \u0026#39;C:\\\\Users\\\\ibm\\\\.ipython\u0026#39;] The first path in sys.path is the folder where the current execution file is located If you need to import a module that is not in this folder, you need to add the module path to sys.path import sys sys.path.append(\u0026#34;C:\\\\Users\\\\ibm\\\\Desktop\u0026#34;) # Note that it is double slashes, if it is win import fun3 fun3.f3() # Import fun3 successfully "},{"id":24,"href":"/posts/python-object-oriented-programming/","title":"Python Object Oriented Programming","section":"Blog","content":"This article will review the object-oriented programming of Python. Mainly about the class, inheritance, and polymorphism.\nCH6 Class # Introduction # Everything is an object Everything has its own attributes Everything has its own methods Class is the carrier of objects\nEach cat is an object, we can abstract the common features of a class of objects, and create a generic class.\n# Create a class class Cat(): \u0026#34;\u0026#34;\u0026#34;Simulate a cat\u0026#34;\u0026#34;\u0026#34; def __init__(self, name): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes\u0026#34;\u0026#34;\u0026#34; self.name = name def jump(self): \u0026#34;\u0026#34;\u0026#34;Simulate a cat jumping\u0026#34;\u0026#34;\u0026#34; print(self.name + \u0026#34; is jumping\u0026#34;) my_cat = Cat(\u0026#34;Loser\u0026#34;) your_cat = Cat(\u0026#34;Lucky\u0026#34;) print(my_cat.name) # Loser print(your_cat.name) # Lucky # Call method my_cat.jump() # Loser is jumping your_cat.jump() # Lucky is jumping Define a class # Three elements: class name, attributes, methods\nClass naming # Camel case - the first letter of each word is capitalized Leave two blank lines before the \u0026ldquo;class\u0026rdquo; and leave two blank lines after the class Class attributes # class Car(): \u0026#34;\u0026#34;\u0026#34;Simulate a car\u0026#34;\u0026#34;\u0026#34; # def __init__(self, the parameters to be passed) def __init__(self, brand, model, year): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the car\u0026#34;\u0026#34;\u0026#34; self.brand = brand self.model = model self.year = year self.mileage = 0 Class methods # A function defined inside a class\nclass Car(): \u0026#34;\u0026#34;\u0026#34;Simulate a car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the car\u0026#34;\u0026#34;\u0026#34; self.brand = brand self.model = model self.year = year self.mileage = 0 def get_main_information(self): # you cannot omit self \u0026#34;\u0026#34;\u0026#34;Get the main information of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Brand: {} Model: {} Year: {}\u0026#34;.format(self.brand, self.model, self.year)) def get_mileage(self): \u0026#34;\u0026#34;\u0026#34;Get the mileage of the car\u0026#34;\u0026#34;\u0026#34; return \u0026#34;Mileage: {} km\u0026#34;.format(self.mileage) Create an instance # Assign the instance to an object, and pass the corresponding parameters during instantiation.\nmy_new_car = Car(\u0026#34;Audi\u0026#34;, \u0026#34;A6\u0026#34;, 2018) Access attributes # Instance name.attribute name\nprint(my_new_car.brand) # Audi print(my_new_car.model) # A6 print(my_new_car.year) # 2018 Call methods # Instance name.method name(necessary parameters)\nmy_new_car = Car(\u0026#34;Audi\u0026#34;, \u0026#34;A6\u0026#34;, 2018) my_new_car.get_main_information() # Brand: Audi Model: A6 Year: 2018 Modify attributes # Direct modification # First access, then modify\nmy_old_car.mileage = 12000 print(my_old_car.mileage) # 12000 Modify attributes through methods # class Car(): \u0026#34;\u0026#34;\u0026#34;Simulate a car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the car\u0026#34;\u0026#34;\u0026#34; self.brand = brand self.model = model self.year = year self.mileage = 0 def get_main_information(self): # self cannot be omitted \u0026#34;\u0026#34;\u0026#34;Get the main information of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Brand: {} Model: {} Year: {}\u0026#34;.format(self.brand, self.model, self.year)) def set_mileage(self, distance): \u0026#34;\u0026#34;\u0026#34;Set the mileage of the car\u0026#34;\u0026#34;\u0026#34; self.mileage = distance my_old_car.set_mileage(8000) You can create an infinite number of instances\nmy_new_car = Car(\u0026#34;Audi\u0026#34;, \u0026#34;A6\u0026#34;, 2018) my_cars = [my_new_car, my_old_car] Inheritance of classes # Inheritance is the process of low-level abstraction inheriting high-level abstraction\nSimple inheritance # Parent class\nclass Car(): \u0026#34;\u0026#34;\u0026#34;Simulate a car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the car\u0026#34;\u0026#34;\u0026#34; self.brand = brand self.model = model self.year = year self.mileage = 0 def get_main_information(self): # self cannot be omitted \u0026#34;\u0026#34;\u0026#34;Get the main information of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Brand: {} Model: {} Year: {}\u0026#34;.format(self.brand, self.model, self.year)) def get_mileage(self): \u0026#34;\u0026#34;\u0026#34;Get the mileage of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Mileage: {} km\u0026#34;.format(self.mileage)) def set_mileage(self, distance): \u0026#34;\u0026#34;\u0026#34;Set the mileage of the car\u0026#34;\u0026#34;\u0026#34; if distance \u0026gt;= 0: self.mileage = distance else: print(\u0026#34;Mileage cannot be negative!\u0026#34;) def increment_mileage(self, distance): \u0026#34;\u0026#34;\u0026#34;Accumulate the mileage\u0026#34;\u0026#34;\u0026#34; if distance \u0026gt;= 0: self.mileage += distance else: print(\u0026#34;The added mileage cannot be negative!\u0026#34;) Subclass\nclass Subclass name (Parent class name):\nCreate an electric car class class ElectricCar(Car): \u0026#34;\u0026#34;\u0026#34;Simulate an electric car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the electric car\u0026#34;\u0026#34;\u0026#34; super().__init__(brand, model, year) # Declare the inheritance of the parent class, super is the superclass (parent class) Automatically inherit all methods from the parent class my_electric_car = ElectricCar(\u0026#34;NextWeek\u0026#34;, \u0026#34;FF91\u0026#34;, 2046) my_electric_car.get_main_information() # Brand: NextWeek Model: FF91 Year: 2046 Add attributes and methods to the subclass # class ElectricCar(Car): \u0026#34;\u0026#34;\u0026#34;Simulate an electric car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year, bettery_size):# New parameters: bettery_size \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the electric car\u0026#34;\u0026#34;\u0026#34; super().__init__(brand, model, year) # Declare the inheritance of the parent class self.bettery_size = bettery_size # Battery capacity self.electric_quantity = bettery_size # Battery remaining capacity self.electric2distance_ratio = 5 # Electric quantity distance conversion coefficient 5 km/kW.h self.remainder_range = self.electric_quantity*self.electric2distance_ratio # Remaining mileage def get_electric_quantit(self): \u0026#34;\u0026#34;\u0026#34;Get the current battery capacity\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Current battery remaining capacity: {} kW.h\u0026#34;.format(self.electric_quantity)) def set_electric_quantity(self, electric_quantity): \u0026#34;\u0026#34;\u0026#34;Set the battery remaining capacity, recalculate the mileage that can be supported\u0026#34;\u0026#34;\u0026#34; if electric_quantity \u0026gt;= 0 and electric_quantity \u0026lt;= self.bettery_size: self.electric_quantity = electric_quantity self.remainder_range = self.electric_quantity*self.electric2distance_ratio else: print(\u0026#34;The battery remaining capacity is not set in a reasonable range!\u0026#34;) def get_remainder_range(self): \u0026#34;\u0026#34;\u0026#34;Get the remaining mileage\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;The current battery remaining capacity can continue driving {} km\u0026#34;.format(self.remainder_range)) my_electric_car = ElectricCar(\u0026#34;NextWeek\u0026#34;, \u0026#34;FF91\u0026#34;, 2046, 70) my_electric_car.get_electric_quantit() # Current battery remaining capacity: 70 kW.h my_electric_car.get_remainder_range() # The current battery remaining capacity can continue driving 350 km my_electric_car.set_electric_quantity(50) # Reset the battery remaining capacity my_electric_car.get_electric_quantit() # Current battery remaining capacity: 50 kW.h my_electric_car.get_remainder_range() # The current battery remaining capacity can continue driving 250 km Overwrite the parent class method - Polymorphism # First look for the method in the subclass, if not found, look for the method in the parent class. Therefore, the subclass can overwrite the parent class method.\nclass ElectricCar(Car): \u0026#34;\u0026#34;\u0026#34;Simulate an electric car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year, bettery_size): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the electric car\u0026#34;\u0026#34;\u0026#34; super().__init__(brand, model, year) # Declare the inheritance of the parent class self.bettery_size = bettery_size # Battery capacity self.electric_quantity = bettery_size # Battery remaining capacity self.electric2distance_ratio = 5 # Electric quantity distance conversion coefficient 5 km/kW.h self.remainder_range = self.electric_quantity*self.electric2distance_ratio # Remaining mileage def get_main_information(self): # Overwrite the parent class method \u0026#34;\u0026#34;\u0026#34;Get the main information of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Brand: {} Model: {} Year: {} Remaining mileage: {} km\u0026#34; .format(self.brand, self.model, self.year, self.bettery_size*self.electric2distance_ratio)) my_electric_car = ElectricCar(\u0026#34;NextWeek\u0026#34;, \u0026#34;FF91\u0026#34;, 2046, 70) my_electric_car.get_main_information() # Brand: NextWeek Model: FF91 Year: 2046 Remaining mileage: 350 km Using instances in classes # Abstract the battery as an object.\nclass Bettery(): \u0026#34;\u0026#34;\u0026#34;Simulate the battery of an electric car\u0026#34;\u0026#34;\u0026#34; def __init__(self, bettery_size = 70): self.bettery_size = bettery_size # Battery capacity self.electric_quantity = bettery_size # Battery remaining capacity self.electric2distance_ratio = 5 # Electric quantity distance conversion coefficient 5 km/kW.h self.remainder_range = self.electric_quantity*self.electric2distance_ratio # Remaining mileage def get_electric_quantit(self): \u0026#34;\u0026#34;\u0026#34;Get the current battery remaining capacity\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Current battery remaining capacity: {} kW.h\u0026#34;.format(self.electric_quantity)) def set_electric_quantity(self, electric_quantity): \u0026#34;\u0026#34;\u0026#34;Set the battery remaining capacity, recalculate the mileage that can be supported\u0026#34;\u0026#34;\u0026#34; if electric_quantity \u0026gt;= 0 and electric_quantity \u0026lt;= self.bettery_size: self.electric_quantity = electric_quantity self.remainder_range = self.electric_quantity*self.electric2distance_ratio else: print(\u0026#34;The battery remaining capacity is not set in a reasonable range!\u0026#34;) def get_remainder_range(self): \u0026#34;\u0026#34;\u0026#34;Get the remaining mileage\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;The current battery remaining capacity can continue driving {} km\u0026#34;.format(self.remainder_range)) class ElectricCar(Car): \u0026#34;\u0026#34;\u0026#34;Simulate an electric car\u0026#34;\u0026#34;\u0026#34; def __init__(self, brand, model, year, bettery_size): \u0026#34;\u0026#34;\u0026#34;Initialize the attributes of the electric car\u0026#34;\u0026#34;\u0026#34; super().__init__(brand, model, year) # Declare the inheritance of the parent class self.bettery = Bettery(bettery_size) # Battery def get_main_information(self): # Overwrite the parent class method \u0026#34;\u0026#34;\u0026#34;Get the main information of the car\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Brand: {} Model: {} Year: {} Remaining mileage: {} km\u0026#34; .format(self.brand, self.model, self.year, self.bettery.bettery_size*self.bettery.electric2distance_ratio)) my_electric_car = ElectricCar(\u0026#34;NextWeek\u0026#34;, \u0026#34;FF91\u0026#34;, 2046, 70) my_electric_car.get_main_information() # Brand: NextWeek Model: FF91 Year: 2046 Remaining mileage: 350 km my_electric_car.bettery.get_electric_quantit() # Current battery remaining capacity: 70 kW.h my_electric_car.bettery.set_electric_quantity(50) # Reset the battery remaining capacity my_electric_car.bettery.get_electric_quantit() # Current battery remaining capacity: 50 kW.h my_electric_car.bettery.get_remainder_range() # The current battery remaining capacity can continue driving 250 km "},{"id":25,"href":"/posts/python-cheatsheet/","title":"Python Cheatsheet","section":"Blog","content":" Basic Data Types # bin(16) oct(16) hex(16)\nint(a, 2) int(b, 8) int(c, 16)\nround(a, 1)\npow(x,n)\nForward indexing - starts incrementing from 0, and a space is also a position. Backward indexing - starts decrementing from -1, and a space is also a position. variable[start🔚step]\nwhen the step is -1, which means the previous position is greater than the latter position by -1.\nString # .split(\u0026quot; \u0026quot;) \u0026quot;,\u0026quot;.join(str) .strip(the character to be removed) .replace(\u0026quot;to be replaced\u0026quot;，\u0026quot;replace\u0026quot;) .count(\u0026quot;str\u0026quot;) .upper() .lower() .title() any() all() type() isinstance(var, type) str(num) int() float() eval() List # variable[start🔚step] use + to concatenate lists use * to duplicate lists\n.append(element) .extend(list) .insert(position, element) .remove(element) default is the first element meeting the condition .pop(position) default is the last .clear() empty the list .index(element) return its index .count(element) .reverse() in-place reverse, no return value .copy() shallow copy == [:] .sort() in-place sort, no return value. list.sort(reverse = True) sorted(列表) temporary sort, original list remains unchanged. sorted(列表, reverse = True) Tuple # def f1(x): return x2, x3 # packing\na, b = f1(3) unpacking zip() packing\nDictionary # unordered key must be immutable dict[key] variable[new key] = new value del variable[key] .keys() return the list of keys .values() return the list of values .items() return the list of key-value pairs .get(key, default) get the value of the key, if the key does not exist, return the default value .update(dict) update the dictionary, if the key does not exist, add it .pop(key) delete the value of the key .clear() clear the dictionary .copy() shallow copy Set # unordered, which means the pop is invalid element must be immutable .add(element) .remove(element) .clear() .copy() S \u0026amp; T intersection S | T union S - T difference S ^ T XOR "},{"id":26,"href":"/posts/python-function-parameter/","title":"Python Function Parameter","section":"Blog","content":"This blog will review the function parameter of Python. Mainly about the parameter passing, Keyword and Position Parameter, Anonymous Function, and unit test with assert.\nCH5 Function # Function Parameter # Parameter Passing # Formal and Actual Parameters # Formal parameter: parameter in function definition, actually variable name Actual parameter: parameter in function call, actually variable value Position Parameter # Assign value to formal parameter according to position order Actual parameter and formal parameter must be one-to-one, one cannot be more, one cannot be less def function(x, y, z): print(x, y, z) function(1, 2, 3) # x = 1; y = 2; z = 3 Keyword Parameter # Break position limit, directly call name to pass value (formal parameter = actual parameter) def function(x, y, z): print(x, y, z) function(y=1, z=2, x=3) # x = 1; y = 2; z = 3 Position parameter can be mixed with keyword parameter, position parameter must be placed before keyword parameter function(1, z=2, y=3) Default Parameter # Assign value to formal parameter in definition stage – the common value of the parameter Default parameter must be placed after non-default parameter When calling function, the parameter can be omitted def register(name, age, sex=\u0026#34;male\u0026#34;): print(name, age, sex) register(\u0026#34;timerring\u0026#34;, 18) Default parameter should be set to immutable type (number, string, tuple) def function(ls=[]): print(id(ls)) ls.append(1) print(id(ls)) print(ls) function() # 1759752744328 # 1759752744328 # [1] function() # 1759752744328 # 1759752744328 # [1, 1] As can be seen from the above, the address of the list has not changed. Each operation is performed on the original address list, and the content has changed, so it seems to have a memory function. Because the default parameter is set to a mutable type (list).\ndef function(ls=\u0026#34;Python\u0026#34;): print(id(ls)) ls += \u0026#34;3.7\u0026#34; print(id(ls)) print(ls) function() # 1759701700656 # 1759754352240 # Python3.7 function() # 1759701700656 # 1759754353328 # Python3.7 Will not produce \u0026ldquo;memory function\u0026rdquo;, each increment to a new address\nVariable Length Parameter *args # Don\u0026rsquo;t know how many parameters will be passed *args This parameter must be placed at the end of the parameter list def foo(x, y, z, *args): print(x, y ,z) print(args) foo(1, 2, 3, 4, 5, 6) # Extra parameters, packaged and passed to args # 1 2 3 # (4, 5, 6) Unpacking actual parameters def foo(x, y, z, *args): print(x, y ,z) print(args) foo(1, 2, 3, [4, 5, 6]) # List is packaged as a tuple and assigned to args # 1 2 3 # ([4, 5, 6],) foo(1, 2, 3, *[4, 5, 6]) # * unpacks these lists, strings, tuples, or sets # 1 2 3 # (4, 5, 6) Variable Length Parameter **kwargs # def foo(x, y, z, **kwargs): print(x, y ,z) print(kwargs) foo(1, 2, 3, a=4, b=5, c=6) # Extra parameters, packaged and passed to kwargs in the form of a dictionary # 1 2 3 # {\u0026#39;a\u0026#39;: 4, \u0026#39;b\u0026#39;: 5, \u0026#39;c\u0026#39;: 6} Unpacking actual parameters def foo(x, y, z, **kwargs): print(x, y ,z) print(kwargs) foo(1, 2, 3, **{\u0026#34;a\u0026#34;: 4, \u0026#34;b\u0026#34;: 5, \u0026#34;c\u0026#34;:6}) # 1 2 3 # {\u0026#39;a\u0026#39;: 4, \u0026#39;b\u0026#39;: 5, \u0026#39;c\u0026#39;: 6} Variable Length Parameter Combination # def foo(*args, **kwargs): print(args) print(kwargs) foo(1, 2, 3, a=4, b=5, c=6) # (1, 2, 3) # {\u0026#39;a\u0026#39;: 4, \u0026#39;b\u0026#39;: 5, \u0026#39;c\u0026#39;: 6} Function Body and Variable Scope # Function body is a piece of code that will only be executed when the function is called, and the code structure is no different from other code Local variable – only defined and used within the function body Global variable – all variables defined outside are global variables, and global variables can be used directly within the function body Define global variable in function body through global def multipy(x, y): global z z = x*y return z print(multipy(2, 9)) # 18 print(z) # 18 Return Value # Single Return Value # def foo(x): return x**2 Multiple Return Values – in the form of a tuple # def foo(x): return 1, x, x**2, x**3 # Comma separated, packaged and returned print(foo(3)) # (1, 3, 9, 27) a, b , c, d = foo(3) # Unpacking assignment print(a) # 1 print(b) # 3 print(c) # 9 print(d) # 27 No return statement default is None # Suggestions # Function and parameter naming:A combination of lowercase letters and underscores. Should include a brief description of the function\u0026rsquo;s functionality, followed by the function definition def foo(): # This function is used to... pass Leave two lines before and after the function definition def f1(): pass # Leave two lines def f2(): pass Default parameter assignment does not require spaces on both sides Unit Test with assert – Assertion # assert expression Trigger exception when expression result is false assert game_over(21, 8) == False --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) \u0026lt;ipython-input-42-88b651626036\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 4 assert game_over(21, 8) == False AssertionError: Anonymous Function # The most suitable use of anonymous functions is with key = lambda Ensemble: Function body, especially when paired with sort() sorted()\nSort sort() sorted() ls = [(93, 88), (79, 100), (86, 71), (85, 85), (76, 94)] ls.sort(key = lambda x: x[1])# Sort by the second data of each tuple ls # [(86, 71), (85, 85), (93, 88), (76, 94), (79, 100)] ls = [(93, 88), (79, 100), (86, 71), (85, 85), (76, 94)] temp = sorted(ls, key = lambda x: x[0]+x[1], reverse=True)# Get descending sort temp # [(93, 88), (79, 100), (85, 85), (76, 94), (86, 71)] max() min() ls = [(93, 88), (79, 100), (86, 71), (85, 85), (76, 94)] n = max(ls, key = lambda x: x[1]) n # (79, 100) "},{"id":27,"href":"/posts/python-control-structure/","title":"Python Control Structure","section":"Blog","content":"This blog will review the control structure of Python.\nCH4 Program Control Structure # Condition Test # Logical Operation # Priority of compound logical operations\nNon \u0026gt; And \u0026gt; Or print((a \u0026gt; b) and (b \u0026gt; c)) # And print((a \u0026gt; b) or (b \u0026gt; c)) # Or print(not(a \u0026gt; b)) # Not Existence Operation # Element in list/string\nBranch Structure if Statement # Simple Version # if age \u0026gt; 7: print(\u0026#34;if\u0026#34;) else: print(\u0026#34;else\u0026#34;) Multiple Branch # if age \u0026lt; 7: print(\u0026#34;7\u0026#34;) elif age \u0026lt; 13: print(\u0026#34;13\u0026#34;) elif age \u0026lt; 60: print(\u0026#34;60\u0026#34;) else: # Sometimes for clarity, it can also be written as elif age \u0026gt;= 60: print(\u0026#34;60\u0026#34;) No matter how many branches, only one branch is executed\nIteration Loop for Loop # Execution Process # Extract each element from the iterable object and perform the corresponding operation List[ ], tuple( ), set{ }, string\u0026quot; \u0026quot;\ngraduates = (\u0026#34;apple\u0026#34;, \u0026#34;google\u0026#34;, \u0026#34;timerring\u0026#34;) for graduate in graduates: print(\u0026#34;Congratulations, \u0026#34;+graduate) Dictionary\nstudents = {201901: \u0026#39;apple\u0026#39;, 201902: \u0026#39;google\u0026#39;, 201903: \u0026#39;timerring\u0026#39;} for k, v in students.items(): print(k, v) for student in students.keys(): # for student in students is equivalent to above range()\nres = [] for i in range(1, 10, 2): res.append(i ** 2) print(res) break and continue # break End whole cycle continue End this cycle for and else # If for loop is executed completely without being interrupted by break, then run else block\nproduct_scores = [89, 90, 99, 70, 67, 78, 85, 92, 77, 82] i = 0 for score in product_scores: if score \u0026lt; 75: i+=1 if i == 2: print(\u0026#34;Product sampling fails\u0026#34;) break else: print(\u0026#34;Product sampling qualified\u0026#34;) while # while and else # If while loop is executed completely without being interrupted by break, then run else block\ncount = 0 while count \u0026lt;= 2 : count += 1 print(\u0026#34;Loop\u0026#34;,count) else: print(\u0026#34;over\u0026#34;) # Loop 1 # Loop 2 # Loop 3 # over "},{"id":28,"href":"/posts/python-composite-data-type/","title":"Python Composite Data Type","section":"Blog","content":"This article will review the composite data type in Python, such as list, tuple, dictionary, and set.\nCH3 Composite Data Type # List # List Definition # Sequence type: Internal elements have positional relationships and can be accessed by position number List is a sequence type that can use multiple types of elements, supports element addition, deletion, query, and modification operations ls = [\u0026#34;Python\u0026#34;, 1989, True, {\u0026#34;version\u0026#34;: 3.7}] Another way to generate: list(iterable), iterable includes: string, tuple, set, range, etc. list(\u0026#34;Welcome to subscribe this column\u0026#34;) # [\u0026#39;W\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;n\u0026#39;] list((\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;student\u0026#34;)) # [\u0026#39;I\u0026#39;, \u0026#39;am\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;student\u0026#39;] list({\u0026#34;Jim\u0026#34;, \u0026#34;Green\u0026#34;}) # [\u0026#39;Green\u0026#39;, \u0026#39;Jim\u0026#39;] range(start number, end number, number interval)\nIf the start number is omitted, it defaults to 0 Must include the end number, closed on the left and open on the right The number interval is omitted, it defaults to 1 for i in range(1, 11, 2): print(i) # 1 # 3 # 5 # 7 # 9 list(range(1, 11, 2)) # [1, 3, 5, 7, 9] List Properties # List length —— len(list) List index —— Same as string cars = [\u0026#34;BYD\u0026#34;, \u0026#34;BMW\u0026#34;, \u0026#34;AUDI\u0026#34;, \u0026#34;TOYOTA\u0026#34;] print(cars[0]) # BYD List Slicing # variable name[start position:end position:slice interval]\ncars = [\u0026#34;BYD\u0026#34;, \u0026#34;BMW\u0026#34;, \u0026#34;AUDI\u0026#34;, \u0026#34;TOYOTA\u0026#34;] print(cars[:3]) # The first three elements, start position omitted, defaults to 0; slice interval omitted, defaults to 1 # [\u0026#39;BYD\u0026#39;, \u0026#39;BMW\u0026#39;, \u0026#39;AUDI\u0026#39;] print(cars[1:4:2]) # The second to fourth elements, the difference between the front and back index is 2 # [\u0026#39;BMW\u0026#39;, \u0026#39;TOYOTA\u0026#39;] print(cars[:]) # Get the entire list, end position omitted, defaults to the last # [\u0026#39;BYD\u0026#39;, \u0026#39;BMW\u0026#39;, \u0026#39;AUDI\u0026#39;, \u0026#39;TOYOTA\u0026#39;] print(cars[-4:-2]) # Get the first two elements # [\u0026#39;BYD\u0026#39;, \u0026#39;BMW\u0026#39;] Reverse slicing cars = [\u0026#34;BYD\u0026#34;, \u0026#34;BMW\u0026#34;, \u0026#34;AUDI\u0026#34;, \u0026#34;TOYOTA\u0026#34;] print(cars[:-4:-1]) # Start position omitted, defaults to -1 # [\u0026#39;TOYOTA\u0026#39;, \u0026#39;AUDI\u0026#39;, \u0026#39;BMW\u0026#39;] print(cars[::-1]) # Get the reverse list # [\u0026#39;TOYOTA\u0026#39;, \u0026#39;AUDI\u0026#39;, \u0026#39;BMW\u0026#39;, \u0026#39;BYD\u0026#39;] List Operators # Use + to concatenate lists Use * to multiply lists [0]*10 # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] List Methods # Add Element # Add element to the end —— list.append(element) Insert element at any position —— list.insert(position number, element) Append another list to the end —— list.extend(another list) append will add the entire list as a single element to the end of the list.\nlanguages.append([\u0026#34;Ruby\u0026#34;, \u0026#34;PHP\u0026#34;]) # [\u0026#39;Python\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;Java\u0026#39;, [\u0026#39;Ruby\u0026#39;, \u0026#39;PHP\u0026#39;]] extend will add each element in the second list to the first list.\nlanguages = [\u0026#39;Python\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;Java\u0026#39;] languages.extend([\u0026#34;Ruby\u0026#34;, \u0026#34;PHP\u0026#34;]) # [\u0026#39;Python\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Ruby\u0026#39;, \u0026#39;PHP\u0026#39;] Delete Element # Delete element at list i position —— list.pop(i) languages = [\u0026#39;Python\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;Java\u0026#39;] languages.pop(1) # [\u0026#39;Python\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;Java\u0026#39;] Do not write position information, default to delete the last element —— list.pop() Delete the first occurrence of the element to be deleted in the list —— list.remove(element) Find Element # The position of the first occurrence of the element to be searched in the list —— list.index(element) Modify Element # Modify element by \u0026ldquo;index first, then assign\u0026rdquo; —— list[position]=new value List Copy # languages_2 = languages Incorrect way: This only creates an alias for the list\nCorrect way —— Shallow copy\nMethod 1: list.copy()\nMethod 2: list[:] is equivalent to slicing the entire list\nList Sorting # Use list.sort() to sort the list in place, no return value, default to increasing. Decreasing order list.sort(reverse = True) Use sorted(list) to temporarily sort the list, the original list remains unchanged, and the sorted list is returned. The same decreasing order sorted(list, reverse = True) List Reversal # Use list.reverse() to reverse the list in place, no return value List Traversal # Use for loop Tuple # Tuple Expression # Treat the tuple as an \u0026ldquo;immutable list\u0026rdquo; Does not support element addition, element deletion, element modification operations, and other operations are completely consistent with list operations Common Uses of Tuple # Packing and Unpacking\nExample 1: The return value is packaged as a tuple def f1(x): return x**2, x**3 # Packing return print(f1(3)) # (9, 27) print(type(f1(3))) # \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; a, b = f1(3) # Unpacking assignment print(a) # 9 print(b) # 27 Example 2: Use zip function to pack numbers = [201901, 201902, 201903] name = [\u0026#34;Apple\u0026#34;, \u0026#34;Google\u0026#34;, \u0026#34;Tesla\u0026#34;] list(zip(numbers, name)) # [(201901, \u0026#39;Apple\u0026#39;), (201902, \u0026#39;Google\u0026#39;), (201903, \u0026#39;Tesla\u0026#39;)] # Unpack each tuple immediately for number,name in zip(numbers,name): print(number, name) # 201901 Apple # 201902 Google # 201903 Tesla Dictionary # Dictionary Expression # Regular dictionary is unordered and can only be accessed by key Dictionary Key Requirements\nDictionary keys cannot be repeated. If they are repeated, the previous keys are overwritten.\nDictionary keys must be immutable types，if the key is mutable, the corresponding stored value cannot be found.\nImmutable types: numbers, strings, tuples. Mutable types: lists, dictionaries, sets. Once determined, they can be freely added, deleted, and modified. Therefore, these three types cannot be used as dictionary keys. Dictionary Properties # Dictionary length len() —— Number of key-value pairs Dictionary index, get the corresponding value through dictionary[key] Dictionary Operations # Add key-value pair\nvariable name[new key] = new value Delete key-value pair\ndel variable name[key to be deleted] variable name.pop(key to be deleted) variable name.popitem() Randomly delete a key-value pair and return it as a tuple Modify value\nModify the corresponding value through \u0026ldquo;index first, then assign\u0026rdquo; d.get( )\nd.get(key, default) Get the value corresponding to the key from the dictionary d, if there is no such key, return default\nExample: Count the frequency of characters in \u0026ldquo;牛奶奶找刘奶奶买牛奶\u0026rdquo;\ns = \u0026#34;牛奶奶找刘奶奶买牛奶\u0026#34; d = {} print(d) for i in s: d[i] = d.get(i, 0)+1 # If the character appears for the first time, return default 0, then add 1 to count. If there is already a key i, return the value corresponding to the key i. print(d) # {} # {\u0026#39;牛\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 2} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 2, \u0026#39;找\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 2, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 3, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 4, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 1, \u0026#39;奶\u0026#39;: 4, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1, \u0026#39;买\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 2, \u0026#39;奶\u0026#39;: 4, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1, \u0026#39;买\u0026#39;: 1} # {\u0026#39;牛\u0026#39;: 2, \u0026#39;奶\u0026#39;: 5, \u0026#39;找\u0026#39;: 1, \u0026#39;刘\u0026#39;: 1, \u0026#39;买\u0026#39;: 1} d.keys( ) d.values( )\nGet all keys and values separately.\nstudents = {201901: \u0026#39;Apple\u0026#39;, 201902: \u0026#39;Google\u0026#39;, 201903: \u0026#39;Tesla\u0026#39;} print(list(students.keys())) print(list(students.values())) # [201901, 201902, 201903] # [\u0026#39;Apple\u0026#39;, \u0026#39;Google\u0026#39;, \u0026#39;Tesla\u0026#39;] d.items( )\nprint(list(students.items())) # [(201901, \u0026#39;Apple\u0026#39;), (201902, \u0026#39;Google\u0026#39;), (201903, \u0026#39;Tesla\u0026#39;)] for k, v in students.items(): # Unpack print(k, v) # 201901 Apple # 201902 Google # 201903 Tesla Set # Set Expression # A collection of unordered elements that are mutually exclusive, which can be used for deduplication Elements must be immutable types: numbers, strings, or tuples, which can be considered as the keys of dictionaries Can be considered as a dictionary without values or values as None Set Operations # S \u0026amp; T Returns a new set, including elements that are in both sets S and T S | T Returns a new set, including all elements in sets S and T S ^ T Returns a new set, including non-common elements in sets S and T S - T Returns a new set, including elements in set S but not in set T Set Methods # Add element S.add(x) Remove element S.remove(x) Set length len(S) Set traversal —— Use for loop for star in stars: print(star) "},{"id":29,"href":"/posts/python-basic-data-type/","title":"Python Basic Data Type","section":"Blog","content":"This article will explore data types and common methods for them in Python. The content of this review is as follows: number type, string type, boolean type and type conversion.\nCH2 Basic Data Type # 1.Number Type # Basic Type # Integer Type # Default is decimal Binary: 0b, Octal: 0o, Hexadecimal: 0x a = bin(16) # Binary b = oct(16) # Octal c = hex(16) # Hexadecimal print(a, b, c) # 0b10000 0o20 0x10 # Attention: str type Convert other base to decimal d = int(a, 2) # Binary e = int(b, 8) # Octal f = int(c, 16) # Hexadecimal print(d, e, f) # 16 16 16 Float Type # Floating point number (0.1+0.2) == 0.3 # 0.30000000000000004 # False Computer uses binary to represent floating point number\nReason: Some decimal numbers cannot be represented by binary\nBinary Decimal 0.00011001100110011001 0.09999942779541016\n0.0011001100110011 0.1999969482421875\n0.01001100110011001 0.29999542236328125\n0.01100110011001101 0.40000152587890625\n0.1 === $1*2^{-1}$ === 0.5\nUsually not affect calculation precision Can use rounding to solve: round(parameter, certain number of decimal places) a = 3*0.1 print(a) # 0.30000000000000004 b = round(a, 1) print(b) # 0.3 b == 0.3 # True Complex Type # # Capital J or lowercase j 3+4j 2+5J # When the imaginary part coefficient is 1, it needs to be explicitly written 2+1j Operations # Addition, subtraction, multiplication, division Negation - Exponentiation ** Integer quotient //: x/y floor division Modulo operation %: x/y calculate remainder Integer and floating point number operations result in floating point numbers\nThe result of division is a floating point number 8/4 = 2.0\nOperations Functions # Calculate absolute value abs() abs(3+4j) # Calculate the modulus of the complex number a+bj (a^2+b^2)=0.5 # 5.0 Power pow(x,n) is equivalent to x**n Power modulo pow(x,n,m) is equivalent to x**n % m Rounding round(x,n) n is the number of decimal places, default is no n, rounding to integer Integer quotient and modulo operation divmod(x,y) is equivalent to returning a tuple (x//y,x % y) Sequence maximum/minimum value max( ) min( ) a = [3, 2, 3, 6, 9, 4, 5] print(\u0026#34;max:\u0026#34;, max(a)) print(\u0026#34;min:\u0026#34;, min(a)) # max: 9 # min: 2 Sum sum(x) Note: sum needs to fill in a sequence data sum((1, 2, 3, 4, 5)) # 15 Use scientific calculation library math\\scipy\\numpy import math # Import library print(math.exp(1)) # Exponential operation e^x print(math.log2(2)) # Logarithmic operation print(math.sqrt(4)) # Square root operation Equivalent to 4^0.5 import numpy as np a = [1, 2, 3, 4, 5] print(np.mean(a)) # Calculate mean print(np.median(a)) # Calculate median print(np.std(a)) # Calculate standard deviation 2.String Type # String Expression # Use \u0026quot;\u0026quot; or '' to enclose any character, refer to the situation where the string contains double quotes or single quotes. If you only want to use one, you can use the escape character \\ to achieve it. # print(\u0026#34;\u0026#34;Python\u0026#34; is good\u0026#34;) # False print(\u0026#34;\\\u0026#34;Python\\\u0026#34; is good\u0026#34;) # \\ character # \u0026#34;Python\u0026#34; is good The escape character can be used to continue inputting on a new line s = \u0026#34;py\\ thon\u0026#34; print(s) # python String Properties # String Index (Single Character) # Variable name[position number]\nPositive index – starts from 0 and increases, spaces are also a position Negative index – starts from -1 and decreases Position number cannot exceed the length of the string s = \u0026#34;My name is Peppa Pig\u0026#34; print(s[0]) # M print(s[2]) # print(s[-1]) # g print(s[-3]) # P String Slicing (Multiple Characters) # Variable name[start position:end position:slice interval]\nThe slice interval defaults to 1, which can be omitted Range: front closed and back open s = \u0026#34;Python\u0026#34; print(s[0:3:1]) == print(s[0:3]) # Pyt print(s[0:3:2]) # Pt The starting position is 0, which can be omitted The end position is omitted, which means it can be taken to the last character s = \u0026#34;Python\u0026#34; print(s[0:6]) == print(s[:6]) == print(s[:]) # Python Reverse Slicing\nThe starting position is -1, which can be omitted The end position is omitted, which means it can be taken to the first character The key point is -1, which means the previous position is -1 larger than the next position s = \u0026#34;123456789\u0026#34; print(s[-1:-10:-1]) # 987654321 print(s[:-10:-1]) # 987654321 print(s[::-1]) # 987654321 String Operators # String Concatenation # String1 + String2 String Multiplication # String * n c = a+b print(c*3) print(3*c) Member Operation # Subset in full set: Any continuous slice is a subset of the original string folk_singers = \u0026#34;Peter, Paul and Mary\u0026#34; \u0026#34;Peter\u0026#34; in folk_singers # True Traverse string characters: for character in string for s in \u0026#34;Python\u0026#34;: print(s) # P # y # t # h # o # n String Processing Functions # String Length # Number of characters len(string) Character Encoding # Convert Chinese characters, English letters, numbers, special characters, etc. to computer-recognizable binary numbers\nEach single character corresponds to a unique, non-repeating binary code Python uses Unicode encoding ord(character)：Convert character to Unicode code\nprint(ord(\u0026#34;1\u0026#34;)) # 49 print(ord(\u0026#34;a\u0026#34;)) # 97 chr(Unicode code)：Convert Unicode code to character\nprint(chr(1010)) # ϲ print(chr(23456)) # 宠 String Processing Methods # Return a list, the original string remains unchanged\nString Splitting .split(\u0026quot; \u0026quot;) # languages = \u0026#34;Python C C++ Java PHP R\u0026#34; languages_list = languages.split(\u0026#34; \u0026#34;)# The parameter in the parentheses is the mark we want to split the target string print(languages_list) print(languages_list) # [\u0026#39;Python\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C++\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;PHP\u0026#39;, \u0026#39;R\u0026#39;] print(languages) # Python C C++ Java PHP R String Aggregation \u0026quot;,\u0026quot;.join(\u0026quot; \u0026quot;) # Iterable type, such as string, list s = \u0026#34;12345\u0026#34; s_join = \u0026#34;,\u0026#34;.join(s) # Take out each element of the iterable object, add the aggregation character between the two s_join # \u0026#39;1,2,3,4,5\u0026#39; The elements of the sequence type must be of character type # s = [1, 2, 3, 4, 5] cannot be used for aggregation s = [\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5\u0026#34;] \u0026#34;*\u0026#34;.join(s) # \u0026#39;1*2*3*4*5\u0026#39; Delete specific characters at both ends .strip(\u0026quot;delete character\u0026quot;) # strip searches from both sides, deletes the specified character when encountered, stops searching when a non-specified character is encountered There are also left deletion lstrip and right deletion rstrip s = \u0026#34; I have many blanks \u0026#34; print(s.strip(\u0026#34; \u0026#34;)) # Search from both sides, delete spaces after encountering the specified character, then stop # I have many blanks print(s.lstrip(\u0026#34; \u0026#34;)) # I have many blanks print(s.rstrip(\u0026#34; \u0026#34;)) # I have many blanks String Replacement .replace(\u0026quot;replaced\u0026quot;, \u0026quot;replaced with\u0026quot;) # s = \u0026#34;Python is coming\u0026#34; s1 = s.replace(\u0026#34;Python\u0026#34;,\u0026#34;Py\u0026#34;) print(s1) # Py is coming String Count .count(\u0026quot;sample string\u0026quot;) # s = \u0026#34;Python is an excellent language\u0026#34; print(\u0026#34;an:\u0026#34;, s.count(\u0026#34;an\u0026#34;)) # an: 2 String Letter Case and First Letter Capital .upper() .lower() .title() # s = \u0026#34;Python\u0026#34; print(s.upper()) # PYTHON print(s.lower()) # python print(s.title()) # Python 3.Boolean Type # Logical Operation Results # any() Data has a non-zero value is True all() Data has a zero value is False (all non-zero) print(any([False,1,0,None])) # 0 False None are all zero # True print(all([False,1,0,None])) # False Mask for numpy array # import numpy as np x = np.array([[1, 3, 2, 5, 7]]) # Define numpy array print(x \u0026gt; 3) # [[False False False True True]] x[x \u0026gt; 3] # array([5, 7]) 4.Type Identification and Type Conversion # Type Identification # type()\nage = 20 name = \u0026#34;Ada\u0026#34; print(type(age)) # \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; print(type(name)) # \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; isinstance(variable, type) Recognize inheritance\nThe variable type is a subtype of the type, then it is true, otherwise it is false print(isinstance(age, int)) # Recognize inheritance, here int is equivalent to a class # True print(isinstance(age, object)) # object is the ancestor of all classes # True String Check Methods # string.isdigit() Character is only composed of numbers string.isalpha() Character is only composed of letters string.isalnum() Character is only composed of numbers and letters Type Conversion # Number type to string str(number type) String composed of only numbers to number int() float() eval() s1 = \u0026#34;20\u0026#34; int(s1) # 20 s2 = \u0026#34;10.1\u0026#34; # int(s2) will error float(s1) # 20.0 eval(s2) # 10.1 "},{"id":30,"href":"/posts/python-basic-syntax-elements/","title":"Python Basic Syntax Elements","section":"Blog","content":"Sometimes you may forget about the basic of Python, so let us take a look at the summary of Python basic summary. The content of this review is as follows: data type, variable, control flow, input \u0026amp; output, PEP8 format.\nCH1 Basic Syntax Elements # 1 Data Type # Basic Type: Number, String, Boolean # Number Type\nint float complex (a+bj) String Type\nstr: use \u0026quot; \u0026quot; or ' ' Boolean Type\nbool y = 2 \u0026lt; 1 y # False Composite Type: List, Tuple, Dictionary, Set # List Type, ordered\na = [1, 2, 3, 4, 5] a[4] # 5 Tuple Type, ordered, elements are not modifiable\nb = (1, 2, 3, 4, 5) b[0] # 1 Dictionary Type, key-value mapping, unordered\nstudent = {201901: \u0026#34;john\u0026#34;, 201902: \u0026#34;howe\u0026#34;, 201903: \u0026#34;timerring\u0026#34;} student[201902] # \u0026#39;howe\u0026#39; Set Type, a collection of unique elements, unordered\ns = {\u0026#34;john\u0026#34;, \u0026#34;howe\u0026#34;, \u0026#34;timerring\u0026#34;, \u0026#34;john\u0026#34;} s # {\u0026#39;john\u0026#39;, \u0026#39;howe\u0026#39;, \u0026#39;timerring\u0026#39;} 2 Variable # Variable Naming # What can be used as variable names?\nuppercase letters, lowercase letters, numbers, underscores, and Chinese characters. strictly case-sensitive What is not allowed?\nthe first character cannot be a number there cannot be spaces in the middle of the variable name cannot be the same as the 33 Python reserved words Variable Name Definition Techniques\nunderscore (variable and function name) variable name consists of multiple words: use _ to connect multiple words age_of_students = [17, 18, 19] Camel Case (class name) variable name consists of multiple words: capitalize the first letter of each word AgeOfStudents Constant (e.g. $\\pi$, e) variable name all letters are uppercase MAX_ITERATION = 1000 Variable Assignment # x, y = 1, 2 # separated by \u0026#34;,\u0026#34; print(x, y) x, y = y, x print(x, y) 3 Control Flow # Loop (for) # res = 0 for i in [1,2,3,4,5]: res += i res # 15 Loop (while) # i = 1 res = 0 while i \u0026lt;= 5: res += i i += 1 res # 15 Branch (if) # if condition: execute statement else: execute statement 4 Input \u0026amp; Output # Data Input # External File Import\nfrom local disk, network, etc. See File, Exception, and Module. Dynamic Interactive Input\nx = input(\u0026#34;please input: \u0026#34;) type(x) # str, so the addition is string concatenation Use eval() to remove the quotes\nx = eval(input(\u0026#34;please input: \u0026#34;)) type(x) # int Data Output # Print # Each print() defaults to a newline\nprint(\u0026#34;timerring\u0026#34;) # timerring print(1) # 1 Line Break Control end= # print(123,end=\u0026#34; \u0026#34;)# also can customize the end content print(456) # 123 456 Combined Output # PI = 3.1415926 E = 2.71828 print(\u0026#34;PI = \u0026#34;, PI, \u0026#34;E = \u0026#34;, E) Formatting Output # # one-to-one correspondence print(\u0026#34;PI = {0},E = {1}\u0026#34;.format(PI, E)) # PI = 3.1415926,E = 2.71828 print(\u0026#34;PI = {0},E = {0}\u0026#34;.format(PI, E)) # PI = 3.1415926,E = 3.1415926 # default order print(\u0026#34;PI = {},E = {}\u0026#34;.format(PI, E)) # PI = 3.1415926,E = 2.71828 Decorative Output # Padding Output\nprint(\u0026#34;{0:_^20}\u0026#34;.format(PI)) # 0 is the variable PI, : is the modifier output, _ is the modifier character, ^ is centered, 20 is the output width # ____3.1415926_____ padding print(\u0026#34;{0:*\u0026lt;30}\u0026#34;.format(PI)) # \u0026lt; is left-aligned # 3.1415926********************* Thousands Separator\nprint(\u0026#34;{0:,}\u0026#34;.format(10000000)) # 10,000,000 Simplified Floating Point Output # keep 2 decimal places print(\u0026#34;{0:.2f}\u0026#34;.format(PI)) # 3.14 Output as a percentage print(\u0026#34;{0:.1%}\u0026#34;.format(0.818727)) # 81.9% Scientific Notation Output print(\u0026#34;{0:.2e}\u0026#34;.format(0.818727)) # 8.19e-01 Integer Base Conversion Output\nDecimal to Binary, Unicode, Decimal, Octal, Hexadecimal \u0026#34;Binary {0:b}, Unicode {0:c}, Decimal {0:d}, Octal {0:o}, Hexadecimal {0:x}\u0026#34;.format(450) # Binary 11100010, Unicode \\u1b6, Decimal 450, Octal 702, Hexadecimal 1c2 Summary # Formatting Output: \u0026quot;character{0:modifier}character{1:modifier}character\u0026quot;.format(v0, v1)\nModifier Output: must be strictly in order.\n5 Program Format (PEP8 Format) # Line Maximum Length # All lines are limited to a maximum of 79 characters\nIndentation # Use indentation to represent the logical relationship between statements, indentation: 4 characters Use Spaces # Add a space on both sides of the binary operator Add spaces around different priority operators x = x*2 - 1 c = (a+b) * (a-b) Use spaces after commas Avoid Using Spaces # Do not add spaces around = when specifying keyword arguments or default parameter values def fun(n=1, m=2): print(n, m) Comments # Single-line comment # comment content\nMulti-line comment \u0026quot;\u0026quot;\u0026quot;comment content, can be split into multiple lines\u0026quot;\u0026quot;\u0026quot;\n"},{"id":31,"href":"/posts/deploy-github-pages-with-gpg-signing/","title":"Deploy Github Pages With GPG Signing","section":"Blog","content":"I have been busy migrating my blog this week. Coincidentally, I learned that there may be cases of commit forgery on GitHub. Therefore, for security reasons, I added a GPG signature. However, when deploying Hugo, I encountered many problems regarding whether GPG signatures can also be used. Fortunately, I finally solved them.\nIf you don\u0026rsquo;t know what GPG is, you can read GPG 101.\nHow to Deploy Github Pages With Gpg Signing and Verify # There are two main ways to deploy:\nPush all source files to GitHub directly, then use the relevant action to complete the entire deployment process. Isolate the blog source files from the built files, push the source files to the private repository of GitHub each time, and then set up the relevant workflow in the private repository to push to the public static repository. To ensure greater security, I chose the second method, deploying Hugo in the workflow of GitHub Pages, and using the actions-gh-pages action. However, due to various reasons, the author of this action does not want to add the GPG signature feature. Therefore, we have to solve the problem ourselves.\nImport GPG Key # First, I found a workflow for importing GPG keys on GitHub. After reading the documentation, my own workflow is as follows:\n- name: Import GPG key # import the gpg key to the github action uses: crazy-max/ghaction-import-gpg@v6 # repository https://github.com/crazy-max/ghaction-import-gpg with: # I use the subkey to sign the commit, if you use the primary key, you can refer to his repository docs. gpg_private_key: ${{ secrets.GPG_PRIVATE_KEY }} # the secret gpg subkey passphrase: ${{ secrets.PASSPHRASE }} # the passphrase of the gpg subkey git_user_signingkey: true git_commit_gpgsign: true fingerprint: ${{ secrets.FINGERPRINT }} # the fingerprint of the public subkey you use If you only use the primary secret key of GPG, you do not need to add the fingerprint, and I generated a dedicated subkey for signing for security reasons. Therefore, you need to specify the fingerprint of the public key of the subkey. Note that the fingerprint should be entered without spaces; otherwise, it will report an error 67108933 Not implemented \u0026lt;GPG Agent\u0026gt;. I added this note to the corresponding issue.\nDon\u0026rsquo;t forget to fill in the corresponding secret variables and values in the repository.\nDeploy # Since the author does not plan to add GPG signature, we need to clone the project and modify it ourselves. Usually, the -S option is used in the commit to specify the use of GPG signature. Therefore, I found the corresponding function in the commit and added the corresponding -S option.\nNote that the modified workflow you created cannot be used directly. The author\u0026rsquo;s instructions are as follows:\nThis action and my other actions do not provide the branch execution. I add the lib/index.js for only each release commit. After releasing, I delete it.\nTherefore, we still need to publish a version ourselves. Run ./release.sh directly in the project, and publish the version you wrote. After that, you can reference your version in the workflow, and my workflow is as follows:\n- name: Deploy Web uses: timerring/actions-gh-pages@v5.0.0 # this is adjusted action from peaceiris/actions-gh-pages, you can use it directly. with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # the personal token of the github action external_repository: your_username/your_repository # your target repository publish_branch: main # the branch you want to deploy publish_dir: ./public # the directory you want to deploy user_name: ${{ secrets.USER_NAME }} # the name of the github action user_email: ${{ secrets.USER_EMAIL }} # the email of the github action # ATTENTION: please add your github verified email commit_message: ${{ github.event.head_commit.message }} Note that please ensure that you add the email verified by GitHub; otherwise, the default parameter ${process.env.GITHUB_ACTOR}@users.noreply.github.com will only generate USERNAME@users.noreply.github.com, not ID+USERNAME@users.noreply.github.com. This is a historical issue with GitHub, details can be found here. However, your private key does not contain this UUID, so it cannot be verified by GPG. (Even if you add this UID to the keys, since the user email has not been verified by GitHub, it will only display unverified in the end.)\nIn short, if your GitHub account was created after July 18, 2017, then your GitHub email address is ID+USERNAME@users.noreply.github.com, not the default USERNAME@users.noreply.github.com. In this case, you need to specify the user_email parameter and fill in the email address you have verified.\nFinally, after pushing to the blogsource repository, the workflow will automatically deploy to the blog repository, and the commit will be signed with GPG and display verified!\nYou can check my result here, every commit pushed from the blogsource repository will be signed with GPG and display verified.\nAppendix # If you also need my hugo deployment method, you can directly use the action version I modified and released, repository address timerring/actions-gh-pages, refer to my complete workflow yaml, and don\u0026rsquo;t forget to fill in the corresponding secret variables and values:\nname: deploy on: push: branches: - main workflow_dispatch: jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 ref: main - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.108.0\u0026#34; extended: true - name: Build Web run: hugo --minify - name: Import GPG key # import the gpg key to the github action uses: crazy-max/ghaction-import-gpg@v6 # repository https://github.com/crazy-max/ghaction-import-gpg with: # I use the subkey to sign the commit, if you use the primary key, you can refer to his repository docs. gpg_private_key: ${{ secrets.GPG_PRIVATE_KEY }} # the secret gpg subkey passphrase: ${{ secrets.PASSPHRASE }} # the passphrase of the gpg subkey git_user_signingkey: true git_commit_gpgsign: true fingerprint: ${{ secrets.FINGERPRINT }} # the fingerprint of the public subkey you use - name: Deploy Web uses: timerring/actions-gh-pages@v5.0.0 # this is adjusted action from peaceiris/actions-gh-pages, you can use it directly. with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # the personal token of the github action external_repository: your_username/your_repository # your target repository publish_branch: main # the branch you want to deploy publish_dir: ./public # the directory you want to deploy user_name: ${{ secrets.USER_NAME }} # the name of the github action user_email: ${{ secrets.USER_EMAIL }} # the email of the github action # ATTENTION: please add your github verified email commit_message: ${{ github.event.head_commit.message }} "},{"id":32,"href":"/posts/gpg-101/","title":"GPG 101","section":"Blog","content":" GnuPG is a complete and free implementation of the OpenPGP standard as defined by RFC4880(also known as PGP). GnuPG allows you to encrypt and sign your data and communications; it features a versatile key management system, along with access modules for all kinds of public key directories. GnuPG, also known as GPG, is a command line tool with features for easy integration with other applications.\nThis article I will introduce the basic usage of GPG.\nWhat is GPG? # When it comes to GPG, you should know the PGP first. The PGP is a protocol that provides encryption and digital signature services(Pretty Good Privacy). The GPG is the implementation of the PGP protocol. PGP can support many kinds of encryption algorithms, such as AES, RSA, ECC, etc.\nAnd you can add it to your Github to make every commit to your repository is signed.\nDo not upload any message to the public key servers, it\u0026rsquo;s not secure! Do not do any operation related to public key servers! In this article, I will not mention any operation related to public key servers! The public key servers is a centralized service, and will not delete any messages even you have revoked the public key.\nSome abbreviations # Usage # A =\u0026gt; Authentication (eg. ssh) C =\u0026gt; Certify (Only the primary key have this capability) E =\u0026gt; Encrypt S =\u0026gt; Sign (eg. sign the commit) ? =\u0026gt; Unknown capability\nType # sec =\u0026gt; Secret Primary Key ssb =\u0026gt; Secret Subkey pub =\u0026gt; Public Primary Key sub =\u0026gt; Public Subkey\nFormat # armored: asc binary: pgp Fingerprint # Each key or subkey has a line of 10 groups of 4 characters. This is the SHA-1 hash of the entire key, which is 160 bits, 20 bytes, and is usually represented as 40 hexadecimal numbers. This fingerprint can be used to uniquely identify a key pair.\nKey ID # Format:\nLong: the last 16 characters of the fingerprint. Short: the last 8 characters of the fingerprint. UID # UID is the user id which contains the username, comment and email. Name (Comment) \u0026lt;Email\u0026gt;\nOne secret key can have multiple UIDs. UID is used for the whole keys not just for specific subkey. The uid can add easily, but the existing uid cannot be adjusted, only can be revoked. Validity # When import a key, it will default to [unknown]. You can check the fingerprint and the owner\u0026rsquo;s claim to verify the key.\nTrust network # Trust levels:\nultimate: Normally you should only ultimately trust your own keys. The root of the trust chain. full: Full trust the key, also contains the keys signed by this key. marginal: Trust the key, but not fully trust. If three people trust the key, then I trust it. never: Never trust the key along with the keys signed by this key. How to use it? # Installation # brew install gpg Generate Key # You have to do the following steps quickly. If the process is timeout, you will need to re-do the steps.\ngpg --full-generate-key # 1. Then select the key type, it\u0026#39;s fine by default. # 2. Then select the key expiration, I choose `3y`, because you can renew the key later, and that\u0026#39;s make sure you cn still control the key. Expired keys are only invalid for new encryption and signing. But you can still decrypt and verify the existing information, just will be marked as expired. # 3. Then enter you name(uid), I don\u0026#39;t recommend you to use your real name, you can instead of your username. # 4. Then enter your email, make sure to use the verified email in Github, it\u0026#39;s highly recommended to use the `no-reply` email provided by Github to avoid spam. # 5. Then enter the passphrase, it\u0026#39;s used to encrypt the key. # 6. After a rondom move, your key is generated. Generate subkey # It is recommended to generate a subkey for the key. And just use the primary key to sign the new subkeys. Each subkey has its own application scenario.\n# Enter the primary key interactive mode gpg --edit-key yourNameInprimaryKey(uid or keyid) gpg \u0026gt; addkey # Then the process is the same as the previous steps. This time I choose the RSA(sign only). # Btw, before generate the subkey, it will ask you to enter the passphrase of the primary key. # After the subkey is generated, don\u0026#39;t forget to save the key. gpg \u0026gt; save Genrate a revocation certificate # Imagine you forget the passphrase of the key, or you lose the control, you can use the revocation certificate to revoke the public key. If not, you will need to notify your friends that you don\u0026rsquo;t use the key anymore. That will be a big problem. Thus it is necessary to generate a revocation certificate.\ngpg --gen-revoke -ao revoke.pgp uid(or keyid) # Make choices based on your situation Then you will get a revoke.pgp file, you can use it to revoke the key.\nlist the keys # gpg --list-keys # list the public keys, you can also use `gpg -k` gpg --list-secret-keys # list the secret keys, you can also use `gpg -K` The common usage # # The most common usage! -k or -K gpg -K --with-fingerprint --with-subkey-fingerprint --keyid-format long Besides, there are some parameters that you may need to use:\n--with-fingerprint # print the fingerprint of the key --with-subkey-fingerprint # print the fingerprint of the subkey --with-sig-list # print the signature of keys Export the key # gpg -ao public-key.txt --export uid(or keyid) # export the public key # It is better to add your secure path before the secret-key, it will export to the machine directly. gpg -ao secret-key --export-secret-key primarykeyid! # export the primary secret key, remember to add the `!` to export the single key, or you will export the whole secret keys. gpg -ao sign-subkey --export-secret-subkeys subkeyid! # export the sign sub secret key.[S] gpg -ao encrypt-subkey --export-secret-subkeys encryptkeyid! # export the encrypt sub secret key.[E] Most usage # Besides, GPG private key exported as an ASCII armored version or its base64 encoding (often).\ngpg --export-secret-key --armor keyid \u0026gt; secret-key.asc Delete the key # After Export the keys, you can delete then from the machine.\ngpg --delete-secret-keys uid(or keyid) # delete the secret key gpg --delete-keys uid(or keyid) # delete the public key As we know, the keys is stored in the machine in plaintext, it will not delete the keys completely, you can use the wipe or other tools to assist. But there is still the risk of restoring the keys. If you really want to generate and delete the keys in the most secure way, you can try Tails(boum.org).\nImport the key # Strongly discourage any operation related to public key servers!\ngpg --import yourkeysfile(your secret key or others public key) # output # the `#` means the primary key is not imported, so it\u0026#39;s safe. # sec# rsa3072/keyid 2021-01-11 [SC] # ... # the `#` means the subkey is imported. # ssb # rsa3072/keyid 2021-01-11 [E] Sign and verify # # Sign # 1. generate the binary signature file gpg --sign input.txt # 2. generate the ASCII signature file gpg --clearsign input.txt # 3. generate the signature file and original file separately. gpg --armor --detach-sign input.txt # verify gpg --verify input.txt.asc input.txt Encrypt and decrypt # # encrypt # uid(or keyid) is the uid or keyid of the recipient which means you have to import the public key of the recipient in advance. gpg --encrypt --recipient uid(or keyid) input.txt --output output.txt # a simple version gpg -se -o encrypt.txt -r uid(or keyid) input.txt # decrypt gpg --decrypt encrypt.txt --output decrypt.txt Revoke # Even you have revoke the key, if there is still someone sent you message by the outdated public key, you can decrypt the message as well as the hacker can. This operation import the revocation certificate which will make the whole keys invalid. The revoked key is only invalid for new encryption and signing. But you can still decrypt and verify the existing information, but it will be marked as revoked.\nImagine the scenario, Alice\u0026rsquo;s secret key is leaked, she will send a key revocation certificate, but the distribution is not centralized, so she cannot make sure everyone has received the message. Besides, the key revocation certificate is need to be signed by the secret key of the Alice, so if the secret key is lost, she will not be able to revoke the key.\nSo once you have revoked the key, you should push the revoked public key to where you publish the key always, and notify your friends.\n# revoke the primary key # import the public key first gpg --import gpg-linus.asc # then import the revoke certificate which will make the public key invalid directly. gpg --import revoke # gpg -k to check the key is revoked. eg.[revoked: 2024-01-01] # revoke the subkey gpg --edit-key uid(or keyid) # then select the subkey you want to revoke gpg \u0026gt; list gpg \u0026gt; key 1 # 1 is the index of the subkey gpg \u0026gt; revoke gpg \u0026gt; save Config your git # Refer to Github docs and Github docs\nReference # Github docs GnuPG docs ulyc blog Ruanyifeng blog GaoWeiX blog "},{"id":33,"href":"/posts/housewarming-2024/","title":"Housewarming 2024","section":"Blog","content":"So after a long time, I decide to restart my blog program. In my daily development, I have a lot of thoughts and ideas, thus I will write some documents to record them. But I believe that sharing is the best way to learn. A specific example is cryptography, which means the closing source algorithm is never the safest. Only algorithms that have been vetted by the public are truly secure.\nRestart # The reason why I call it restart is that I have been using hexo for a long time, and I wrote the blogs via hexo from the time I entered the university. But there is a serious problem in hexo, which is the deploy speed is too slow. When I have a little blogs, it is not a big problem, but the number of blogs increases with time, the deploy time exceeds 2 minutes, which is unbearable for me and it is hard to check the blog before publishing. And that makes me don\u0026rsquo;t want to publish blogs again, and then I reduced the times of publishing blogs until stopped.\nAfter about 1 year, now I decide to restart it, I came across hugo by chance, and just as the documentation says:\nHugo is a static site generator written in Go, optimized for speed and designed for flexibility. With its advanced templating system and fast asset pipelines, Hugo renders a complete site in seconds, often less.\nSo I finally decide to migrated contents from hexo to hugo.\nMigration # The migration process is smooth. The content types are nearly uniform, so I just need to pay attention to the project structure. And reading the documentation, the hugo mainly contains these parts:\n. ├── archetypes # the template of creating new pages ├── assets # the static files ├── config.toml # the configuration of the blog ├── content # blogs ├── public # hugo build output ├── resources # some resources ├── static # the static files └── themes # the added themes will be here and the theme structure is similar to the main hugo The creation of the blog can be referred to the official documentation.\nThemes # The theme I choose is hugo-book, which is a theme for hugo. Simple and graceful.\nMathematics # For the mathematics, there are two ways in browser to render the formula, the Katex and MathJax. They are all open source javascript libraries. Since I knew the markdown syntax, I use the Typora which supports MathJax library. So I get used to its syntax which accounts for the reason why I choose it.\nDeployment # The deployment is done by github actions, and the workflow file is in the .github/workflows/hugo.yml. BTW, the most contents on the search engine are about the blog deployment in personal github pages, which is not suitable for me, cause the personal github pages is used to store personal homepage. Thus, I will use the private repository blogsource to store the source code and use the blog repository to host the blog.\nAbout the process, I found a toturial at random, you can refer to it. And for more infomation you can refer to the official documentation.\nThere are some key steps to note:\nMake sure the blog repository is public and the Settings -\u0026gt; Pages -\u0026gt; Build and deployment -\u0026gt; Source is set to Deploy from a branch, and the branch is main as well as /(root) is selected.\nGenerate a personal token in github and set it in the blogsource repository. This guarantees you have the permission to operate the target repository.\nSet a deploy.yml file in the .github/workflows directory of blog source code repository which is private. You can refer to this code name: deploy on: push: branches: - main workflow_dispatch: jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 ref: main - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.108.0\u0026#34; # your hugo version. extended: true - name: Build Web run: hugo --minify - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: # Make sure the name is same as what you set in the repo. PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} # Set the token in the `blog` repository. EXTERNAL_REPOSITORY: timerring/blogs # Set the target repository. PUBLISH_BRANCH: main PUBLISH_DIR: ./public # Set the publish directory. commit_message: ${{ github.event.head_commit.message }} Add the publishDir = \u0026quot;public\u0026quot; in the config.toml file and set your baseURL according to your target.\nAfter setting these, you can try to push it as normal. You will only need to push the source code to the blogsource repository, and then the blog will be deployed to the blog repository automatically through github actions.\nFonts # From the process of configurate the fonts, I have learned a lot about the fonts.\nStyle # The Style of fonts mainly contains these:\nserif: the fonts with serifs always have a small line at the end of the character. Often used in formal occasions. sans-serif: the fonts focus on simplicity and clarity. Hence it is often used in the web. monospace: the fonts with the same width for all characters. Which is often used in the code display. Weight # Different weights of fonts have different names:\n100 - Thin(Hairline) 200 - Extra Light (Ultra Light) 300 - Light 400 - Regular (Normal,Book,Roman) 500 - Medium 600 - Semi Bold (Demi Bold) 700 - Bold 800 - Extra Bold (Ultra Bold) 900 - Black (Heavy) The Regular and Bold are the most commonly used weights.\nType # The type of fonts mainly contains these:\nttf: TrueType is a font format developed by Apple and Microsoft focusing on the display in the printer in the beginning. otf: OpenType is a extension of TrueType. woff: Web Open Font Format which is a font format compressed to improve the loading speed in web. woff2: Web Open Font Format 2.0. The mostly differ in regard to the compression algorithm. For the fonts part, I have use the production of JetBrains for many years, so I choose the JetBrainsMono-Bold font for the code display.\nAnd for the content part, I use the Helvetica Neue font which is a popular sans-serif font and it is suitable for the web content.\nExtension # In conclusion, I use these extensions in the blog:\ngiscus: the comment system. mathjax: the mathematics system. Google Custom Search Engine: the search system. "},{"id":34,"href":"/about/","title":"About","section":"timerring","content":" About # John Howe GPG Public: 0x26FEE0805E6C9F71 Key fingerprint = B613 FBAF 0822 BEBD FABF 8F65 26FE E080 5E6C 9F71 If you want to know what this blog is about, here are some representative posts:\nNetwork Real Computer Network Coffee chat # blog topic and coffee chat buy me a coffee Where to find me # RSS: source Github: timerring Mainpage: timerring Email: me[at]timerring.com Footprints # Changelog # 2024-12-15 Transfer from hexo to hugo. "},{"id":35,"href":"/friends/","title":"Friends","section":"timerring","content":" Friends links # Sukka Selfboot zu1k Spencer Woo zhile.io 52txr Colah Bojie Li Bimu Timothy immmmm Harry Chen Qcrao Liam ishell dewx Eryajf Darmau gaoweix limbopro Changqian Yu ice1000 lsvih zhheo jiejoe shuyuej likun only.rs aigonna bulianglin "}]