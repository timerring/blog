<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This article is mainly about the Poisson processes in the book &ldquo;Random Processes&rdquo; by Gregory F. Lawler."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://blog.timerring.com/posts/possion-processes/"><meta property="og:site_name" content="timerring"><meta property="og:title" content="Possion Processes"><meta property="og:description" content="This article is mainly about the Poisson processes in the book “Random Processes” by Gregory F. Lawler."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-19T22:01:16+08:00"><meta property="article:tag" content="Random Process"><meta property="article:tag" content="Math"><meta itemprop=name content="Possion Processes"><meta itemprop=description content="This article is mainly about the Poisson processes in the book “Random Processes” by Gregory F. Lawler."><meta itemprop=datePublished content="2025-04-19T22:01:16+08:00"><meta itemprop=dateModified content="2025-04-19T22:01:16+08:00"><meta itemprop=wordCount content="3710"><meta itemprop=image content="https://blog.timerring.com/favicon.png"><meta itemprop=keywords content="Random Process,Math"><meta name=twitter:image content="https://blog.timerring.com/favicon.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Possion Processes"><meta name=twitter:description content="This article is mainly about the Poisson processes in the book “Random Processes” by Gregory F. Lawler."><meta name=twitter:site content="@imjohnhowe"><title>Possion Processes | timerring</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.b2496f568c7d479e460b580e0e81d4b97841f83539eba8c770dc9f8e1aa7682e.css integrity="sha256-sklvVox9R55GC1gODoHUuXhB+DU566jHcNyfjhqnaC4=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.6e13ec44129e93ab869727fbe1bffd2804f0bebc0af90130d36e9d549f9eaa7d.js integrity="sha256-bhPsRBKek6uGlyf74b/9KATwvrwK+QEw026dVJ+eqn0=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H5Y60NE14Z"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H5Y60NE14Z")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script defer>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/favicon.png alt=Logo><span>timerring</span></a></h2><hr><p>Rhythmic trend.</p><div class=book-search><div class=gcse-search></div></div><script async src="https://cse.google.com/cse.js?cx=40782701766144f96"></script><ul><li><a href=/>Dashboard</a></li><li><a href=/posts/>Blogs</a></li><li><a href=/categories/weekly/>Newsletter</a></li><li><a href=/index.xml>RSS</a></li><li><a href=/friends/>Friends</a></li><li><a href=/about/>About</a></li></ul><script>function goToRandomPost(){const e=["/posts/hidden-markov-models/?utm_source=random","/posts/markov-chains/?utm_source=random","/posts/markov-processes/?utm_source=random","/posts/stock-prices/?utm_source=random","/posts/possion-processes/?utm_source=random","/posts/random-walks/?utm_source=random","/posts/0418-find-the-formula-rendering-issue-of-hugo/?utm_source=random","/posts/stochastic-processes/?utm_source=random","/posts/multi-platform-builds-docker/?utm_source=random","/posts/0404-The-invitation-only-mechanism-from-clubhouse-to-manus/?utm_source=random","/posts/how-to-use-git-submodule/?utm_source=random","/posts/live-streaming-infra-and-protocols/?utm_source=random","/posts/implement-danmaku-rendering-algorithm-from-scratch/?utm_source=random","/posts/is-there-an-rss-renaissance-in-the-ai-era/?utm_source=random","/posts/docker-with-gpu/?utm_source=random","/posts/some-useful-tools/?utm_source=random","/posts/a-shopping-experience-in-pangdonglai-supermarket/?utm_source=random","/posts/langchain-and-rag-best-practices/?utm_source=random","/posts/sequences-of-random-variables/?utm_source=random","/posts/random-variables/?utm_source=random","/posts/repeated-trials/?utm_source=random","/posts/probability-and-its-axioms/?utm_source=random","/posts/further-understanding-of-proc/?utm_source=random","/posts/the-iftop/?utm_source=random","/posts/some-useful-commands-to-share/?utm_source=random","/posts/reflections-on-trending-topics/?utm_source=random","/posts/cpu-can-only-see-the-threads/?utm_source=random","/posts/go-common-test/?utm_source=random","/posts/go-concurrency-and-parallelism/?utm_source=random","/posts/go-cheatsheet/?utm_source=random","/posts/video-technology-101/?utm_source=random","/posts/the-main-kind-of-message-queue/?utm_source=random","/posts/the-method-to-manage-traffic/?utm_source=random","/posts/the-different-kind-of-api-design/?utm_source=random","/posts/the-encode-and-decode-in-python/?utm_source=random","/posts/about-the-systemd/?utm_source=random","/posts/the-tips-about-dockerfile/?utm_source=random","/posts/docker-cheatsheet/?utm_source=random","/posts/docker-101/?utm_source=random","/posts/the-instance-class-static-magic-method-in-python/?utm_source=random","/posts/the-review-and-plan-for-bilive/?utm_source=random","/posts/the-overview-of-security/?utm_source=random","/posts/how-to-publish-your-code-as-a-pip-module/?utm_source=random","/posts/some-good-things-to-share-about-the-packages/?utm_source=random","/posts/introduction-to-the-http-and-https-protocol/?utm_source=random","/posts/mail-service-and-protocol/?utm_source=random","/posts/understanding-clash-through-configuration/?utm_source=random","/posts/thinking-about-advertisement-from-an-open-source-perspective/?utm_source=random","/posts/a-brief-introduction-to-dns/?utm_source=random","/posts/real-computer-network/?utm_source=random","/posts/python-generator-iterator-and-decorator/?utm_source=random","/posts/python-underlying-mechanism/?utm_source=random","/posts/python-files-exceptions-and-modules/?utm_source=random","/posts/python-object-oriented-programming/?utm_source=random","/posts/python-cheatsheet/?utm_source=random","/posts/python-function-parameter/?utm_source=random","/posts/python-control-structure/?utm_source=random","/posts/python-composite-data-type/?utm_source=random","/posts/python-basic-data-type/?utm_source=random","/posts/python-basic-syntax-elements/?utm_source=random","/posts/deploy-github-pages-with-gpg-signing/?utm_source=random","/posts/gpg-101/?utm_source=random","/posts/housewarming-2024/?utm_source=random"],t=Math.floor(Math.random()*e.length);window.location.href=e[t]}</script><a class=random onclick=goToRandomPost()>Stroll</a></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>timerring</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#outline>Outline</a></li><li><a href=#review-of-some-basic-properties>Review of Some Basic Properties</a><ul><li><a href=#definition-of-poisson-process>Definition of Poisson Process</a></li><li><a href=#autocorrelation-function-r_xxt_1-t_2>Autocorrelation Function $R_{XX}(t_{1}, t_{2})$</a></li></ul></li><li><a href=#some-typical-poisson-processes>Some Typical Poisson Processes</a><ul><li><a href=#example-of-poisson-process-application>Example of Poisson Process Application</a></li><li><a href=#sum-and-difference-of-poisson-processes>Sum and Difference of Poisson Processes</a></li><li><a href=#example-of-sum-of-poisson-processes>Example of Sum of Poisson Processes</a></li></ul></li><li><a href=#random-selection-of-poisson-points>Random Selection of Poisson Points</a><ul><li><a href=#example-of-random-selection>Example of Random Selection</a></li><li><a href=#inter-arrival-distribution-for-poisson-processes>Inter-arrival Distribution for Poisson Processes</a></li><li><a href=#conclusion>Conclusion</a></li></ul></li><li><a href=#little-oh-notation>Little O(H) Notation</a></li><li><a href=#axiomatic-development-of-poisson-processes>Axiomatic Development of Poisson Processes</a><ul><li><a href=#first-arrival-time-interval>first arrival time interval</a></li></ul></li><li><a href=#counting-process>COUNTING PROCESS</a><ul><li><a href=#alternative-definition-of-poisson-process-independent-and-stationary-increments>ALTERNATIVE DEFINITION OF POISSON PROCESS INDEPENDENT AND STATIONARY INCREMENTS</a><ul><li><a href=#example>Example</a></li></ul></li></ul></li><li><a href=#the-bernoulli-process-a-discrete-time-poisson-process>THE BERNOULLI PROCESS: A DISCRETE-TIME &ldquo;POISSON PROCESS&rdquo;</a><ul><li><a href=#alternative-definition-2-of-poisson-process>ALTERNATIVE DEFINITION 2 OF POISSON PROCESS</a></li></ul></li><li><a href=#other-alternative-ways-to-define-poisson-processes>OTHER ALTERNATIVE WAYS TO DEFINE POISSON PROCESSES</a></li><li><a href=#some-comments-for-poisson-processes>SOME COMMENTS FOR POISSON PROCESSES</a><ul><li><a href=#important-properties-of-poisson-processes>IMPORTANT PROPERTIES OF POISSON PROCESSES！！！</a></li><li><a href=#conditional-distribution-of-the-arrival-times>CONDITIONAL DISTRIBUTION OF THE ARRIVAL TIMES</a></li><li><a href=#example-1>Example</a></li><li><a href=#poisson-departures-between-exponential-inter-arrivals>Poisson Departures between Exponential Inter-arrivals</a></li><li><a href=#compound-poisson-process>COMPOUND POISSON PROCESS</a><ul><li><a href=#bulk-arrivals>BULK ARRIVALS</a></li></ul></li><li><a href=#compound-poison-process>COMPOUND POISON PROCESS</a></li></ul></li></ul></nav><style>.book-toc .book-toc-content a{color:var(--body-font-color)}</style></aside></header><article class=markdown><h1>Possion Processes</h1><h5>April 19, 2025
·
18 min read
<span id=busuanzi_container_page_pv>· Page View: <span id=busuanzi_value_page_pv></span></span></h5><div><a href=/categories/tutorial/ style=color:#000>Tutorial</a></div><div><a href=/tags/random-process/ style=color:#000>Random Process</a> <span style=color:#000>| </span><a href=/tags/math/ style=color:#000>Math</a></div><blockquote class="book-hint info">If you have any questions, feel free to comment below.</blockquote><hr><p>This article is mainly about the Poisson processes in the book &ldquo;Random Processes&rdquo; by Gregory F. Lawler.</p><h2 id=outline>Outline
<a class=anchor href=#outline>#</a></h2><ul><li>Definition of Poisson Process</li><li>Axiomatic Development</li><li>Sum of Poisson Processes</li><li>Inter-arrival Distribution for Poisson Processes</li><li>Poisson Departures between Exponential Interarrivals</li><li>Independent and stationary increments</li><li>Bulk Arrivals and Compound Poisson Processes</li></ul><h2 id=review-of-some-basic-properties>Review of Some Basic Properties
<a class=anchor href=#review-of-some-basic-properties>#</a></h2><p>Poisson arrivals can be seen as the limiting behavior of Binomial random variables (refer to Poisson approximation of Binomial random variables).</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-19-22-12-51.png alt></p><p>The probability that $k$ arrivals occur in an interval of duration $\Delta$ is given by</p>$$P\left\{\begin{array}{l}" k \text{ arrivals occur in an }\\ \text{interval of duration } \Delta''\end{array}\right\}=e^{-\lambda} \frac{\lambda^{k}}{k!}, k = 0,1,2,\cdots
$$<p>, where $\lambda=np=\mu T\cdot\frac{\Delta}{T}=\mu\Delta$.</p><p>For an interval of duration $2\Delta$,</p>$$P\left\{\begin{array}{l}" k \text{ arrivals occur in an }\\ \text{interval of duration } 2\Delta''\end{array}\right\}=e^{-2\lambda} \frac{(2\lambda)^{k}}{k!}, k = 0,1,2,\cdots
$$<p>, and $np_{1}=\mu T\cdot\frac{2\Delta}{T}=2\mu\Delta = 2\lambda$.</p><p>Poisson arrivals over an interval form a Poisson random variable whose parameter depends on the duration of that interval. Also, due to the Bernoulli nature of the underlying basic random arrivals, events over non-overlapping intervals are independent.</p><p>Example 9-5.</p><h3 id=definition-of-poisson-process>Definition of Poisson Process
<a class=anchor href=#definition-of-poisson-process>#</a></h3><p>$X(t)=n(0, t)$ represents a Poisson process if:</p><ol><li>The number of arrivals $n(t_{1}, t_{2})$ in an interval $(t_{1}, t_{2})$ of length $t=t_{2}-t_{1}$ is a Poisson random variable with parameter $\lambda t$, i.e., $P{n(t_{1}, t_{2}) = k}=e^{-\lambda t} \frac{(\lambda t)^{k}}{k!}, k = 0,1,2,\cdots$.</li><li>If the intervals $(t_{1}, t_{2})$ and $(t_{3}, t_{4})$ are <strong>non-overlapping</strong>, then the random variables $n(t_{1}, t_{2})$ and $n(t_{3}, t_{4})$ are independent.</li></ol><p>Since $n(0, t)\sim P(\lambda t)$, we have:</p><ul><li>$E[X(t)] = E[n(0, t)]=\lambda t$</li><li>$E[X^{2}(t)] = E[n^{2}(0, t)]=\lambda t+\lambda^{2}t^{2}$<ul><li>Since $E[X(t)] = \lambda t$, $VAR[X(t)] = E[X(t)]$.</li></ul></li></ul><h3 id=autocorrelation-function-r_xxt_1-t_2>Autocorrelation Function $R_{XX}(t_{1}, t_{2})$
<a class=anchor href=#autocorrelation-function-r_xxt_1-t_2>#</a></h3><p>Let $t_{2}>t_{1}$. Then $n(0,t_{1})$ and $n(t_{1},t_{2})$ are independent Poisson random variables with parameters $\lambda t_{1}$ and $\lambda(t_{2}-t_{1})$ respectively.</p><p>So, $E\left[n\left(0, t_{1}\right) n\left(t_{1}, t_{2}\right)\right]=E\left[n\left(0, t_{1}\right)\right] E\left[n\left(t_{1}, t_{2}\right)\right]=\lambda^{2}t_{1}(t_{2}-t_{1})$.</p><p>Since $n(t_{1}, t_{2})=n(0, t_{2}) - n(0, t_{1})=X(t_{2}) - X(t_{1})$, we have</p>$$
E\left[X\left(t_{1}\right)\left\{X\left(t_{2}\right)-X\left(t_{1}\right)\right\}\right]=R_{xx}\left(t_{1}, t_{2}\right)-E\left[X^{2}\left(t_{1}\right)\right].
$$<p>Therefore,</p><ul><li>$R_{XX}\left(t_{1}, t_{2}\right)=\lambda^{2}t_{1}(t_{2}-t_{1})+E\left[X^{2}\left(t_{1}\right)\right]=\lambda t_{1}+\lambda^{2}t_{1}t_{2}, t_{2}\geq t_{1}$.</li><li>Similarly, $R_{XX}\left(t_{1}, t_{2}\right)=\lambda t_{2}+\lambda^{2}t_{1}t_{2}, t_{2}&lt;t_{1}$.</li></ul><p>In general, $R_{XX}\left(t_{1}, t_{2}\right)=\lambda^{2}t_{1}t_{2}+\lambda\min\left(t_{1}, t_{2}\right)$.</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-19-22-22-09.png alt></p><blockquote><p>Binary Level Process and Stationarity</p><p>Define a binary level process $Y(t)=(-1)^{X(t)}$ representing a telegraph signal. The transition instants ${t}$ are random.</p></blockquote><p>Although $X(t)$ is not a wide-sense stationary process, its derivative $X^{\prime}(t)$ is a wide-sense stationary process.</p>$$
\mu_{x^{\prime}}(t)=\frac{d\mu_{x}(t)}{dt}=\frac{d\lambda t}{dt}=\lambda (constant).
$$$$
R_{x x^{\prime}}\left(t_{1}, t_{2}\right)=\frac{\partial R_{x x}\left(t_{1}, t_{2}\right)}{\partial t_{2}}=\begin{cases}\lambda^{2}t_{1}&t_{1}\leq t_{2}\\\lambda^{2}t_{1}+\lambda&t_{1}>t_{2}\end{cases}=\lambda^{2}t_{1}+\lambda U\left(t_{1}-t_{2}\right)
$$$$
R_{x^{\prime} x^{\prime}}\left(t_{1}, t_{2}\right)=\frac{\partial R_{x x^{\prime}}\left(t_{1}, t_{2}\right)}{\partial t_{1}}=\lambda^{2}+\lambda\delta\left(t_{1}-t_{2}\right)
$$<p><strong>Thus nonstationary inputs to linear systems can lead to wide sense stationary outputs, an interesting observation.</strong></p><h2 id=some-typical-poisson-processes>Some Typical Poisson Processes
<a class=anchor href=#some-typical-poisson-processes>#</a></h2><ul><li>Arrivals to a queueing system.</li><li>Earthquakes in a geological system.</li><li>Accidents in a given city.</li><li>Claims on an insurance company.</li><li>Demands on an inventory system.</li><li>Failures in a manufacturing system (e.g., an average of 1 failure per week, $P(X = 0 \text{ failures}) = 0.36788$, $P(X = 1 \text{ failure}) = 0.36788$, $P(X = 2 \text{ failures}) = 0.18394$).</li></ul><p><strong>Modeling is more tractable if the successive inter-event (inter-arrival) times are independent and identically-distributed (iid) exponential random variables, which leads to a Poisson process.</strong></p><h3 id=example-of-poisson-process-application>Example of Poisson Process Application
<a class=anchor href=#example-of-poisson-process-application>#</a></h3><p>Let $N(t)$ be the number of births in a hospital over the interval $(0, t)$ and assume $N(t)$ is a Poisson process with rate 10 per day.</p><ol><li>For an 8-hour shift ($\frac{1}{3}$ day), $N(\frac{1}{3})\sim Poisson(\frac{10}{3})$. So, $E[N(\frac{1}{3})]=\frac{10}{3}$ and $Var[N(\frac{1}{3})]=\frac{10}{3}$.</li><li>For the probability that there are no births from noon to 1 p.m. (1 hour = $\frac{1}{24}$ day), $N(\frac{1}{24})\sim Poisson(\frac{10}{24})$. The probability $P[N(\frac{1}{24}) = 0]=e^{-\frac{10}{24}}\approx0.6592$.</li><li>For the probability that there are three births from 8 a.m. to 12 noon ($4$ hours = $\frac{4}{24}$ day) and four from 12 noon to 5 p.m. ($5$ hours = $\frac{5}{24}$ day), a</li></ol><p>Assuming 8 a.m. is $t = 0$, the probability will be:</p><p>$P(N(\frac{12}{24})-N(\frac{8}{24})=3;N(\frac{17}{24})-N(\frac{12}{24}) = 4)=P(N(\frac{12}{24})-N(\frac{8}{24})=3)P(N(\frac{17}{24})-N(\frac{12}{24}) = 4)$ (by independence of increments)
$=P(N(\frac{4}{24}) = 3)P(N(\frac{5}{24}) = 4)$ (by stationarity of increments)
$=e^{-\frac{10}{6}}\frac{(\frac{10}{6})^{3}}{3!}e^{-\frac{10}{6}}\frac{(\frac{10}{6})^{4}}{4!}\approx0.0088$</p><h3 id=sum-and-difference-of-poisson-processes>Sum and Difference of Poisson Processes
<a class=anchor href=#sum-and-difference-of-poisson-processes>#</a></h3><p>If $X_{1}(t)$ and $X_{2}(t)$ are two independent Poisson processes:</p><ul><li><strong>Superposition/Sum</strong>: $X_{1}(t)+X_{2}(t)$ is also a Poisson process with parameter $(\lambda_{1}+\lambda_{2})t$.</li><li>No Difference: $Y(t)=X_{1}(t)-X_{2}(t)$ is not a Poisson process since $E{y(t)}=(\lambda_{1}-\lambda_{2})t$ and $Var{y(t)}=(\lambda_{1}+\lambda_{2})t$.</li></ul><h3 id=example-of-sum-of-poisson-processes>Example of Sum of Poisson Processes
<a class=anchor href=#example-of-sum-of-poisson-processes>#</a></h3><p>Let $B(t)$ be the number of boys born in a hospital over $(0, t)$ with rate 10 per day and $G(t)$ be the number of girls born with rate 9 per day. They are independent Poisson processes.</p><p>Let $N(t)=B(t)+G(t)$. Then $N(t)$ is a Poisson process with rate $10 + 9 = 19$ per day.</p><p>Then mean and variance of $N(t)$ are $19t$ respectively, when t is a week, the value is $19\times7=133$.</p><h2 id=random-selection-of-poisson-points>Random Selection of Poisson Points
<a class=anchor href=#random-selection-of-poisson-points>#</a></h2><blockquote><p>Remember the random process definition? (t and $\xi$)</p></blockquote><p>Let $t_{1}, t_{2},\cdots,t_{i},\cdots$ be random arrival points of a Poisson process $X(t)$ with parameter $\lambda t$. Define an independent Bernoulli random variable $N_{i}$ for each arrival point, where $P(N_{i}=1)=p$ and $P(N_{i}=0)=q = 1 - p$.</p><p>Define:</p><ul><li>$Y(t)=\sum_{i = 1}^{X(t)}N_{i}$, Each arrival of $X(t)$ gets tagged independently with probability $p$.</li><li>$Z(t)=\sum_{i = 1}^{X(t)}(1 - N_{i})=X(t)-Y(t)$, Each arrival of $X(t)$ gets untagged independently with probability $q = 1 - p$.</li></ul><p>Both $Y(t)$ and $Z(t)$ are independent Poisson processes with parameters $\lambda p t$ and $\lambda q t$ respectively.</p><blockquote><p>Proof:</p><ul><li>Let $A_{n}={n \text{ events occur in }(0, t)\text{ and }k \text{ of them are tagged}}$.</li></ul><p>$P(A_{n})=P{k \text{ events are tagged}|x(t)=n}P{x(t)=n}=\binom{n}{k}p^{k}q^{n - k}e^{-\lambda t}\frac{(\lambda t)^{n}}{n!}$</p><p>So the probability that $Y(t)=k$ is the sum of the probabilities that $n$ events occur in $(0, t)$ and $k$ of them are tagged for all $n\geq k$, ${Y(t)=k}=\bigcup_{n = k}^{\infty}A_{n}$.</p><p>$P{Y(t)=k}=\sum_{n = k}^{\infty}P{Y(t)=k|X(t)=n}P{X(t)=n}$</p><p>Since $P{Y(t)=k|X(t)=n}=\binom{n}{k}p^{k}q^{n - k}$ and $P{X(t)=n}=e^{-\lambda t}\frac{(\lambda t)^{n}}{n!}$, we have $P{Y(t)=k}=e^{-\lambda p t}\frac{(\lambda p t)^{k}}{k!}\sim P(\lambda p t)$.</p></blockquote><blockquote><p>In the end: $P{Y(t)=k,Z(t)=m}=P{Y(t)=k,X(t)-Y(t)=m}=P{Y(t)=k,X(t)=k + m}=P{Y(t)=k|X(t)=k + m}P{X(t)=k + m}=\binom{k + m}{k}p^{k}q^{m}e^{-\lambda t}\frac{(\lambda t)^{k + m}}{(k + m)!}=P{Y(t)=k}P{Z(t)=m}$</p></blockquote><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-19-23-03-10.png alt></p><p>Thus <strong>random selection</strong> (not deterministic) of Poisson points <strong>preserve</strong> the Poisson nature of the resulting processes!</p><h3 id=example-of-random-selection>Example of Random Selection
<a class=anchor href=#example-of-random-selection>#</a></h3><p>Let $N(t)$ be the number of births in a hospital with rate 16 per day, 48% of births are boys and 52% are girls.</p><p>Let $B(t)$ and $G(t)$ be the number of boys and girls born respectively. Then $B(t)\sim Poisson(16\times0.48)$ and $G(t)\sim Poisson(16\times0.52)$.</p><p>The probability that we see six boys and eight girls born on a given day is $P(B(1)=6,G(1)=8)=e^{-7.68}\frac{7.68^{6}}{6!}e^{-8.32}\frac{8.32^{8}}{8!}\approx0.0183$</p><h3 id=inter-arrival-distribution-for-poisson-processes>Inter-arrival Distribution for Poisson Processes
<a class=anchor href=#inter-arrival-distribution-for-poisson-processes>#</a></h3><p>Let $\tau_{1}$ be the time interval to the first arrival from a fixed point $t_{0}$.</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-19-23-07-50.png alt></p><p>To determine the probability distribution of the random variable $\tau_{1}$:</p><p>The event ${\tau_{1}\leq t}$ is the same as ${n(t_{0}, t_{0}+t)>0}$, or ${\tau_{1} > t}$ is the same as ${n(t_{0}, t_{0}+t)=0}$.</p><p>So $F_{\tau_{1}}(t)=P{\tau_{1}\leq t}=P{X(t)>0}=1 - P{n(t_{0}, t_{0}+t)=0}=1 - e^{-\lambda t}$.</p><p>The probability density function $f_{\tau_{1}}(t)=\frac{dF_{\tau_{1}}(t)}{dt}=\lambda e^{-\lambda t},t\geq0$.</p><p><strong>So $\tau_{1}$ is an exponential random variable with parameter $\lambda$ and $E(\tau_{1})=\frac{1}{\lambda}$.</strong></p><p><strong>All inter-arrival durations $\tau_{1},\tau_{2},\cdots,\tau_{n},\cdots$ of a Poisson process are independent exponential random variables with common parameter $\lambda$, i.e., $f_{\tau_{i}}(t)=\lambda e^{-\lambda t},t\geq0$.</strong></p><p>Let $t_{n}$ be the $n^{th}$ random arrival point.</p><ul><li><p>Then $F_{t_{n}}(t)=P{t_{n}\leq t}=P{X(t)\geq n}=1 - P{X(t)&lt;n}=1-\sum_{k = 0}^{n - 1}\frac{(\lambda t)^{k}}{k!}e^{-\lambda t}$.</p></li><li><p>The probability density function $f_{t_{n}}(x)=\frac{dF_{t_{n}}(x)}{dx}=\frac{\lambda^{n}x^{n - 1}}{(n - 1)!}e^{-\lambda x},x\geq0$, which is a gamma density function.</p></li></ul><p>The waiting time to the $n^{th}$ Poisson arrival instant has a gamma distribution, and $t_n=\sum_{i = 1}^{n}\tau_i$, $\tau_i$ means the inter-arrival time between the $(i-1)^{th}$ and $i^{th}$ Poisson arrival instant.</p><p>If we systematically tag every $m^{th}$ outcome of a Poisson process $X(t)$ to generate a new process $e(t)$, the inter - arrival time between any two events of $e(t)$ is a gamma random variable. If $\lambda=m\mu$, then $E[e(t)]=\frac{1}{\mu}$, and the inter-arrival time represents an Erlang-$m$ random variable, and $e(t)$ is an Erlang-$m$ process.</p><h3 id=conclusion>Conclusion
<a class=anchor href=#conclusion>#</a></h3><p>In summary, <strong>if Poisson arrivals are randomly redirected to form new queues, then each such queue generates a new Poisson process.</strong></p><p>However if the arrivals are systematically redirected (1st arrival to 1st counter, 2nd arrival to 2nd counter, $m^{th}$ arrival to $m^{th}$ counter, $(m +1)^{st}$ arrival to 1st counter), then the new subqueues form Erlang-$m$ processes.</p><h2 id=little-oh-notation>Little O(H) Notation
<a class=anchor href=#little-oh-notation>#</a></h2><p>Let $o(h)$ denote any function of $h$ such that $\frac{o(h)}{h}\to0$ as $h\to0$, which can be ignored.</p><p>Examples:</p><ol><li>$h^{k}$ is $o(h)$ for any $k > 1$ since $\frac{h^{k}}{h}=h^{k - 1}\to0$ when $h\to0$.</li><li>The finite series $\sum_{k = 2}^{\infty}c_{k}h^{k}$ with $|c_{k}|&lt;1$ is $o(h)$ because $\lim_{h\to0}\frac{\sum_{k = 2}^{\infty}c_{k}h^{k}}{h}=\lim_{h\to0}\sum_{k = 2}^{\infty}c_{k}h^{k - 1}=0$. where taking the limit inside the summation is justified because the sum is bounded by 1 /（1 - h） for h &lt;1.</li></ol><ul><li>$o(h)+o(h)=o(h)$</li><li>$o(h)o(h)=o(h)$</li><li>$co(h)=o(h)$ for any constant $c$.</li><li>even for any linear combination.</li></ul><h2 id=axiomatic-development-of-poisson-processes>Axiomatic Development of Poisson Processes
<a class=anchor href=#axiomatic-development-of-poisson-processes>#</a></h2><p>Some conditions:</p><p>The defining properties of a Poisson process are that in any &ldquo;small&rdquo; interval one event can occur with probability that is proportional to $\Delta t$.</p><p>Further, the probability that two or more events occur in that interval is proportional to $o(\Delta t)$, higher powers of $\Delta t$, and events over non-overlapping intervals are independent of each other.</p><p>This gives rise to the following Axioms:</p><ol><li>$P{n(t, t+\Delta t)=1}=\lambda \Delta t+o(\Delta t)$: means only one event occurs in the interval.</li><li>$P{n(t, t+\Delta t)=0}=1-\lambda \Delta t+o(\Delta t)$ : means no event occurs in the interval.</li><li>$P{n(t, t+\Delta t) \geq 2}=o(\Delta t)$ : means two or more events occur in the interval.</li><li>$n(t, t+\Delta t)$ is independent of $n(0, t)$ : means the events are independent of each other.</li></ol><p>Notice that axiom3 specifies that the events occur singly, and axiom4 specifies the randomness of the entire series. Axiom2 follows from 1 and 3 together with the axiom of total probability.</p><h3 id=first-arrival-time-interval>first arrival time interval
<a class=anchor href=#first-arrival-time-interval>#</a></h3><p>Let $t_0$ be any fixed point and let $\tau_1$ represent the time of the first arrival after $t_0$.
Notice that the random variable $\tau_1$ (Axiom4), is <strong>independent</strong> of the occurrences prior to the instant $t_0$. With $F_{\tau_{1}}(t)=P{\tau_{1} \leq t}$ representing the distribution function of $\tau_1$.</p><p>Now define $Q(t)=1 - F_{\tau_{1}}(t)=P{\tau_{1}>t}$. Then for $\Delta t>0$</p><blockquote>$$
\begin{aligned} Q(t+\Delta t) &=P\left\{\tau_{1}>t+\Delta t\right\}\\
&=P\left\{\tau_{1}>t, \text{ and no event occurs in } \left(t_{0}+t, t_{0}+t+\Delta t\right)\right\}\\
&=P\left\{\tau_{1}>t, n\left(t_{0}+t, t_{0}+t+\Delta t\right)=0\right\}\\
&=P\left\{n\left(t_{0}+t, t_{0}+t+\Delta t\right)=0 | \tau_{1}>t\right\} P\left\{\tau_{1}>t\right\}.
\end{aligned}
$$<p>From axiom 2, the conditional probability in the above expression is not affected by the event $\tau_{1}>t$ which refers to $n(t_{0}, t_{0}+t)=0$, i.e., to events before $t_0 + t$, and hence the unconditional probability in axiom 2 can be used there.</p><p>Thus</p>$$
Q(t+\Delta t)=[1-\lambda \Delta t+o(\Delta t)] Q(t)
$$<p>or $\lim _{\Delta t \to 0} \frac{Q(t+\Delta t)-Q(t)}{\Delta t}=Q&rsquo;(t)=-\lambda Q(t) \Rightarrow Q(t)=c e^{-\lambda t}$</p><p>but c=Q(0)=$P{\tau_{1}>0}=1$, so that $Q(t)=1 - F_{\tau_{1}}(t)=e^{-\lambda t}$</p></blockquote><p>So $F_{\tau_{1}}(t)=1 - e^{-\lambda t}, t \geq 0$, which gives $f_{\tau_{1}}(t)=\frac{d F_{\tau_{1}}(t)}{d t}=\lambda e^{-\lambda t}$, $t \geq 0$ to be the p.d.f of $\tau_1$.</p><p>In addition, $p_{k}(t)=P{n(0, t)=k}$, $k = 0,1,2,\cdots$ represent the probability that the total number of arrivals in the interval $(0, t)$ equals $k$.</p><p>Then</p>$$
p_{k}(t+\Delta t)=P\{n(0, t+\Delta t)=k\}=P\{X_1\cup X_2\cup X_3\}
$$<p>where the events</p>$$
X_1 = n(0, t)=k, \text{ and } n(t, t+\Delta t)=0
$$$$
X_2 = n(0, t)=k - 1, \text{ and } n(t, t+\Delta t)=1
$$$$
X_3 = n(0, t)=k - i, \text{ and } n(t, t+\Delta t)=i \geq 2
$$<p>are mutually exclusive.</p><p>Thus</p>$$
p_{k}(t+\Delta t)=P\left(X_{1}\right)+P\left(X_{2}\right)+P\left(X_{3}\right)
$$$$
\begin{aligned} P\left(X_{1}\right) &=P\{n(t, t+\Delta t)=0 | n(0, t)=k\} P\{n(0, t)=k\}\\
&=P\{n(t, t+\Delta t)=0\} P\{n(0, t)=k\}\\
&=(1-\lambda \Delta t) p_{k}(t)
\end{aligned}
$$$$
\begin{aligned} P\left(X_{2}\right) &=P\{n(t, t+\Delta t)=1 | n(0, t)=k - 1\} P\{n(0, t)=k - 1\}\\
&=\lambda \Delta t p_{k - 1}(t)
\end{aligned}
$$$$
P\left(X_{3}\right)=0
$$<p>where once again we have made use of axioms1-4.</p><p>This gives:</p>$$
p_{k}(t+\Delta t)=(1-\lambda \Delta t) p_{k}(t)+\lambda \Delta t p_{k - 1}(t)
$$$$
or \text{ with } \lim _{\Delta t \to 0} \frac{p_{k}(t+\Delta t)-p_{k}(t)}{\Delta t}=p_{k}'(t)
$$<p>we get the differential equation $p_{k}&rsquo;(t)=-\lambda p_{k}(t)+\lambda p_{k - 1}(t)$, $k = 0,1,2,\cdots$ whose solution gives:</p>$$p_{k}(t)=e^{-\lambda t} \frac{(\lambda t)^{k}}{k !}, k = 0,1,2,\cdots \text{ with } p_{-1}(t) \equiv 0
$$<h2 id=counting-process>COUNTING PROCESS
<a class=anchor href=#counting-process>#</a></h2><p>A stochastic process ${N(t):t\geq 0}$ is a counting process if $N(t)$ represents the total number of &ldquo;events&rdquo; that occur by time $t$.
eg, # of persons entering a store before time $t$, # of people who were born by time $t$, # of goals a soccer player scores by time $t$.</p><p>$N(t)$ should satisfy:</p><ul><li>$N(t)\geq0$</li><li>$N(t)$ is integer valued</li><li>If $s\leq t$, then $N(s)\leq N(t)$, the counting is non-decreasing</li><li>For $s &lt; t$, $N(t)-N(s)$ equals the number of events that occur in $(s,t]$</li></ul><h3 id=alternative-definition-of-poisson-process-independent-and-stationary-increments>ALTERNATIVE DEFINITION OF POISSON PROCESS INDEPENDENT AND STATIONARY INCREMENTS
<a class=anchor href=#alternative-definition-of-poisson-process-independent-and-stationary-increments>#</a></h3><p>A continuous-time stochastic process ${N(t):t\geq0}$ is a Poisson process with rate $\lambda>0$</p><p>if:</p><ol><li>$N(0)=0$.</li><li>It has stationary and independent increments.(stationary means the distribution of increments are only related to the length of the interval, independent means the increments are independent of each other)</li><li>The distribution of its increments is given by mean = $\lambda k$, $P(N(t)=k)=\frac{(\lambda t)^{k}}{k!}e^{-\lambda t}$ for $k = 0,1,2,\cdots$.</li></ol><p>By stationary increments, the distribution of $N(t)-N(s)$, for $s &lt; t$ is the same as the distribution of $N(t - s)-N(0)=N(t - s)$, which is a Poisson distribution with mean $\lambda(t - s)$, so for any non-overlapping intervals of time $I_1$ and $I_2$, $N(I_1)$ and $N(I_2)$ are independent.</p><ul><li>$N(t)\to\infty$ as $t\to\infty$, so that $N(t)$ itself is by no means stationary.</li><li>The process is non-decreasing, for $N(t)-N(s)>0$ with probability for any $s &lt; t$ since $N(t)-N(s)$ has a Poisson distribution.</li><li>The state space of the process is clearly $S={0,1,2,\cdots}$.</li><li>$E[N(t)]=\lambda t$.</li></ul><p>The Poisson process is a counting process, as $N(t)$ could represent the number of events that have occurred up to time $t$, such as the number of arrivals of tasks/jobs/customers to a system by time $t$.</p><h4 id=example>Example
<a class=anchor href=#example>#</a></h4><p>Data packets transmitted by a modem over a phone line form a Poisson process of rate 10 packet/sec. Using $M_j$ to denote the number of packets transmitted in the $j$ - th hour, find the joint pmf of $M_1$ and $M_2$.</p><p>The first and second hours are non - overlapping intervals. Since one hour equals 3600 seconds and the Poisson process has a rate of 10 packet/sec, the expected number of packets in each hour is $E[M_j]=\lambda t = 10\times3600=36000$.</p><p>This implies $M_1$ and $M_2$ are independent Poisson random variables each with pmf</p>$$
p_m(m)=\begin{cases}\alpha^m e^{-\alpha}/m!&m = 0,1,2,\cdots\\0&otherwise\end{cases}
$$<p>where $\alpha = 36000$.</p><p>Since $M_1$ and $M_2$ are independent, the joint pmf is</p>$$
p_{M_1,M_2}(m_1,m_2)=p_{M_1}(m_1)p_{M_2}(m_2)=\begin{cases}\frac{\alpha^{m_1 + m_2}e^{-2\alpha}}{m_1!m_2!}&m_1 = 0,1,2,\cdots;m_2 = 0,1,2,\cdots\\0&otherwise\end{cases}
$$<h2 id=the-bernoulli-process-a-discrete-time-poisson-process>THE BERNOULLI PROCESS: A DISCRETE-TIME &ldquo;POISSON PROCESS&rdquo;
<a class=anchor href=#the-bernoulli-process-a-discrete-time-poisson-process>#</a></h2><p>Divide up the positive half-line $[0,\infty)$ into disjoint intervals, each of length $h$, where $h$ is small. Thus we have the intervals $[0,h),[h,2h),[2h,3h),\cdots$ and so on.</p><p>Suppose further that each interval corresponds to an independent Bernoulli trial, such that in each interval, independently of every other interval, there is a successful event (such as an arrival) with probability $\lambda h$.</p><p>The Bernoulli process is defined as ${B(t):t = 0,h,2h,3h,\cdots}$, <strong>where $B(t)$ is the number of successful trials up to time $t$.</strong></p><p>For a given $t$ of the form $nh$, we know the exact distribution of $B(t)$. <strong>Up to time $t$ there are $n$ independent trials, each with probability $\lambda h$ of success</strong>, so $B(t)$ has a Binomial distribution with parameters $n$ and $\lambda h$.</p><p>Therefore, the mean number of successes up to time $t$ is $n\lambda h=\lambda t$.</p>$$
P(B(t)=k)=\binom{n}{k}(\lambda h)^{k}(1 - \lambda h)^{n - k}\approx(\lambda t)^{k}/k!e^{-\lambda t}
$$<p>Distribution of $B(t)$ is approximately Poisson($\lambda t$) follows from the Poisson approximation to the Binomial distribution.</p><h3 id=alternative-definition-2-of-poisson-process>ALTERNATIVE DEFINITION 2 OF POISSON PROCESS
<a class=anchor href=#alternative-definition-2-of-poisson-process>#</a></h3><p>A continuous-time stochastic process ${N(t):t\geq 0}$ is a Poisson process with rate $\lambda>0$ if:</p><ol><li>$N(0)=0$.</li><li>It has stationary and independent increments.</li><li>$E(N(h)=1)=\lambda h$, $P(N(t)\geq 2)=o(t)$, and $P(N(t)=0)=1-\lambda(t)$.</li></ol><p><strong>First Definition IMPLIES the Alternate definition!</strong></p><blockquote><p>Proof:
$P(N(h)=0)=e^{-\lambda h}$, but expanding in Taylor series,</p>$$P(N(h)=0)=1-\lambda h+\frac{(\lambda h)^{2}}{2!}-\frac{(\lambda h)^{3}}{3!}+\cdots=1-\lambda h+o(h)$$$$P(N(h)=1)=\lambda h e^{-\lambda h}=\lambda h\left[1-\lambda h+\frac{(\lambda h)^{2}}{2!}-\frac{(\lambda h)^{3}}{3!}+\cdots\right]=\lambda h-\lambda^{2}h^{2}+\frac{(\lambda h)^{3}}{2!}-\frac{(\lambda h)^{4}}{3!}+\cdots=\lambda h+o(h)$$$$P(N(h)\geq 2)=1 - P(N(h)=1)-P(N(h)=0)=1-(\lambda h+o(h))-(1-\lambda h+o(h))=-o(h)-o(h)=o(h)$$</blockquote><h2 id=other-alternative-ways-to-define-poisson-processes>OTHER ALTERNATIVE WAYS TO DEFINE POISSON PROCESSES
<a class=anchor href=#other-alternative-ways-to-define-poisson-processes>#</a></h2><p>Define the distribution of the time between events: if the times between events are independent and identically distributed Exponential($\lambda$) random variables.</p><p><strong>Definition 3 of a Poisson Process</strong>: A continuous-time stochastic process ${N(t):t>0}$ is a Poisson process with rate $\lambda>0$ if:</p><ol><li>$N(0)=0$.</li><li>$N(t)$ counts the number of events that have occurred up to time $t$ (i.e. it is a counting process).</li><li>The times between events are independent and identically distributed with an Exponential($\lambda$) distribution.</li></ol><p>Exponential inter-arrival times implies stationary and independent increments by using the memoryless property.</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-20-14-23-08.png alt></p><p>Formally:</p><p>Define $T_{i}=t_{i}-t_{i - 1}$, the inter-arrival time.</p><p>Can define $X(t)=n(0,t)=\max{n\geq0:t_n &lt; t},t > 0$.</p><p>The stochastic process $X(t)=n(0,t)$ is a Poisson process with rate $\lambda$ if ${t_i,i\geq1}$ is a sequence of iid exp($\lambda$) rvs.</p><ul><li>$\lambda$ - the rate of the Poisson process</li></ul><h2 id=some-comments-for-poisson-processes>SOME COMMENTS FOR POISSON PROCESSES
<a class=anchor href=#some-comments-for-poisson-processes>#</a></h2><p>Poisson process is one of the most important models used in <strong>queueing theory</strong>, as it is a viable model when the calls or packets originate from a large population of independent users.</p><p>There are two assumptions which lead to the Poisson process:</p><ol><li><strong>Events are independent.</strong></li><li><strong>Events occur one at a time.</strong></li></ol><p>The Poisson process properties: The &ldquo;most random&rdquo; process with a given arrival intensity.</p><ul><li>Independence/independent increments.</li><li>Memory-less properties.</li><li>Inter-event times are independently and identically distributed as exponential prob. distr.</li></ul><p>If we assume that the number of packets incoming to a network has a Poisson distribution, then this implies that the time between two consecutive packet arrivals are both independent and have an exponential probability distribution.</p><p><strong>The rate $\lambda$ of a Poisson process is the average number of events per unit time (over a long time).</strong></p><h3 id=important-properties-of-poisson-processes>IMPORTANT PROPERTIES OF POISSON PROCESSES！！！
<a class=anchor href=#important-properties-of-poisson-processes>#</a></h3><ul><li>The <strong>inter-arrival times</strong> are iid Exponential($\lambda$) random variables, where $\lambda$ is the rate of the Poisson process.</li><li>The sum of $n$ independent Exponential($\lambda$) random variables has a Gamma($n,\lambda$) distribution: Distribution of <strong>the Time to the $n^{th}$ Arrival</strong>.</li><li>The sum (superposition) of two independent Poisson processes (called the superposition of the processes) is again a Poisson process but with rate $\lambda_1+\lambda_2$, where $\lambda_1$ and $\lambda_2$ are the rates of the constituent Poisson processes.<ul><li><strong>If we take $N$ independent counting processes and sum them up, then the resulting superposition process is approximately a Poisson process, while $N$ must be large enough!→justification for using a Poisson process model.</strong></li></ul></li><li>If each event in <strong>a Poisson process is marked with probability $p$</strong>, independently from event to event, then the marked process ${N_m(t),t\geq0}$, where $N_m(t)$ is the number of marked events up to time $t$, is a Poisson process with rate <strong>$\lambda p$</strong>, where $\lambda$ is the rate of the original Poisson process. This is called thinning a Poisson process.</li></ul><h3 id=conditional-distribution-of-the-arrival-times>CONDITIONAL DISTRIBUTION OF THE ARRIVAL TIMES
<a class=anchor href=#conditional-distribution-of-the-arrival-times>#</a></h3><p>Recall Order Statistics: Let $S_1,S_2,\cdots,S_n$ be $n$ i.i.d. continuous random variables having common pdf $f$. Define $S_{(k)}$ as the $k$-th smallest value among all $S_i$’s, i.e., $S_{(1)}\leq S_{(2)}\leq\cdots\leq S_{(n)}$, then $S_{(1)},S_{(2)},\cdots,S_{(n)}$ are the “order statistics” corresponding to random variables $S_1,S_2,\cdots,S_n$.</p><p>The joint pdf of $S_{(1)},S_{(2)},\cdots,S_{(n)}$ is</p>$$
f_{S_{(1)},S_{(2)},\cdots,S_{(n)}}(s_1,s_2,\cdots,s_n)=n!\times f(s_1)f(s_2)\cdots f(s_n), \text{ where } S_{(1)}\leq S_{(2)}\leq\cdots\leq S_{(n)}.
$$<p>Given that $N(t)=n$ means that there are $n$ arrivals in the interval $(0,t)$, the $n$ arrival times $S_1,S_2,\cdots,S_n$ have the same distribution as the order statistics corresponding to $n$ i.i.d. uniformly distributed random variables from $(0,t)$.</p><p>Let $0 &lt; t_1&lt;t_2&lt;\cdots&lt;t_{n + 2}=t$ and let $h_i$ be small enough such that $t_i+h_i &lt; t_{i + 1}$, $i = 1,\cdots,n$.</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-20-14-40-00.png alt></p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-20-14-47-06.png alt></p>$$
\therefore\frac{P\{t_i < \tilde{S}_i < t_i+h_i,i = 1,\cdots,n|\tilde{n}(t)=n\}}{h_1h_2\cdots h_n}=\frac{n!}{t^{n}}
$$<p>For $0 &lt; s_1&lt;s_2&lt;\cdots&lt;s_n\leq t$, the event $S_1 = s_1,S_2 = s_2,\cdots,S_n = s_n$ is equiva lent to the event that the first $n + 1$ inter - arrival times satisfy $T_1 = s_1,T_2 = s_2 - s_1,\cdots,T_n=s_n - s_{n - 1},T_{n+1}>t - s_n$.</p><h3 id=example-1>Example
<a class=anchor href=#example-1>#</a></h3><p>Suppose that people immigrate into a territory at a Poisson rate $\lambda = 1$ per day.</p><ol><li>What is the expected time until the tenth immigrant arrives?</li><li>What is the probability that the elapsed time between the tenth and the eleventh arrival exceeds two days?
$$
(a)E[S_{10}]=\frac{10}{\lambda}=10\text{ days.}
$$
$$
(b)P(t_{n}>2)=e^{-2\lambda}=e^{-2}\approx0.133.
$$</li></ol><h3 id=poisson-departures-between-exponential-inter-arrivals>Poisson Departures between Exponential Inter-arrivals
<a class=anchor href=#poisson-departures-between-exponential-inter-arrivals>#</a></h3><p>Let $X(t)\sim P(\lambda t)$ and $Y(t)\sim P(\mu t)$ represent two independent Poisson processes called arrival and departure processes.</p><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-20-14-53-02.png alt></p><p><strong>Let $Z$ represent the random interval between any two successive arrivals of $X(t)$. As discussed before, $Z$ has an exponential distribution with parameter $\lambda$.</strong></p><p>Let $N$ represent <strong>the number of &ldquo;departures&rdquo;</strong> of $Y(t)$ between any two successive arrivals of $X(t)$.</p><p>Then from the Poisson nature of the departures we have $P{N = k|Z = t}=e^{-\mu t}\frac{(\mu t)^{k}}{k!}$.</p><p>Thus:</p>$$
\begin{align*}P\{N = k\}&=\int_{0}^{\infty}P\{N = k|Z = t\}f_Z(t)dt\\&=\int_{0}^{\infty}e^{-\mu t}\frac{(\mu t)^{k}}{k!}\lambda e^{-\lambda t}dt\\&=\frac{\lambda}{k!}\int_{0}^{\infty}(\mu t)^{k}e^{-(\lambda+\mu)t}dt\\&=\frac{\lambda}{\lambda+\mu}(\frac{\mu}{\lambda+\mu})^{k}\frac{1}{k!}\int_{0}^{\infty}x^{k}e^{-x}dx\\&=(\frac{\lambda}{\lambda+\mu})(\frac{\mu}{\lambda+\mu})^{k},k = 0,1,2,\cdots\end{align*}
$$<p>i.e., the random variable $N$ has a <strong>geometric distribution</strong>.</p><p>If arrivals and departures occur at a counter according to two independent Poisson processes, then <strong>the number of arrivals between any two departures has a geometric distribution</strong>. Similarly the number of departures between any two arrivals also represents another geometric distribution.</p><h3 id=compound-poisson-process>COMPOUND POISSON PROCESS
<a class=anchor href=#compound-poisson-process>#</a></h3><p>A stochastic process ${X(t),t\geq0}$ is said to be a compound Poisson process if it can be represented as $X(t)=\sum_{i = 1}^{N(t)}Y_i$.</p><p>Here ${N(t),t\geq0}$ is a Poisson process, and ${Y_i,i\geq0}$ is a family of independent and identically distributed random variables that is also independent of $N(t)$.</p><p>Some examples:</p><ol><li>If $Y_i\equiv1$, then $X(t)=N(t)$, and so we have the usual Poisson process.</li><li>Suppose that buses arrive at a sporting event in accordance with a Poisson process and suppose that the numbers of fans in each bus are assumed to be independent and identically distributed. Then ${X(t),t\geq0}$ is a compound Poisson process where $X(t)$ denotes the number of fans who have arrived by $t$, $Y_i$ represents the number of fans in the $i$ - th bus.</li><li>Suppose customers leave a supermarket in accordance with a Poisson process. If the $Y_i$, the amount spent by the $i$ - th customer, $i = 1,2,\cdots$, are iid, then ${X(t),t\geq0}$ is a compound Poisson process when $X(t)$ denotes the total amount of money spent by time $t$!</li></ol><h4 id=bulk-arrivals>BULK ARRIVALS
<a class=anchor href=#bulk-arrivals>#</a></h4><p><img src=https://cdn.jsdelivr.net/gh/timerring/scratchpad2023/2024/2025-04-20-15-06-45.png alt></p><ul><li>Ordinary Poisson Process: One arrival at a time $(Y_i = 1)$</li><li>Compound Poisson Process: At each arrival, $Y_i>1$ (more than one ➔BULK) arrivals at each $t_i$</li></ul><h3 id=compound-poison-process>COMPOUND POISON PROCESS
<a class=anchor href=#compound-poison-process>#</a></h3>$$
E[X(t)]=\lambda t E[Y_i]
$$$$
Var[X(t)]=\lambda t E[Y_i^{2}]
$$<p>Example: Suppose that families migrate to an area at a Poisson rate $\lambda = 2$ per week.</p><p>If the number of people in each family is independent and takes on the values $1,2,3,4$ with respective probabilities $1/6,1/3,1/3,1/6$, then what is the expected value and variance of the number of individuals migrating to this area during a fixed five-week period?</p><p>Letting $Y_i$ denote the number of people in the $i$-th family, we have</p>$$
E[Y_i]=1\times\frac{1}{6}+2\times\frac{1}{3}+3\times\frac{1}{3}+4\times\frac{1}{6}=\frac{5}{2},
$$$$
E[Y_i^{2}]=1^{2}\times\frac{1}{6}+2^{2}\times\frac{1}{3}+3^{2}\times\frac{1}{3}+4^{2}\times\frac{1}{6}=\frac{43}{6}
$$<p>Hence, letting $X(5)$ denote the number of immigrants during a five - week period, then $E[X(5)] = 2\times5\times\frac{5}{2}=25$ and $Var[X(5)] = 2\times5\times\frac{43}{6}=\frac{215}{3}$</p><h2>Related readings</h2><ul><li><a href="/posts/random-walks/?utm_source=related">Random Walks</a></li><li><a href="/posts/stochastic-processes/?utm_source=related">Stochastic Processes</a></li><li><a href="/posts/sequences-of-random-variables/?utm_source=related">Sequences of Random Variables</a></li><li><a href="/posts/random-variables/?utm_source=related">Random Variables</a></li><li><a href="/posts/repeated-trials/?utm_source=related">Repeated Trials</a></li></ul><hr><div class=post-nav><a href="https://blog.timerring.com/posts/random-walks/?utm_source=nav">&lt;&lt; prev | Random Walks</a>
<a onclick=goToRandomPost() style=cursor:pointer>Continue strolling
</a><a href="https://blog.timerring.com/posts/stock-prices/?utm_source=nav">Stock Prices ｜ next >></a></div><hr>If you find this blog useful and want to support my blog, need my skill for something, or have a coffee chat with me, feel free to:<div class=support><a href=https://ko-fi.com/polls/What-is-the-custom-topic-for-the-next-month-C0C219LHQJ class=book-btn target=_blank>Subscribe to participate in blog topics and custom services
</a><a href=https://ko-fi.com/timerring class=book-btn target=_blank>Buy me a coffee</a></div><div style=margin-bottom:8px></div><script>function goToRandomPost(){const e=["/posts/hidden-markov-models/?utm_source=random","/posts/markov-chains/?utm_source=random","/posts/markov-processes/?utm_source=random","/posts/stock-prices/?utm_source=random","/posts/possion-processes/?utm_source=random","/posts/random-walks/?utm_source=random","/posts/0418-find-the-formula-rendering-issue-of-hugo/?utm_source=random","/posts/stochastic-processes/?utm_source=random","/posts/multi-platform-builds-docker/?utm_source=random","/posts/0404-The-invitation-only-mechanism-from-clubhouse-to-manus/?utm_source=random","/posts/how-to-use-git-submodule/?utm_source=random","/posts/live-streaming-infra-and-protocols/?utm_source=random","/posts/implement-danmaku-rendering-algorithm-from-scratch/?utm_source=random","/posts/is-there-an-rss-renaissance-in-the-ai-era/?utm_source=random","/posts/docker-with-gpu/?utm_source=random","/posts/some-useful-tools/?utm_source=random","/posts/a-shopping-experience-in-pangdonglai-supermarket/?utm_source=random","/posts/langchain-and-rag-best-practices/?utm_source=random","/posts/sequences-of-random-variables/?utm_source=random","/posts/random-variables/?utm_source=random","/posts/repeated-trials/?utm_source=random","/posts/probability-and-its-axioms/?utm_source=random","/posts/further-understanding-of-proc/?utm_source=random","/posts/the-iftop/?utm_source=random","/posts/some-useful-commands-to-share/?utm_source=random","/posts/reflections-on-trending-topics/?utm_source=random","/posts/cpu-can-only-see-the-threads/?utm_source=random","/posts/go-common-test/?utm_source=random","/posts/go-concurrency-and-parallelism/?utm_source=random","/posts/go-cheatsheet/?utm_source=random","/posts/video-technology-101/?utm_source=random","/posts/the-main-kind-of-message-queue/?utm_source=random","/posts/the-method-to-manage-traffic/?utm_source=random","/posts/the-different-kind-of-api-design/?utm_source=random","/posts/the-encode-and-decode-in-python/?utm_source=random","/posts/about-the-systemd/?utm_source=random","/posts/the-tips-about-dockerfile/?utm_source=random","/posts/docker-cheatsheet/?utm_source=random","/posts/docker-101/?utm_source=random","/posts/the-instance-class-static-magic-method-in-python/?utm_source=random","/posts/the-review-and-plan-for-bilive/?utm_source=random","/posts/the-overview-of-security/?utm_source=random","/posts/how-to-publish-your-code-as-a-pip-module/?utm_source=random","/posts/some-good-things-to-share-about-the-packages/?utm_source=random","/posts/introduction-to-the-http-and-https-protocol/?utm_source=random","/posts/mail-service-and-protocol/?utm_source=random","/posts/understanding-clash-through-configuration/?utm_source=random","/posts/thinking-about-advertisement-from-an-open-source-perspective/?utm_source=random","/posts/a-brief-introduction-to-dns/?utm_source=random","/posts/real-computer-network/?utm_source=random","/posts/python-generator-iterator-and-decorator/?utm_source=random","/posts/python-underlying-mechanism/?utm_source=random","/posts/python-files-exceptions-and-modules/?utm_source=random","/posts/python-object-oriented-programming/?utm_source=random","/posts/python-cheatsheet/?utm_source=random","/posts/python-function-parameter/?utm_source=random","/posts/python-control-structure/?utm_source=random","/posts/python-composite-data-type/?utm_source=random","/posts/python-basic-data-type/?utm_source=random","/posts/python-basic-syntax-elements/?utm_source=random","/posts/deploy-github-pages-with-gpg-signing/?utm_source=random","/posts/gpg-101/?utm_source=random","/posts/housewarming-2024/?utm_source=random"],t=Math.floor(Math.random()*e.length);window.location.href=e[t]}</script></article><div class=book-comments><div class="book-tabs-content markdown-inner"><div id=tcomment></div><script src=https://giscus.app/client.js data-repo=timerring/blog data-repo-id=R_kgDONeZYZg data-category=Announcements data-category-id=DIC_kwDONeZYZs4ClRWs data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div></div><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=busuanzi-footer><p style=text-align:center>&copy; 2022 - present <a href=https://github.com/timerring>timerring</a> | PV: <span id=busuanzi_value_site_pv></span> | UV: <span id=busuanzi_value_site_uv></span></p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#outline>Outline</a></li><li><a href=#review-of-some-basic-properties>Review of Some Basic Properties</a><ul><li><a href=#definition-of-poisson-process>Definition of Poisson Process</a></li><li><a href=#autocorrelation-function-r_xxt_1-t_2>Autocorrelation Function $R_{XX}(t_{1}, t_{2})$</a></li></ul></li><li><a href=#some-typical-poisson-processes>Some Typical Poisson Processes</a><ul><li><a href=#example-of-poisson-process-application>Example of Poisson Process Application</a></li><li><a href=#sum-and-difference-of-poisson-processes>Sum and Difference of Poisson Processes</a></li><li><a href=#example-of-sum-of-poisson-processes>Example of Sum of Poisson Processes</a></li></ul></li><li><a href=#random-selection-of-poisson-points>Random Selection of Poisson Points</a><ul><li><a href=#example-of-random-selection>Example of Random Selection</a></li><li><a href=#inter-arrival-distribution-for-poisson-processes>Inter-arrival Distribution for Poisson Processes</a></li><li><a href=#conclusion>Conclusion</a></li></ul></li><li><a href=#little-oh-notation>Little O(H) Notation</a></li><li><a href=#axiomatic-development-of-poisson-processes>Axiomatic Development of Poisson Processes</a><ul><li><a href=#first-arrival-time-interval>first arrival time interval</a></li></ul></li><li><a href=#counting-process>COUNTING PROCESS</a><ul><li><a href=#alternative-definition-of-poisson-process-independent-and-stationary-increments>ALTERNATIVE DEFINITION OF POISSON PROCESS INDEPENDENT AND STATIONARY INCREMENTS</a><ul><li><a href=#example>Example</a></li></ul></li></ul></li><li><a href=#the-bernoulli-process-a-discrete-time-poisson-process>THE BERNOULLI PROCESS: A DISCRETE-TIME &ldquo;POISSON PROCESS&rdquo;</a><ul><li><a href=#alternative-definition-2-of-poisson-process>ALTERNATIVE DEFINITION 2 OF POISSON PROCESS</a></li></ul></li><li><a href=#other-alternative-ways-to-define-poisson-processes>OTHER ALTERNATIVE WAYS TO DEFINE POISSON PROCESSES</a></li><li><a href=#some-comments-for-poisson-processes>SOME COMMENTS FOR POISSON PROCESSES</a><ul><li><a href=#important-properties-of-poisson-processes>IMPORTANT PROPERTIES OF POISSON PROCESSES！！！</a></li><li><a href=#conditional-distribution-of-the-arrival-times>CONDITIONAL DISTRIBUTION OF THE ARRIVAL TIMES</a></li><li><a href=#example-1>Example</a></li><li><a href=#poisson-departures-between-exponential-inter-arrivals>Poisson Departures between Exponential Inter-arrivals</a></li><li><a href=#compound-poisson-process>COMPOUND POISSON PROCESS</a><ul><li><a href=#bulk-arrivals>BULK ARRIVALS</a></li></ul></li><li><a href=#compound-poison-process>COMPOUND POISON PROCESS</a></li></ul></li></ul></nav><style>.book-toc .book-toc-content a{color:var(--body-font-color)}</style></div></aside></main></body></html>